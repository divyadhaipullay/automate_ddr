{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221c90b2-5321-43a6-b6d4-bb111080a359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "496d7298-d546-4673-aef5-bfcf51863f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e55589f5-8cb3-4585-9ecb-3c5e0e94e45e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"UnifiedExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility Functions\n",
    "# ---------------------------------------------------------------------\n",
    "def dbfs_to_local_path(dbfs_path):\n",
    "    \"\"\"Convert a DBFS URI to a local path.\"\"\"\n",
    "    if dbfs_path.startswith(\"dbfs:/\"):\n",
    "        return \"/dbfs/\" + dbfs_path[len(\"dbfs:/\"):]\n",
    "    return dbfs_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ff3e0a-8066-4a06-af13-149944ca548f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_cropped_section_image(section_path):\n",
    "    \"\"\"Read an image from a cropped section (handles DBFS paths).\"\"\"\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    logger.info(f\"Image loaded from {local_path} with shape {img.shape}\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cad0f93-61a6-4cb9-81ec-03b6fa129e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# COMMON UTILITY FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    local_path = img_path if not img_path.startswith(\"dbfs:\") else img_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {local_path}\")\n",
    "    logger.info(f\"Image loaded from {local_path} with shape {img.shape}\")\n",
    "    return img\n",
    "\n",
    "def preprocess_image(img, debug=False):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 9)\n",
    "    if debug:\n",
    "        logger.info(\"Preprocessing completed (grayscale and threshold applied).\")\n",
    "    return thresh\n",
    "\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        logger.info(f\"Detected {len(rois)} text regions.\")\n",
    "    return rois\n",
    "\n",
    "# def perform_ocr_on_rois(img, rois, debug=False):\n",
    "#     results = []\n",
    "#     for (x, y, w, h) in rois:\n",
    "#         roi = img[y:y+h, x:x+w]\n",
    "#         text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "#         results.append((x, y, w, h, text))\n",
    "#         if debug:\n",
    "#             logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "#     return results\n",
    "\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns a list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ae68a4-313d-43fc-9204-bfb2585e8707",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# PARSING HELPERS\n",
    "# -----------------------------------------------------------------------------\n",
    "def group_ocr_results(roi_texts, row_tolerance=10):\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    row_strings = []\n",
    "    for row in rows:\n",
    "        row.sort(key=lambda c: c[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line)\n",
    "    return row_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8464adc-3361-47ab-8b20-254577781b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#DDR combo\n",
    "def read_image_ddr(image_path):\n",
    "    \"\"\"\n",
    "    Read an image from the given file path using OpenCV.\n",
    "    \n",
    "    If the provided path starts with 'dbfs:/', convert it to a local path by\n",
    "    replacing the prefix with '/dbfs/'.\n",
    "    \"\"\"\n",
    "    if image_path.startswith(\"dbfs:/\"):\n",
    "        local_path = \"/dbfs/\" + image_path[len(\"dbfs:/\"):]\n",
    "    else:\n",
    "        local_path = image_path\n",
    "\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"Image file not found at {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read image from {local_path}\")\n",
    "    return img\n",
    "\n",
    "def draw_bounding_box_and_crop_ddr(image, coords, debug_path=None):\n",
    "    \"\"\"\n",
    "    Crop the region defined by 'coords' (x, y, width, height).\n",
    "    If a debug_path is provided, draw the bounding box on a copy and save it.\n",
    "    \"\"\"\n",
    "    x, y, w, h = coords\n",
    "    if debug_path:\n",
    "        debug_img = image.copy()\n",
    "        cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.imwrite(debug_path, debug_img)\n",
    "        logger.info(f\"Debug image saved to: {debug_path}\")\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "def preprocess_image_for_ocr_ddr(image):\n",
    "    \"\"\"\n",
    "    Preprocess the image for OCR by converting it to grayscale, applying histogram equalization,\n",
    "    Gaussian blur, and adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
    "    processed = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    return processed\n",
    "\n",
    "# def perform_ocr(image):\n",
    "#     \"\"\"\n",
    "#     Perform OCR on the preprocessed image using pytesseract.\n",
    "#     Uses OEM 3 (LSTM) and PSM 6 (assume a single uniform block).\n",
    "#     \"\"\"\n",
    "#     config = \"--oem 3 --psm 6\"\n",
    "#     return pytesseract.image_to_string(image, config=config)\n",
    "\n",
    "def extract_key_value_from_text_ddr(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Extract key-value pairs from the OCR text based on expected keys.\n",
    "    This function normalizes whitespace and uses regex to capture values.\n",
    "    \"\"\"\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        result[key] = match.group(1).strip() if match and match.group(1).strip() else None\n",
    "    return result\n",
    "\n",
    "def clean_report_num_ddr(report_num_str):\n",
    "    \"\"\"\n",
    "    Remove any trailing punctuation from the Report Num (e.g., converts '11.' to '11').\n",
    "    \"\"\"\n",
    "    if not report_num_str:\n",
    "        return report_num_str\n",
    "    match = re.search(r'^(\\d+)\\.?$', report_num_str)\n",
    "    return match.group(1) if match else report_num_str\n",
    "\n",
    "def process_daily_drilling_report(image_path, debug=False):\n",
    "    \"\"\"\n",
    "    Process the Daily Drilling Report section.\n",
    "    \n",
    "    Expected output format:\n",
    "    {\n",
    "        \"DAILY DRILLING REPORT\": {\n",
    "            \"Report Date\": \"7/4/2024\",\n",
    "            \"Report Num\": \"11\",\n",
    "            \"Rig\": \"Cyclone 39\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Steps:\n",
    "      1. Read the image from the provided local path.\n",
    "      2. Crop the top-right region where DDR details are located.\n",
    "      3. Preprocess the cropped region for OCR.\n",
    "      4. Perform OCR to extract text.\n",
    "      5. Extract and clean key-value pairs.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing DDR image from: {image_path}\")\n",
    "    img = read_image_ddr(image_path)\n",
    "    \n",
    "    # Coordinates for the top-right region; adjust as needed\n",
    "    coords = (1600, 0, 950, 185)\n",
    "    debug_path = \"/dbfs/mnt/mini-proj-dd/final_ocr_results/debug_top_right.png\"\n",
    "    cropped = draw_bounding_box_and_crop_ddr(img, coords, debug_path=debug_path)\n",
    "    \n",
    "    processed = preprocess_image_for_ocr_ddr(cropped)\n",
    "    ocr_text = perform_ocr(processed)\n",
    "    logger.info(\"DDR OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "    \n",
    "    expected_keys = [\"Report Date\", \"Report Num\", \"Rig\"]\n",
    "    extracted = extract_key_value_from_text_ddr(ocr_text, expected_keys)\n",
    "    if extracted.get(\"Report Num\"):\n",
    "        extracted[\"Report Num\"] = clean_report_num_ddr(extracted[\"Report Num\"])\n",
    "    \n",
    "    df = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    return {\"DAILY DRILLING REPORT\": extracted}, df\n",
    "\n",
    "def save_output(section_name, data_json, df, output_folder):\n",
    "    \"\"\"\n",
    "    Save JSON and CSV output files for a section.\n",
    "    \"\"\"\n",
    "    file_base = section_name.lower().replace(\" \", \"_\").replace(\":\", \"\").replace(\"&\", \"and\")\n",
    "    json_path = os.path.join(output_folder, f\"{file_base}_data.json\")\n",
    "    csv_path = os.path.join(output_folder, f\"{file_base}_data.csv\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data_json, f, indent=4)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    logger.info(f\"{section_name} output saved to:\\n JSON: {json_path}\\n CSV: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aadc8fe9-dc15-4306-9227-a20582ece1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_casing_dict_from_rois(roi_texts, expected_headers, debug=False):\n",
    "    row_strings = group_ocr_results(roi_texts)\n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for sub in line.split(\"\\n\"):\n",
    "            sub = sub.strip()\n",
    "            if sub:\n",
    "                all_lines.append(sub)\n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        if \"type\" in lower_tokens and \"size\" in lower_tokens:\n",
    "            logger.info(f\"CASING - Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"CASING - Line has fewer tokens than expected: {tokens}\")\n",
    "            continue\n",
    "        tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    casing_list = [{expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "                   for tokens in data_lines]\n",
    "    return casing_list\n",
    "\n",
    "def detect_text_regions_casing(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    # Sort by y (top-to-bottom) then by x (left-to-right)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "def process_casing_data(img_path, debug=False):\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions_casing(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    expected_headers = [\"Type\", \"Size\", \"Weight\", \"Grade\", \"Connection\", \"Top MD\", \"Bottom MD\", \"TOC\"]\n",
    "    casing_list = build_casing_dict_from_rois(roi_texts, expected_headers, debug=debug)\n",
    "    # df = pd.DataFrame(casing_list)\n",
    "    # logger.info(f\"CASING DataFrame shape: {df.shape}\")\n",
    "    return {\"CASING\": casing_list}, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ef3e812-d63d-43ec-b60a-977218a06b65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# process FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_key_value_from_text_cost(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Extracts key-value pairs from the text, ensuring that keys with empty values\n",
    "    are correctly detected instead of capturing the next key as their value.\n",
    "    \"\"\"\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)  # Normalize whitespace\n",
    "\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value if value else None  # Assign None for empty values\n",
    "        else:\n",
    "            result[key] = None  # Explicitly mark missing values\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_cost_data(img_path, debug=False):\n",
    "    #section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\"\n",
    "    img = safe_read_image(img_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"Cost OCR extraction complete.\")\n",
    "    expected_keys = [\n",
    "        \"Drilling AFE Amount\", \"Daily Drilling Cost\", \"Cumulative Drilling Cost\",\n",
    "        \"Cumulative Well Cost\", \"Daily Mud Cost\", \"Cumulative Mud Cost\"\n",
    "    ]\n",
    "    extracted = extract_key_value_from_text_cost(ocr_text, expected_keys)\n",
    "    df = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    logger.info(f\"COST DataFrame shape: {df.shape}\")\n",
    "    return {\"COST DATA\": extracted}, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf9b7c9-14c0-4098-b9fc-45ad2d35fc69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_well_job_info(section_path, debug=False):\n",
    "    img = safe_read_image(section_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"Well/Job OCR extraction complete.\")\n",
    "    expected_keys = [\n",
    "        \"Well Name\", \"Job Name\", \"Supervisor(s)\", \"Field\", \"Sec/Twn/Rng\", \"Phone\",\n",
    "        \"AFE #\", \"API #\", \"Email\", \"Contractor\", \"Elevation\", \"RKB\",\n",
    "        \"Spud Date\", \"Days from Spud\", \"Days on Loc\", \"MD/TVD\", \"24 Hr Footage\",\n",
    "        \"Present Operations\", \"Activity Planned\"\n",
    "    ]\n",
    "    combined = \" \".join(line.strip() for line in ocr_text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*?)(?=\\s*' + re.escape(next_key) + r'\\s*:|$)'\n",
    "        else:\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*)'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        result[key] = match.group(1).strip() if match else \"\"\n",
    "    df = pd.DataFrame(list(result.items()), columns=[\"Key\", \"Value\"])\n",
    "    logger.info(f\"WELL/JOB DataFrame shape: {df.shape}\")\n",
    "    return {\"WELL/JOB INFORMATION\": result}, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "323dfced-6c83-4009-9dd2-e4055653b649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_obs_int(section_path, debug=False):\n",
    "    img = safe_read_image(section_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    header_str = \"daily numbers: observation & intervention\"\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "    types_list, numbers_list = [], []\n",
    "    for txt in all_texts:\n",
    "        clean = txt.strip()\n",
    "        if clean.lower() in [header_str, \"number\", \"[blank]\"]:\n",
    "            continue\n",
    "        try:\n",
    "            float(clean)\n",
    "            numbers_list.append(\"\" if clean.lower() == \"[blank]\" else clean)\n",
    "            continue\n",
    "        except ValueError:\n",
    "            pass\n",
    "        if \"\\n\" in clean:\n",
    "            for line in clean.splitlines():\n",
    "                line = line.strip()\n",
    "                if line and line.lower() != \"[blank]\":\n",
    "                    types_list.append(line)\n",
    "        else:\n",
    "            types_list.append(clean)\n",
    "    expected_count = 5\n",
    "    while len(numbers_list) < expected_count:\n",
    "        numbers_list.append(\"\")\n",
    "    types_list = types_list[:expected_count]\n",
    "    numbers_list = numbers_list[:expected_count]\n",
    "    structured = [{\"Type\": types_list[i], \"Number\": numbers_list[i]} for i in range(expected_count)]\n",
    "    df = pd.DataFrame(structured)\n",
    "    logger.info(f\"DAILY NUMBERS: OBSERVATION & INTERVENTION DataFrame shape: {df.shape}\")\n",
    "    return {\"DAILY NUMBERS: OBSERVATION & INTERVENTION\": structured}, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "007662d6-c29b-4de9-aef9-d6c7a24337a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_dir_info_dict_from_rois(roi_texts, debug=False):\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "    daily_cum_idx = next((i for i, txt in enumerate(all_texts)\n",
    "                           if \"daily\" in txt.lower() and \"cumulative\" in txt.lower()), None)\n",
    "    if daily_cum_idx is None:\n",
    "        logger.warning(\"Could not find 'Daily Cumulative' bounding box.\")\n",
    "        return {}, pd.DataFrame()\n",
    "    cat_idx = daily_cum_idx + 1\n",
    "    if cat_idx >= len(all_texts):\n",
    "        logger.warning(\"No bounding box after 'Daily Cumulative'.\")\n",
    "        return {}, pd.DataFrame()\n",
    "    categories_box = all_texts[cat_idx]\n",
    "    lines = [ln.strip() for ln in categories_box.split(\"\\n\") if ln.strip()]\n",
    "    if len(lines) < 5:\n",
    "        logger.warning(f\"Expected 5 category lines, got {len(lines)}: {lines}\")\n",
    "    def safe_get(idx):\n",
    "        return all_texts[idx] if 0 <= idx < len(all_texts) else \"\"\n",
    "    structured = []\n",
    "    for i in range(4):\n",
    "        cat_name = lines[i] if i < len(lines) else f\"Unknown Category {i+1}\"\n",
    "        daily_box = safe_get(cat_idx + 1 + (i * 2))\n",
    "        cum_box = safe_get(cat_idx + 2 + (i * 2))\n",
    "        structured.append({\n",
    "            \"Category\": cat_name,\n",
    "            \"Daily\": \"\" if daily_box == \"[BLANK]\" else daily_box,\n",
    "            \"Cumulative\": \"\" if cum_box == \"[BLANK]\" else cum_box\n",
    "        })\n",
    "    last_box = safe_get(cat_idx + 9)\n",
    "    last_cat = lines[4] if len(lines) >= 5 else \"Rotating Footage\"\n",
    "    remainder = last_box.replace(last_cat, \"\").strip()\n",
    "    tokens = remainder.split()\n",
    "    daily_val = tokens[0] if len(tokens) >= 2 else \"\"\n",
    "    cum_val = tokens[1] if len(tokens) >= 2 else \"\"\n",
    "    structured.append({\n",
    "        \"Category\": last_cat,\n",
    "        \"Daily\": \"\" if daily_val == \"[BLANK]\" else daily_val,\n",
    "        \"Cumulative\": \"\" if cum_val == \"[BLANK]\" else cum_val\n",
    "    })\n",
    "    df = pd.DataFrame(structured)\n",
    "    logger.info(f\"DIR INFO DataFrame shape: {df.shape}\")\n",
    "    return {\"DIR INFO\": structured}, df\n",
    "\n",
    "def process_dir_info(section_path, debug=False):\n",
    "    img = safe_read_image(section_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    return build_dir_info_dict_from_rois(roi_texts, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f309641-a8e1-4fe6-bc45-8a9752862d77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def detect_text_regions_consumables(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # A basic size filter to skip very small or very thin boxes\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    # Sort by y then x\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "\n",
    "def build_consumables_dict_from_rois(roi_texts, debug=False):\n",
    "    row_strings = group_ocr_results(roi_texts)\n",
    "    data_rows = []\n",
    "    for line in row_strings:\n",
    "        lower_line = line.lower()\n",
    "        if (\"consumable\" in lower_line and \"received\" in lower_line) or \"nun\" in lower_line:\n",
    "            continue\n",
    "        if len(line.split()) < 5:\n",
    "            continue\n",
    "        data_rows.append(line)\n",
    "    consumables_list = []\n",
    "    for line in data_rows:\n",
    "        tokens = re.split(r'\\s+', line)\n",
    "        if len(tokens) > 5:\n",
    "            first = \" \".join(tokens[:-4])\n",
    "            tokens = [first] + tokens[-4:]\n",
    "        if len(tokens) != 5:\n",
    "            logger.warning(f\"CONSUMABLES - Skipping row (unexpected token count): {tokens}\")\n",
    "            continue\n",
    "        consumables_list.append({\n",
    "            \"Consumable\": tokens[0],\n",
    "            \"Daily Received (gal)\": tokens[1],\n",
    "            \"Daily Used (gal)\": tokens[2],\n",
    "            \"Cumulative Used (gal)\": tokens[3],\n",
    "            \"Daily on Hand (gal)\": tokens[4]\n",
    "        })\n",
    "    return consumables_list\n",
    "\n",
    "def process_consumables_data(img_path, debug=False):\n",
    "    #section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_2_section_2.png\"\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions_consumables(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    consumables_list = build_consumables_dict_from_rois(roi_texts, debug=debug)\n",
    "    df = pd.DataFrame(consumables_list)\n",
    "    logger.info(f\"CONSUMABLES DataFrame shape: {df.shape}\")\n",
    "    return {\"CONSUMABLES\": consumables_list}, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a9eea98-76aa-4aa0-a2b5-264e218ed9d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_bha_data(image_path, debug=False):\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pat in patterns.items():\n",
    "        match = re.search(pat, ocr_text)\n",
    "        if match:\n",
    "            bha_data[key] = match.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for remove_key in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if remove_key in bha_data:\n",
    "                detail = re.sub(rf\"{remove_key}:\\s*{re.escape(bha_data[remove_key])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured_data = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    if debug:\n",
    "        logger.info(\"Extracted BHA data:\")\n",
    "        logger.info(json.dumps(structured_data, indent=4))\n",
    "    return structured_data\n",
    "\n",
    "def process_bha_data(image_path, debug=False):\n",
    "    #image_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png\"  # Adjust as needed\n",
    "    bha_json = extract_bha_data(image_path, debug=debug)\n",
    "    img = safe_read_image(image_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    pump_data = parse_pumps_table(ocr_text)\n",
    "    circ_data = parse_drilling_circ_rates(ocr_text)\n",
    "    pumps_df = pd.DataFrame(pump_data)\n",
    "    circ_df = pd.DataFrame(circ_data)\n",
    "    bha_df = pd.DataFrame([bha_json])\n",
    "    logger.info(f\"BHA DataFrame shape: {bha_df.shape}\")\n",
    "    combined = {\"BHA\": bha_json, \"Pumps\": pump_data, \"DrillingCircRates\": circ_data}\n",
    "    return combined, pumps_df, circ_df, bha_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33043d19-605f-4834-b763-a1a940bed780",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_mud_data(img_path, debug=False):\n",
    "    #section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\"\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    expected_headers = [\n",
    "        \"Type\", \"Weight In\", \"Weight Out\", \"pH\", \"CAKE\",\n",
    "        \"GELS (10s/10m/30m)\", \"Oil/Water\", \"FV\", \"ES\", \"PV\",\n",
    "        \"YP\", \"CL\", \"Ca\", \"LGS\", \"WL\", \"HTHP Loss\", \"3 RPM\",\n",
    "        \"6 RPM\", \"Mud Pits and Hole Volume\", \"24 Hr Loss\",\n",
    "        \"Total Loss\", \"Comments\"\n",
    "    ]\n",
    "    mud_dict = build_mud_dict_from_rois(roi_texts, expected_headers)\n",
    "    return {\"MUD\": mud_dict}, pd.DataFrame(list(mud_dict.items()), columns=[\"Key\", \"Value\"])\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# parse_value_row_tokens for mud section\n",
    "# ---------------------------------------------------------------------\n",
    "def parse_value_row_tokens(expected_headers, tokens):\n",
    "    \"\"\"\n",
    "    Map a flat list of tokens to the expected headers.\n",
    "    For \"GELS (10s/10m/30m)\", consume 3 tokens and create a sub-dictionary.\n",
    "    Expected token count = (number of headers - 1) + 3.\n",
    "    \"\"\"\n",
    "    expected_token_count = (len(expected_headers) - 1) + 3\n",
    "    logger.info(f\"Expected token count: {expected_token_count}, tokens extracted: {tokens}\")\n",
    "    \n",
    "    # Pad or trim tokens as needed.\n",
    "    if len(tokens) < expected_token_count:\n",
    "        tokens += [\"[BLANK]\"] * (expected_token_count - len(tokens))\n",
    "        logger.warning(\"Not enough tokens. Padding with [BLANK].\")\n",
    "    elif len(tokens) > expected_token_count:\n",
    "        tokens = tokens[:expected_token_count]\n",
    "        logger.warning(\"Too many tokens. Trimming the extra tokens.\")\n",
    "    \n",
    "    result = {}\n",
    "    idx = 0\n",
    "    for header in expected_headers:\n",
    "        if header == \"GELS (10s/10m/30m)\":\n",
    "            gels_tokens = tokens[idx:idx+3]\n",
    "            result[header] = {\n",
    "                \"10s\": gels_tokens[0],\n",
    "                \"10m\": gels_tokens[1],\n",
    "                \"30m\": gels_tokens[2]\n",
    "            }\n",
    "            idx += 3\n",
    "        else:\n",
    "            result[header] = tokens[idx]\n",
    "            idx += 1\n",
    "    logger.info(f\"Mapped dictionary: {result}\")\n",
    "    return result\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_mud_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_mud_dict_from_rois(roi_texts, expected_headers):\n",
    "    \"\"\"\n",
    "    Group OCR results into rows based on the y coordinate.\n",
    "    Identify header rows and corresponding data rows.\n",
    "    \n",
    "    In our case, we expect:\n",
    "      - A header row (with labels) followed by a data row,\n",
    "      - Then a second header row (for the remaining fields) followed by a second data row.\n",
    "    \n",
    "    We then combine the two data rows' tokens and map them to expected_headers.\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    # Group by row based on y coordinate.\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    # Sort each row by x coordinate and log its text.\n",
    "    row_strings = []\n",
    "    for i, row_cells in enumerate(rows):\n",
    "        row_cells.sort(key=lambda c: c[0])\n",
    "        line_text = \" \".join(cell[4] for cell in row_cells)\n",
    "        row_strings.append(line_text)\n",
    "        logger.info(f\"Row {i} text: {line_text}\")\n",
    "\n",
    "    # Based on OCR output expectations:\n",
    "    # Row 1: header row 1 (first set of labels)\n",
    "    # Row 2: data row 1 (first set of values)\n",
    "    # Row 3: header row 2 (remaining labels)\n",
    "    # Row 4: data row 2 (remaining values)\n",
    "    header1_line = None\n",
    "    value1_line = None\n",
    "    header2_line = None\n",
    "    value2_line = None\n",
    "\n",
    "    for i, r_text in enumerate(row_strings):\n",
    "        if \"Type\" in r_text and not header1_line:\n",
    "            header1_line = r_text\n",
    "            if i + 1 < len(row_strings):\n",
    "                value1_line = row_strings[i+1]\n",
    "        elif header1_line and not header2_line and any(kw in r_text for kw in [\"RPM\", \"Mud\", \"Loss\", \"Comments\"]):\n",
    "            header2_line = r_text\n",
    "            if i + 1 < len(row_strings):\n",
    "                value2_line = row_strings[i+1]\n",
    "            break\n",
    "\n",
    "    logger.info(f\"Header1: {header1_line}\")\n",
    "    logger.info(f\"Value1: {value1_line}\")\n",
    "    logger.info(f\"Header2: {header2_line}\")\n",
    "    logger.info(f\"Value2: {value2_line}\")\n",
    "\n",
    "    if value1_line is None:\n",
    "        logger.error(\"No data row found for header1!\")\n",
    "        return {}\n",
    "\n",
    "    # Split the data rows into tokens.\n",
    "    tokens1 = value1_line.split()\n",
    "    tokens2 = value2_line.split() if value2_line else []\n",
    "    logger.info(f\"Tokens from data row 1: {tokens1}\")\n",
    "    logger.info(f\"Tokens from data row 2: {tokens2}\")\n",
    "\n",
    "    # Combine tokens from both data rows.\n",
    "    combined_tokens = tokens1 + tokens2\n",
    "    logger.info(f\"Combined tokens: {combined_tokens}\")\n",
    "\n",
    "    # Map the tokens to the expected headers.\n",
    "    return parse_value_row_tokens(expected_headers, combined_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f611b34-6920-4ce4-be46-0c3a62ee0e4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Pumps Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def parse_pumps_table(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses the pumps table from OCR text using a regex.\n",
    "    Expected format: Number BOMCO TRIPLEX [HHP] Efficiency Stroke(in) Liner(in) P-Rating P-Limit SPM_Rating SPM_Limit\n",
    "    \"\"\"\n",
    "    pump_pattern = re.compile(\n",
    "        r\"^(\\d+)?\\s*\"               # Number (optional)\n",
    "        r\"(BOMCO)\\s+(TRIPLEX)\\s+\"    # Model, Type\n",
    "        r\"(\\d+)?\\s*\"                # HHP (optional)\n",
    "        r\"(\\d+)\\s+\"                 # Efficiency\n",
    "        r\"([\\d.]+)\\s+\"              # Stroke\\(in\\)\n",
    "        r\"([\\d.]+)\\s+\"              # Liner\\(in\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Rating\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Limit\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # SPM Rating\n",
    "        r\"(\\d+)\\s*$\",               # SPM Limit\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    pumps = []\n",
    "    lines = ocr_text.splitlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        match = pump_pattern.match(line)\n",
    "        if match:\n",
    "            number, model, pump_type, hhp, efficiency, stroke, liner, p_rating, p_limit, spm_rating, spm_limit = match.groups()\n",
    "            pumps.append({\n",
    "                \"Number\": number if number else \"\",\n",
    "                \"Model\": model,\n",
    "                \"Type\": pump_type,\n",
    "                \"HHP\": hhp if hhp else \"\",\n",
    "                \"Efficiency\": efficiency,\n",
    "                \"Stroke(in)\": stroke,\n",
    "                \"Liner(in)\": liner,\n",
    "                \"P-Rating(psi)\": p_rating,\n",
    "                \"P-Limit(psi)\": p_limit,\n",
    "                \"SPM Rating\": spm_rating,\n",
    "                \"SPM Limit\": spm_limit\n",
    "            })\n",
    "    return pumps\n",
    "\n",
    "def parse_drilling_circ_rates(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses drilling/circ rates from OCR text.\n",
    "    This version splits the text into segments starting with \"Drilling/Circ Rate <n>\"\n",
    "    then combines the lines in each segment and applies a regex with DOTALL.\n",
    "    \"\"\"\n",
    "    circ_rates = []\n",
    "    \n",
    "    # Split the OCR text into segments where each segment begins with \"Drilling/Circ Rate\" followed by a digit\n",
    "    segments = re.split(r\"(?=Drilling/Circ Rate \\d+)\", ocr_text)\n",
    "    \n",
    "    # Regex pattern to capture the numbers:\n",
    "    # Group 1: Rate ID (the number after \"Drilling/Circ Rate\")\n",
    "    # Group 2: Pressure (number preceding \"PS!\" or \"PSI\")\n",
    "    # Group 3: SPM value (number after \"@\")\n",
    "    # Group 4: Gal/Stoke value\n",
    "    # Group 5: GPM value\n",
    "    # Group 6: BPM value\n",
    "    # Group 7: DC value\n",
    "    # Group 8: DP value\n",
    "    pattern = re.compile(\n",
    "        r\"Drilling/Circ Rate\\s+(\\d+).*?\"       # Rate ID\n",
    "        r\"(\\d+)\\s+PS[!I].*?\"                   # Pressure\n",
    "        r\"@\\s*(\\d+).*?\"                        # SPM value\n",
    "        r\"([\\d.]+)\\s+Gal/Stoke.*?\"              # Gal/Stoke\n",
    "        r\"([\\d.]+)\\s+GPM.*?\"                    # GPM\n",
    "        r\"([\\d.]+)\\s+BPM.*?\"                    # BPM\n",
    "        r\"([\\d.]+)\\s+DC.*?\"                     # DC\n",
    "        r\"([\\d.]+)\\s+DP\",                      # DP\n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    \n",
    "    # Process each segment individually\n",
    "    for seg in segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg.startswith(\"Drilling/Circ Rate\"):\n",
    "            continue  # Skip any header or unrelated segments\n",
    "        # Replace newline characters with spaces to form a continuous string\n",
    "        seg_clean = \" \".join(seg.splitlines())\n",
    "        match = pattern.search(seg_clean)\n",
    "        if match:\n",
    "            rate_id, pressure, spm, gal_stroke, gpm, bpm, dc, dp = match.groups()\n",
    "            circ_rates.append({\n",
    "                \"RateID\": rate_id,\n",
    "                \"Pressure(PSI)\": pressure,\n",
    "                \"SPM\": spm,\n",
    "                \"Gal/Stoke\": gal_stroke,\n",
    "                \"GPM\": gpm,\n",
    "                \"BPM\": bpm,\n",
    "                \"DC\": dc,\n",
    "                \"DP\": dp\n",
    "            })\n",
    "        else:\n",
    "            # Optional: log a warning if no match is found for a segment\n",
    "            print(f\"Warning: No match found in segment:\\n{seg_clean}\")\n",
    "            \n",
    "    return circ_rates\n",
    "\n",
    "\n",
    "def process_pumps(pumps_img_path, debug=False):\n",
    "    \"\"\"\n",
    "    Processes the pumps section:\n",
    "    #   - Reads image using PIL,\n",
    "      - Performs OCR,\n",
    "      - Parses pumps table and drilling/circ rates,\n",
    "      - Returns combined results as JSON and a DataFrame.\n",
    "    \"\"\"\n",
    "    #pil_img = read_pil_image(pumps_img_path)\n",
    "    ocr_text = perform_ocr(pil_img)\n",
    "    if debug:\n",
    "        logger.info(\"Pumps OCR Text:\\n\" + ocr_text)\n",
    "    pumps = parse_pumps_table(ocr_text)\n",
    "    circ_rates = parse_drilling_circ_rates(ocr_text)\n",
    "    final_data = {\"Pumps\": pumps, \"DrillingCircRates\": circ_rates}\n",
    "    df_pumps = pd.DataFrame(pumps)\n",
    "    df_circ = pd.DataFrame(circ_rates)\n",
    "    if not df_pumps.empty and not df_circ.empty:\n",
    "        df = pd.concat([df_pumps, df_circ], axis=0, ignore_index=True)\n",
    "    elif not df_pumps.empty:\n",
    "        df = df_pumps\n",
    "    else:\n",
    "        df = df_circ\n",
    "    return final_data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba78492e-ce7c-4f7b-bcd9-70f117c27e3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Personnel Extraction process\n",
    "# --------------------------------------------------------\n",
    "def detect_text_regions_personnel(thresh_img, debug=False):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    logger.debug(f\"Detected {len(rois)} text regions for personnel.\")\n",
    "    # if debug:\n",
    "    #     show_image(\"Detected Personnel Text Regions\", debug_img, size=(12, 12))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois_personnel(img, rois, debug=False):\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        logger.debug(f\"ROI bbox=({x}, {y}, {w}, {h}), text: '{text}'\")\n",
    "    return results\n",
    "\n",
    "def group_rois_by_row(roi_results, threshold=20):\n",
    "    roi_with_center = [(x, y, w, h, text, y + h/2) for (x, y, w, h, text) in roi_results]\n",
    "    roi_with_center.sort(key=lambda r: r[5])\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    current_center = None\n",
    "    for roi in roi_with_center:\n",
    "        x, y, w, h, text, y_center = roi\n",
    "        if current_center is None:\n",
    "            current_center = y_center\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        elif abs(y_center - current_center) < threshold:\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [(x, y, w, h, text)]\n",
    "            current_center = y_center\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    logger.debug(f\"Grouped ROIs into {len(groups)} rows.\")\n",
    "    return groups\n",
    "\n",
    "def preprocess_personnel_data_from_rows(groups):\n",
    "    personnel_data = []\n",
    "    header_lines = {\n",
    "        \"personnel\", \n",
    "        \"company contractor no. personnel daily hours cumulative hours\",\n",
    "        \"ssn\"\n",
    "    }\n",
    "    for group in groups:\n",
    "        group.sort(key=lambda r: r[0])\n",
    "        row_text = \" \".join([r[4] for r in group]).strip()\n",
    "        logger.debug(f\"Processing row: '{row_text}'\")\n",
    "        if row_text.lower() in header_lines:\n",
    "            logger.debug(\"Skipping header row.\")\n",
    "            continue\n",
    "        tokens = row_text.split()\n",
    "        numeric_tokens = re.findall(r'\\d+(?:\\.\\d+)?', row_text)\n",
    "        logger.debug(f\"Row tokens: {tokens}\")\n",
    "        logger.debug(f\"Numeric tokens found: {numeric_tokens}\")\n",
    "        if tokens[0].lower().startswith(\"totals\"):\n",
    "            if len(numeric_tokens) >= 2:\n",
    "                try:\n",
    "                    daily_hours = int(float(numeric_tokens[0]))\n",
    "                    cumulative_hours = numeric_tokens[1]\n",
    "                except ValueError as e:\n",
    "                    logger.error(f\"Error parsing Totals row: {row_text} => {e}\")\n",
    "                    continue\n",
    "                row_dict = {\n",
    "                    \"Company\": \"\",\n",
    "                    \"Contractor\": \"\",\n",
    "                    \"No. Personnel\": \"Totals\",\n",
    "                    \"Daily Hours\": daily_hours,\n",
    "                    \"Cumulative Hours\": cumulative_hours\n",
    "                }\n",
    "                logger.info(f\"Totals row parsed: {row_dict}\")\n",
    "                personnel_data.append(row_dict)\n",
    "            else:\n",
    "                logger.warning(f\"Totals row without sufficient numbers: {row_text}\")\n",
    "            continue\n",
    "        if len(numeric_tokens) >= 3:\n",
    "            try:\n",
    "                no_personnel = int(float(numeric_tokens[-3]))\n",
    "                daily_hours = int(float(numeric_tokens[-2]))\n",
    "                cumulative_hours = int(float(numeric_tokens[-1]))\n",
    "                logger.debug(f\"Extracted: no_personnel={no_personnel}, daily_hours={daily_hours}, cumulative_hours={cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting numbers in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            pattern = (r'\\s*' + re.escape(numeric_tokens[-3]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-2]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-1]) + r'\\s*$')\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        elif len(numeric_tokens) == 1:\n",
    "            try:\n",
    "                cumulative_hours = int(float(numeric_tokens[0]))\n",
    "                logger.debug(f\"Single numeric token, cumulative_hours: {cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting single number in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            no_personnel = None\n",
    "            daily_hours = None\n",
    "            pattern = r'\\s*' + re.escape(numeric_tokens[0]) + r'\\s*$'\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        else:\n",
    "            logger.warning(f\"Row has unexpected number of numeric tokens: {row_text}\")\n",
    "            continue\n",
    "\n",
    "        if \"service company\" in text_only.lower():\n",
    "            parts = re.split(r'(?i)service company', text_only, maxsplit=1)\n",
    "            company = parts[0].strip()\n",
    "            contractor = \"Service Company\"\n",
    "        else:\n",
    "            company = text_only\n",
    "            contractor = \"Service Company\"\n",
    "        \n",
    "        row_dict = {\n",
    "            \"Company\": company,\n",
    "            \"Contractor\": contractor,\n",
    "            \"No. Personnel\": no_personnel,\n",
    "            \"Daily Hours\": daily_hours,\n",
    "            \"Cumulative Hours\": cumulative_hours\n",
    "        }\n",
    "        logger.info(f\"Parsed row: {row_dict}\")\n",
    "        personnel_data.append(row_dict)\n",
    "    return {\"PERSONNEL\": personnel_data}\n",
    "\n",
    "def process_personnel(personnel_img_path, debug=False):\n",
    "    \"\"\"Processes the personnel section: read image, detect ROIs, OCR, group and parse rows.\"\"\"\n",
    "    img = read_cropped_section_image(personnel_img_path)\n",
    "    if debug:\n",
    "        show_image(\"Original Personnel Image\", img, size=(10,10))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "    if debug:\n",
    "        show_image(\"Thresholded Personnel Image\", cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR), size=(8,8))\n",
    "    rois = detect_text_regions_personnel(thresh_img, debug=debug)\n",
    "    roi_results = perform_ocr_on_rois_personnel(img, rois, debug=debug)\n",
    "    grouped_rows = group_rois_by_row(roi_results, threshold=20)\n",
    "    data_dict = preprocess_personnel_data_from_rows(grouped_rows)\n",
    "    df = pd.DataFrame(data_dict[\"PERSONNEL\"]) if data_dict[\"PERSONNEL\"] else pd.DataFrame(\n",
    "        columns=[\"Company\", \"Contractor\", \"No. Personnel\", \"Daily Hours\", \"Cumulative Hours\"])\n",
    "    return data_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5667a894-db65-4c0e-b3f8-c43644d45863",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 3) Survey Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def build_survey_dict_from_rois(roi_texts, expected_headers):\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    \n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line)\n",
    "        logger.info(f\"Grouped Row {i}: {line}\")\n",
    "    \n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for subline in line.split(\"\\n\"):\n",
    "            subline = subline.strip()\n",
    "            if subline:\n",
    "                all_lines.append(subline)\n",
    "    logger.info(f\"All extracted lines: {all_lines}\")\n",
    "    \n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        if \"md\" in lower_tokens and \"inclination\" in lower_tokens:\n",
    "            logger.info(f\"Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"Line has fewer tokens than expected: {tokens}\")\n",
    "            continue\n",
    "        tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    \n",
    "    survey_list = []\n",
    "    for tokens in data_lines:\n",
    "        row_dict = {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        survey_list.append(row_dict)\n",
    "    return survey_list\n",
    "\n",
    "def sort_survey_data(survey_list):\n",
    "    def md_value(row):\n",
    "        try:\n",
    "            return float(row[\"MD\"].replace(\",\", \"\"))\n",
    "        except Exception:\n",
    "            return 0\n",
    "    sorted_list = sorted(survey_list, key=md_value, reverse=True)\n",
    "    filtered_list = [row for row in sorted_list if not row[\"MD\"].upper().startswith(\"SURVEY\")]\n",
    "    return filtered_list\n",
    "\n",
    "def process_survey(survey_img_path, debug=False):\n",
    "    expected_headers = [\"MD\", \"Inclination\", \"Azimuth\", \"DLS\", \"TVD\"]\n",
    "    img = safe_read_image(survey_img_path)\n",
    "    if debug:\n",
    "        show_image(\"Original Survey Image\", img, size=(12,12))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"Adaptive Threshold\", thresh, cmap=\"gray\")\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"Detected Text Regions\", debug_img)\n",
    "    roi_texts = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        roi_texts.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    survey_list = build_survey_dict_from_rois(roi_texts, expected_headers)\n",
    "    survey_list = sort_survey_data(survey_list)\n",
    "    final_output = {\"SURVEY DATA\": survey_list}\n",
    "    df = pd.DataFrame(survey_list)\n",
    "    return final_output, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) BOP Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def process_bop(ocr_text, debug= False):\n",
    "    pattern = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in pattern.items():\n",
    "        match = re.search(regex, ocr_text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    return result\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) BHA Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def extract_bha_data(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, ocr_text)\n",
    "        if match:\n",
    "            bha_data[key] = match.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for remove_key in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if remove_key in bha_data:\n",
    "                detail = re.sub(rf\"{remove_key}:\\s*{re.escape(bha_data[remove_key])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured_data = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    return structured_data\n",
    "\n",
    "def process_bha(bha_img_path, debug=False):\n",
    "    bha_json = extract_bha_data(bha_img_path)\n",
    "    df = pd.json_normalize(bha_json[\"BHA\"])\n",
    "    return {\"BHA\": bha_json[\"BHA\"]}, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c3ca69-a49d-4f6f-b87e-314f82234257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_bit_info_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_bit_info_dict_from_rois(roi_texts, debug=False):\n",
    "    \"\"\"\n",
    "    Custom parsing for the multi-row header layout:\n",
    "      Row 0 => Table Title (e.g. \"DRILL BITS ...\")\n",
    "      Row 1 => Super Headers: \"Bit Data  Nozzles  Depth  Hours  Dull Grade\"\n",
    "      Row 2 => Sub-headers:   \"Bit # Size Make Model Serial #  Number x Size TFA  In Out Feet ROP  Total On Btm  I oO D L B G oO RP\"\n",
    "      Row 3 => Data row #1\n",
    "      Row 4 => Data row #2\n",
    "      ...\n",
    "    We'll parse row 1 and row 2 to define column groups. Then parse each subsequent row in chunks.\n",
    "    \"\"\"\n",
    "    # Step 1) Group bounding boxes by y-coordinate\n",
    "    row_tolerance = 10\n",
    "    grouped_rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            grouped_rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        grouped_rows.append(current_row)\n",
    "\n",
    "    # Step 2) Convert each row group into a single string\n",
    "    row_strings = []\n",
    "    for i, row_cells in enumerate(grouped_rows):\n",
    "        row_cells.sort(key=lambda c: c[0])  # left->right\n",
    "        line = \" \".join(cell[4] for cell in row_cells)\n",
    "        line = line.replace(\"\\n\", \" \").strip()  # flatten\n",
    "        row_strings.append(line)\n",
    "        if debug:\n",
    "            logger.info(f\"Row {i} => {line}\")\n",
    "\n",
    "    # We expect something like:\n",
    "    # Row 0 => \"DRILL BITS DRILL BITS [BLANK]\"\n",
    "    # Row 1 => \"Bit Data Nozzles Depth Hours Dull Grade\"\n",
    "    # Row 2 => \"Bit # Size Make Model Serial # Number x Size TFA In Out Feet ROP Total On Btm I oO D L B G oO RP\"\n",
    "    # Row 3 => \"4 6.750 BAKER DD40+TWS 5355166 6X12 0.66 ...\"\n",
    "    # Row 4 => \"3 9.875 REED TKS6-H1 A308739 7X12 0.77 ...\"\n",
    "\n",
    "    # Step 3) Identify the row indices for:\n",
    "    #  - Title (row 0)\n",
    "    #  - Super headers (row 1)\n",
    "    #  - Sub-headers (row 2)\n",
    "    #  - Data rows (row 3, 4, ...)\n",
    "    if len(row_strings) < 3:\n",
    "        logger.warning(\"Not enough rows found for this layout.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # We'll skip row 0 (table title).\n",
    "    super_header_line = row_strings[1] if len(row_strings) > 1 else \"\"\n",
    "    sub_header_line   = row_strings[2] if len(row_strings) > 2 else \"\"\n",
    "    data_lines        = row_strings[3:]  # everything after row 2\n",
    "\n",
    "    if debug:\n",
    "        logger.info(f\"Super Headers => {super_header_line}\")\n",
    "        logger.info(f\"Sub Headers => {sub_header_line}\")\n",
    "        logger.info(f\"Data Lines => {data_lines}\")\n",
    "\n",
    "    # Step 4) Define the \"super header\" groups and sub-headers\n",
    "    # We'll do a simpler approach: we know how many tokens each group has:\n",
    "    #  Bit Data => 5, Nozzles => 2, Depth => 4, Hours => 2, Dull Grade => 8 (Total = 21)\n",
    "    final_columns = [\n",
    "        \"Bit #\", \"Size\", \"Make\", \"Model\", \"Serial #\",         # 5\n",
    "        \"Nozzle-(Number x Size)\", \"Nozzle-TFA\",               # 2\n",
    "        \"Depth-In\", \"Depth-Out\", \"Depth-Feet\", \"Depth-ROP\",   # 4\n",
    "        \"Hours-Total\", \"Hours-On Btm\",                        # 2\n",
    "        \"Dull Grade-I\", \"Dull Grade-O1\", \"Dull Grade-D\", \"Dull Grade-L\", \n",
    "        \"Dull Grade-B\", \"Dull Grade-G\", \"Dull Grade-O2\", \"Dull Grade-RP\"  # 8\n",
    "    ]\n",
    "\n",
    "    # Step 5) Parse each data row in chunks of 21 tokens\n",
    "    structured_data = []\n",
    "    for line in data_lines:\n",
    "        tokens = line.split()\n",
    "        # We expect 21 tokens per data row; pad or truncate if necessary\n",
    "        if len(tokens) < 21:\n",
    "            tokens += [\"\"] * (21 - len(tokens))\n",
    "        elif len(tokens) > 21:\n",
    "            tokens = tokens[:21]\n",
    "\n",
    "        row_dict = {}\n",
    "        for col_idx, col_name in enumerate(final_columns):\n",
    "            row_dict[col_name] = tokens[col_idx] if col_idx < len(tokens) else \"\"\n",
    "\n",
    "        structured_data.append(row_dict)\n",
    "        if debug:\n",
    "            logger.info(f\"Parsed row => {row_dict}\")\n",
    "\n",
    "    # Step 6) Convert to DataFrame and JSON\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    if debug:\n",
    "        logger.info(\"DataFrame Preview:\")\n",
    "        logger.info(df.head())\n",
    "\n",
    "    df.to_csv(\"bit_info_data.csv\", index=False)\n",
    "    logger.info(\"Data saved successfully as CSV.\")\n",
    "\n",
    "    structured_data_json = df.to_dict(orient='records')\n",
    "    with open(\"bit_info_data.json\", \"w\") as json_file:\n",
    "        json.dump(structured_data_json, json_file, indent=4)\n",
    "    logger.info(\"Data saved successfully in JSON format.\")\n",
    "\n",
    "    return structured_data_json, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_bit_info_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def process_drill_bits(img_path, debug=False):\n",
    "    \"\"\"\n",
    "    Main pipeline for extracting the BIT DETAILS table from your layout.\n",
    "    \"\"\"\n",
    "    # Replace with your actual path\n",
    "    #bit_info_img_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_6.png\"\n",
    "\n",
    "    try:\n",
    "        img = safe_read_image(img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # 1) Preprocess\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "\n",
    "    # 2) Detect bounding boxes\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "\n",
    "    # 3) Perform OCR\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # --- New Step: Annotate and show OCR results on the image ---\n",
    "    # annotate_ocr_results(img, roi_texts)\n",
    "\n",
    "    # 4) Build structured data (tailored to your table layout)\n",
    "    bit_info_list, df = build_bit_info_dict_from_rois(roi_texts, debug=True)\n",
    "\n",
    "    # 5) Show final JSON in logs\n",
    "    final_output = {\"BIT DETAILS\": bit_info_list}\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    print(df)\n",
    "\n",
    "    # 6) Save final results\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_bit_info_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    with open(os.path.join(output_folder, \"bit_info_data.json\"), \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    df.to_csv(os.path.join(output_folder, \"bit_info_data.csv\"), index=False)\n",
    "    logger.info(\"Data saved successfully in output folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6332d95-760b-4f60-a21c-6f8db985caec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_pumps_table(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses the pumps table from OCR text using a regex.\n",
    "    Expected format: Number BOMCO TRIPLEX [HHP] Efficiency Stroke(in) Liner(in) P-Rating P-Limit SPM_Rating SPM_Limit\n",
    "    \"\"\"\n",
    "    pump_pattern = re.compile(\n",
    "        r\"^(\\d+)?\\s*\"               # Number (optional)\n",
    "        r\"(BOMCO)\\s+(TRIPLEX)\\s+\"    # Model, Type\n",
    "        r\"(\\d+)?\\s*\"                # HHP (optional)\n",
    "        r\"(\\d+)\\s+\"                 # Efficiency\n",
    "        r\"([\\d.]+)\\s+\"              # Stroke\\(in\\)\n",
    "        r\"([\\d.]+)\\s+\"              # Liner\\(in\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Rating\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Limit\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # SPM Rating\n",
    "        r\"(\\d+)\\s*$\",               # SPM Limit\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    pumps = []\n",
    "    lines = ocr_text.splitlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        match = pump_pattern.match(line)\n",
    "        if match:\n",
    "            number, model, pump_type, hhp, efficiency, stroke, liner, p_rating, p_limit, spm_rating, spm_limit = match.groups()\n",
    "            pumps.append({\n",
    "                \"Number\": number if number else \"\",\n",
    "                \"Model\": model,\n",
    "                \"Type\": pump_type,\n",
    "                \"HHP\": hhp if hhp else \"\",\n",
    "                \"Efficiency\": efficiency,\n",
    "                \"Stroke(in)\": stroke,\n",
    "                \"Liner(in)\": liner,\n",
    "                \"P-Rating(psi)\": p_rating,\n",
    "                \"P-Limit(psi)\": p_limit,\n",
    "                \"SPM Rating\": spm_rating,\n",
    "                \"SPM Limit\": spm_limit\n",
    "            })\n",
    "    return pumps\n",
    "    \n",
    "def parse_drilling_circ_rates(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses drilling/circ rates from OCR text.\n",
    "    This version splits the text into segments starting with \"Drilling/Circ Rate <n>\"\n",
    "    then combines the lines in each segment and applies a regex with DOTALL.\n",
    "    \"\"\"\n",
    "    circ_rates = []\n",
    "    \n",
    "    # Split the OCR text into segments where each segment begins with \"Drilling/Circ Rate\" followed by a digit\n",
    "    segments = re.split(r\"(?=Drilling/Circ Rate \\d+)\", ocr_text)\n",
    "    \n",
    "    # Regex pattern to capture the numbers:\n",
    "    # Group 1: Rate ID (the number after \"Drilling/Circ Rate\")\n",
    "    # Group 2: Pressure (number preceding \"PS!\" or \"PSI\")\n",
    "    # Group 3: SPM value (number after \"@\")\n",
    "    # Group 4: Gal/Stoke value\n",
    "    # Group 5: GPM value\n",
    "    # Group 6: BPM value\n",
    "    # Group 7: DC value\n",
    "    # Group 8: DP value\n",
    "    pattern = re.compile(\n",
    "        r\"Drilling/Circ Rate\\s+(\\d+).*?\"       # Rate ID\n",
    "        r\"(\\d+)\\s+PS[!I].*?\"                   # Pressure\n",
    "        r\"@\\s*(\\d+).*?\"                        # SPM value\n",
    "        r\"([\\d.]+)\\s+Gal/Stoke.*?\"              # Gal/Stoke\n",
    "        r\"([\\d.]+)\\s+GPM.*?\"                    # GPM\n",
    "        r\"([\\d.]+)\\s+BPM.*?\"                    # BPM\n",
    "        r\"([\\d.]+)\\s+DC.*?\"                     # DC\n",
    "        r\"([\\d.]+)\\s+DP\",                      # DP\n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    \n",
    "    # Process each segment individually\n",
    "    for seg in segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg.startswith(\"Drilling/Circ Rate\"):\n",
    "            continue  # Skip any header or unrelated segments\n",
    "        # Replace newline characters with spaces to form a continuous string\n",
    "        seg_clean = \" \".join(seg.splitlines())\n",
    "        match = pattern.search(seg_clean)\n",
    "        if match:\n",
    "            rate_id, pressure, spm, gal_stroke, gpm, bpm, dc, dp = match.groups()\n",
    "            circ_rates.append({\n",
    "                \"RateID\": rate_id,\n",
    "                \"Pressure(PSI)\": pressure,\n",
    "                \"SPM\": spm,\n",
    "                \"Gal/Stoke\": gal_stroke,\n",
    "                \"GPM\": gpm,\n",
    "                \"BPM\": bpm,\n",
    "                \"DC\": dc,\n",
    "                \"DP\": dp\n",
    "            })\n",
    "        else:\n",
    "            # Optional: log a warning if no match is found for a segment\n",
    "            print(f\"Warning: No match found in segment:\\n{seg_clean}\")\n",
    "            \n",
    "    return circ_rates\n",
    "\n",
    "def process_pumps(pumps_img_path, debug=False):\n",
    "    \"\"\"\n",
    "    Processes the pumps section:\n",
    "      - Reads image using PIL,\n",
    "      - Performs OCR,\n",
    "      - Parses pumps table and drilling/circ rates,\n",
    "      - Returns combined results as JSON and a DataFrame.\n",
    "    \"\"\"\n",
    "    pil_img = read_pil_image(pumps_img_path)\n",
    "    ocr_text = perform_ocr(pil_img)\n",
    "    if debug:\n",
    "        logger.info(\"Pumps OCR Text:\\n\" + ocr_text)\n",
    "    pumps = parse_pumps_table(ocr_text)\n",
    "    circ_rates = parse_drilling_circ_rates(ocr_text)\n",
    "    final_data = {\"Pumps\": pumps, \"DrillingCircRates\": circ_rates}\n",
    "    df_pumps = pd.DataFrame(pumps)\n",
    "    df_circ = pd.DataFrame(circ_rates)\n",
    "    if not df_pumps.empty and not df_circ.empty:\n",
    "        df = pd.concat([df_pumps, df_circ], axis=0, ignore_index=True)\n",
    "    elif not df_pumps.empty:\n",
    "        df = df_pumps\n",
    "    else:\n",
    "        df = df_circ\n",
    "    return final_data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4188da6-427e-4f6d-936b-86f32525f112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 7) Time Breakdown process\n",
    "# ---------------------------------------------------------------------\n",
    "# def preprocess_image(img, debug=False):\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     if debug:\n",
    "#         show_image(\"1) Grayscale\", gray, cmap=\"gray\", size=(10,10))\n",
    "#     thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#                                    cv2.THRESH_BINARY, 15, 9)\n",
    "#     if debug:\n",
    "#         show_image(\"2) Adaptive Threshold\", thresh, cmap=\"gray\", size=(10,10))\n",
    "#     return thresh\n",
    "\n",
    "def detect_text_regions_tb(thresh_img, debug=True):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        show_image(\"3) Detected Text Regions\", debug_img, size=(12,12))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois_tb(img, rois, debug=True):\n",
    "    results = []\n",
    "    n = len(rois)\n",
    "    if debug and n > 0:\n",
    "        cols = 5\n",
    "        rows = math.ceil(n / cols)\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "        axes = axes.flatten() if rows > 1 else [axes]\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug and i < len(axes):\n",
    "            roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(roi_rgb)\n",
    "            axes[i].set_title(f\"ROI {i+1}\\n{text[:30]}...\")\n",
    "            axes[i].axis(\"off\")\n",
    "    if debug and n > 0:\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return results\n",
    "\n",
    "def group_ocr_rows(roi_results, y_threshold=20):\n",
    "    groups = []\n",
    "    roi_results_sorted = sorted(roi_results, key=lambda r: r[1])\n",
    "    current_group = []\n",
    "    current_y = None\n",
    "    for (x, y, w, h, text) in roi_results_sorted:\n",
    "        if current_y is None:\n",
    "            current_y = y\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        elif abs(y - current_y) <= y_threshold:\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [(x, y, w, h, text)]\n",
    "            current_y = y\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    return groups\n",
    "\n",
    "def parse_operations_description(ops_text):\n",
    "    ops_data = {\n",
    "        \"Depth\": {\"From\": \"\", \"To\": \"\"},\n",
    "        \"Performance\": {\"Feet\": \"\", \"FPH\": \"\"},\n",
    "        \"Rotation_Slide\": {\"Rotate\": \"\", \"Slide\": \"\"},\n",
    "        \"Rotation_Time\": {\"Rotate Time\": \"\", \"Slide Time\": \"\"},\n",
    "        \"GPM\": \"\",\n",
    "        \"MTR RPM\": \"\",\n",
    "        \"SPP\": \"\",\n",
    "        \"DIFF\": \"\",\n",
    "        \"WOB\": \"\",\n",
    "        \"ROT RPM\": \"\",\n",
    "        \"ON BTM TRQ\": \"\",\n",
    "        \"OFF BTM TRQ\": \"\",\n",
    "        \"GAS\": {\"Units\": \"\", \"Flare\": \"\"},\n",
    "        \"MW\": {\"In\": \"\", \"Out\": \"\"},\n",
    "        \"Targets\": [],\n",
    "        \"Observations\": []\n",
    "    }\n",
    "    depth_match = re.search(r\"F/\\s*([\\d,']+)\\s*T/\\s*([\\d,']+)\", ops_text, re.IGNORECASE)\n",
    "    if depth_match:\n",
    "        ops_data[\"Depth\"][\"From\"] = depth_match.group(1)\n",
    "        ops_data[\"Depth\"][\"To\"] = depth_match.group(2)\n",
    "    perf_match = re.search(r\"\\(([\\d,']+)\\s*@\\s*(\\d+)\\s*FPH\\)\", ops_text, re.IGNORECASE)\n",
    "    if perf_match:\n",
    "        ops_data[\"Performance\"][\"Feet\"] = perf_match.group(1)\n",
    "        ops_data[\"Performance\"][\"FPH\"] = perf_match.group(2)\n",
    "    rs_match = re.search(r\"ROTATE\\s*([\\d.]+%)\\s*/\\s*SLIDE\\s*([\\d.]+%)\", ops_text, re.IGNORECASE)\n",
    "    if rs_match:\n",
    "        ops_data[\"Rotation_Slide\"][\"Rotate\"] = rs_match.group(1)\n",
    "        ops_data[\"Rotation_Slide\"][\"Slide\"] = rs_match.group(2)\n",
    "    rt_match = re.search(r\"ROTATE\\s*TIME\\s*([\\d.]+%)\\s*/\\s*SLIDE\\s*TIME\\s*([\\d.]+%)\", ops_text, re.IGNORECASE)\n",
    "    if rt_match:\n",
    "        ops_data[\"Rotation_Time\"][\"Rotate Time\"] = rt_match.group(1)\n",
    "        ops_data[\"Rotation_Time\"][\"Slide Time\"] = rt_match.group(2)\n",
    "    numeric_patterns = {\n",
    "        \"GPM\": r\"GPM:\\s*(\\d+)\",\n",
    "        \"MTR RPM\": r\"MTR\\s*RPM:\\s*(\\d+)\",\n",
    "        \"SPP\": r\"SPP:\\s*([\\d,]+(?:-\\d+)?)(?:,|\\s|$)\",\n",
    "        \"DIFF\": r\"DIFF:\\s*([\\d\\-]+)\",\n",
    "        \"WOB\": r\"WOB:\\s*([\\d,]+(?:-\\d+)?)(?:,|\\s|$)\",\n",
    "        \"ROT RPM\": r\"ROT\\s*RPM:\\s*([\\d,]+(?:-\\d+)?)(?:,|\\s|$)\",\n",
    "        \"ON BTM TRQ\": r\"ON\\s*BTM\\s*TRQ[:;]?\\s*([\\d\\-K]+)\",\n",
    "        \"OFF BTM TRQ\": r\"OFF\\s*BTM\\s*TRQ[:;]?\\s*([\\d\\-K]+)\"\n",
    "    }\n",
    "    for key, pattern in numeric_patterns.items():\n",
    "        m = re.search(pattern, ops_text, re.IGNORECASE)\n",
    "        if m:\n",
    "            ops_data[key] = m.group(1)\n",
    "    gas_units = re.search(r\"GAS:\\s*([\\d,]+)\\s*UNITS\", ops_text, re.IGNORECASE)\n",
    "    if gas_units:\n",
    "        ops_data[\"GAS\"][\"Units\"] = gas_units.group(1)\n",
    "    flare = re.search(r\"(NO\\s*FLARE|FLARE\\s*ON|FLARE\\s*\\S+)\", ops_text, re.IGNORECASE)\n",
    "    if flare:\n",
    "        ops_data[\"GAS\"][\"Flare\"] = flare.group(1)\n",
    "    mw_match = re.search(r\"MW\\s*IN\\s*([\\d.+]+)\\s*PPG\\s*/\\s*OUT\\s*([\\d.+]+)\\s*PPG\", ops_text, re.IGNORECASE)\n",
    "    if mw_match:\n",
    "        ops_data[\"MW\"][\"In\"] = mw_match.group(1)\n",
    "        ops_data[\"MW\"][\"Out\"] = mw_match.group(2)\n",
    "    header_match = re.search(r\".*MW\\s*IN\\s*[\\d.+]+\\s*PPG\\s*/\\s*OUT\\s*[\\d.+]+\\s*PPG\\.\", ops_text, re.IGNORECASE)\n",
    "    if header_match:\n",
    "        residual = ops_text[header_match.end():]\n",
    "    else:\n",
    "        residual = ops_text\n",
    "    segments = re.split(r'(?=\\*\\*\\*)', residual)\n",
    "    obs_list = []\n",
    "    for seg in segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg:\n",
    "            continue\n",
    "        if not seg.startswith('***'):\n",
    "            parts = [p.strip() for p in seg.split('.') if p.strip()]\n",
    "            obs_list.extend(parts)\n",
    "        else:\n",
    "            obs_list.append(seg)\n",
    "    obs_list = [o.lstrip('* ').strip() for o in obs_list]\n",
    "    clean_obs = [o for o in obs_list if \"TARGET\" not in o.upper()]\n",
    "    targets = [o for o in obs_list if \"TARGET\" in o.upper()]\n",
    "    targets = [t.lstrip('* ').strip() for t in targets]\n",
    "    ops_data[\"Observations\"] = clean_obs\n",
    "    ops_data[\"Targets\"] = targets\n",
    "    return ops_data\n",
    "\n",
    "def parse_row_text(row_text):\n",
    "    clean_text = \" \".join(row_text.split())\n",
    "    if \"Daily Hrs\" in clean_text:\n",
    "        pattern = r\"Daily Hrs\\s+(\\S+)\\s+Daily NPT Hrs\\s*(\\S*)\\s+Total Job NPT Hours\\s+(\\S+)\"\n",
    "        m = re.search(pattern, clean_text, re.IGNORECASE)\n",
    "        if m:\n",
    "            return {\n",
    "                \"Daily Summary\": {\n",
    "                    \"Daily Hrs\": m.group(1),\n",
    "                    \"Daily NPT Hrs\": m.group(2),\n",
    "                    \"Total Job NPT Hours\": m.group(3)\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            logger.warning(f\"Daily summary row detected but could not parse: {clean_text}\")\n",
    "            return None\n",
    "    tokens = clean_text.split()\n",
    "    if not tokens or not re.match(r\"\\d{2}:\\d{2}\", tokens[0]):\n",
    "        logger.info(f\"Skipping header or invalid row: {clean_text}\")\n",
    "        return None\n",
    "    if len(tokens) < 8:\n",
    "        logger.warning(f\"Row does not have enough tokens: {clean_text}\")\n",
    "        return None\n",
    "    from_time = tokens[0]\n",
    "    to_time = tokens[1]\n",
    "    hours = tokens[2]\n",
    "    depth_start = tokens[3]\n",
    "    depth_end = tokens[4]\n",
    "    header_rest = \" \".join(tokens[5:])\n",
    "    m = re.search(r\"^(?P<phase>.+?)\\s+(?P<activity>DR[-]?Drilling)\\s+(?P<ops>.*)$\", header_rest, re.IGNORECASE)\n",
    "    if m:\n",
    "        phase = m.group(\"phase\")\n",
    "        activity = m.group(\"activity\")\n",
    "        ops = m.group(\"ops\")\n",
    "    else:\n",
    "        phase = tokens[5]\n",
    "        activity = tokens[6] if len(tokens) > 6 else \"\"\n",
    "        ops = \" \".join(tokens[7:]) if len(tokens) > 7 else \"\"\n",
    "    return {\n",
    "        \"From\": from_time,\n",
    "        \"To\": to_time,\n",
    "        \"Hours\": hours,\n",
    "        \"Depth Start\": depth_start,\n",
    "        \"Depth End\": depth_end,\n",
    "        \"Phase\": phase,\n",
    "        \"Activity\": activity,\n",
    "        \"Operations Description\": parse_operations_description(ops)\n",
    "    }\n",
    "\n",
    "def parse_all_rows_from_text(full_text):\n",
    "    if re.search(r\"\\d{2}:\\d{2}\\s+\\d{2}:\\d{2}\", full_text):\n",
    "        row_chunks = re.split(r\"(?=\\d{2}:\\d{2}\\s+\\d{2}:\\d{2})\", full_text)\n",
    "        rows = []\n",
    "        for chunk in row_chunks:\n",
    "            chunk = chunk.strip()\n",
    "            if not chunk:\n",
    "                continue\n",
    "            row = parse_row_text(chunk)\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "        return rows\n",
    "    else:\n",
    "        fallback_row = {\n",
    "            \"From\": \"\",\n",
    "            \"To\": \"\",\n",
    "            \"Hours\": \"\",\n",
    "            \"Depth Start\": \"\",\n",
    "            \"Depth End\": \"\",\n",
    "            \"Phase\": \"\",\n",
    "            \"Activity\": \"\",\n",
    "            \"Operations Description\": parse_operations_description(full_text)\n",
    "        }\n",
    "        return [fallback_row]\n",
    "\n",
    "def parse_all_rows_from_ocr_groups(roi_results):\n",
    "    rows = []\n",
    "    groups = group_ocr_rows(roi_results, y_threshold=20)\n",
    "    for group in groups:\n",
    "        group_sorted = sorted(group, key=lambda r: r[0])\n",
    "        row_text = \" \".join([text for (x, y, w, h, text) in group_sorted])\n",
    "        if any(kw in row_text.upper() for kw in [\"TIME PERIOD\", \"FROM TO\", \"DEPTH PHASE\", \"OPERATIONS DESCRIPTION\"]):\n",
    "            continue\n",
    "        parsed_row = parse_row_text(row_text)\n",
    "        if parsed_row:\n",
    "            rows.append(parsed_row)\n",
    "    return rows\n",
    "\n",
    "def main_time_breakdown_process(img_path, debug=False):\n",
    "    img_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_14.png\"\n",
    "    try:\n",
    "        img = safe_read_image(img_path)\n",
    "        logger.info(\"Time Breakdown image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    rois = detect_text_regions_tb(thresh_img, debug=True)\n",
    "    roi_ocr_results = perform_ocr_on_rois_tb(img, rois, debug=True)\n",
    "    time_breakdown_list = parse_all_rows_from_ocr_groups(roi_ocr_results)\n",
    "    if not time_breakdown_list:\n",
    "        logger.warning(\"No rows detected from ROI grouping. Falling back to full-image OCR.\")\n",
    "        full_text = pytesseract.image_to_string(thresh_img, config=\"--psm 6\")\n",
    "        time_breakdown_list = parse_all_rows_from_text(full_text)\n",
    "    if not time_breakdown_list:\n",
    "        logger.error(\"No rows were detected. Please check the OCR output and header format.\")\n",
    "        return\n",
    "    final_output = {\"TIME BREAKDOWN\": time_breakdown_list}\n",
    "    logger.info(\"===== FINAL TIME BREAKDOWN DATA =====\")\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    df = pd.json_normalize(final_output[\"TIME BREAKDOWN\"])\n",
    "    print(\"----- Extracted Time Breakdown DataFrame -----\")\n",
    "    print(df)\n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_time_breakdown_results\"\n",
    "    local_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_folder, exist_ok=True)\n",
    "    out_json = os.path.join(local_folder, \"time_breakdown_data.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    logger.info(f\"Time Breakdown JSON saved to {out_json}\")\n",
    "    out_csv = os.path.join(local_folder, \"time_breakdown_data.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    logger.info(f\"Time Breakdown CSV saved to {out_csv}\")\n",
    "    return final_output, df\n",
    "\n",
    "def merge_time_breakdown_data(main_data, continuation_data):\n",
    "    return main_data + continuation_data\n",
    "\n",
    "def process_time_breakdown_image(img_path, debug=False):\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh_img = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions_tb(thresh_img, debug=debug)\n",
    "    roi_ocr_results = perform_ocr_on_rois_tb(img, rois, debug=debug)\n",
    "    rows = parse_all_rows_from_ocr_groups(roi_ocr_results)\n",
    "    if not rows:\n",
    "        full_text = pytesseract.image_to_string(thresh_img, config=\"--psm 6\")\n",
    "        rows = parse_all_rows_from_text(full_text)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb537ed-6e2c-40c8-a8e4-fe5d6eb4ffd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- BHA ---\n",
    "def extract_bha_data(image_path, debug=False):\n",
    "    # Read using PIL for BHA extraction\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pat in patterns.items():\n",
    "        m = re.search(pat, ocr_text)\n",
    "        if m:\n",
    "            bha_data[key] = m.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for rem in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if rem in bha_data:\n",
    "                detail = re.sub(rf\"{rem}:\\s*{re.escape(bha_data[rem])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    if debug:\n",
    "        logger.info(\"Extracted BHA data:\")\n",
    "        logger.info(json.dumps(structured, indent=4))\n",
    "    return structured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb3175c-69ed-4bbe-9284-b89bc295263a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility Functions\n",
    "# ---------------------------------------------------------------------\n",
    "def dbfs_to_local_path(dbfs_path):\n",
    "    \"\"\"Converts a DBFS path to a local path.\"\"\"\n",
    "    return dbfs_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"Read an image from a DBFS path using OpenCV.\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found at {image_path}\")\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to read image from {image_path}\")\n",
    "    return img\n",
    "\n",
    "def save_output(section_name, data_json, df, output_folder):\n",
    "    \"\"\"Save JSON and CSV output files for a section.\"\"\"\n",
    "    file_base = section_name.lower().replace(\" \", \"_\").replace(\":\", \"\").replace(\"&\", \"and\")\n",
    "    json_path = os.path.join(output_folder, f\"{file_base}_data.json\")\n",
    "    csv_path = os.path.join(output_folder, f\"{file_base}_data.csv\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data_json, f, indent=4)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    logger.info(f\"{section_name} output saved to:\\n JSON: {json_path}\\n CSV: {csv_path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# OCR and Image Processing Functions\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(image, debug=False):\n",
    "    \"\"\"\n",
    "    Preprocess the image for OCR by converting it to grayscale and applying a binary threshold.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "    if debug:\n",
    "        logger.info(\"Image preprocessed for OCR.\")\n",
    "    return thresh\n",
    "\n",
    "def detect_text_regions(image, debug=False):\n",
    "    \"\"\"\n",
    "    Stub for detecting text regions. For demonstration, returns the entire image as one ROI.\n",
    "    A production implementation might use contours or deep learning.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    # Each ROI tuple: (x, y, width, height, dummy_text)\n",
    "    roi = (0, 0, w, h, \"dummy\")\n",
    "    if debug:\n",
    "        logger.info(\"Text region detection completed (stub).\")\n",
    "    return [roi]\n",
    "\n",
    "def perform_ocr(image):\n",
    "    \"\"\"\n",
    "    Performs OCR on the provided image using pytesseract.\n",
    "    \"\"\"\n",
    "    config = \"--oem 3 --psm 6\"\n",
    "    return pytesseract.image_to_string(image, config=config)\n",
    "\n",
    "def perform_ocr_on_rois(image, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each region of interest (ROI).\n",
    "    \"\"\"\n",
    "    roi_texts = []\n",
    "    for (x, y, w, h, _) in rois:\n",
    "        roi_img = image[y:y+h, x:x+w]\n",
    "        text = perform_ocr(roi_img)\n",
    "        roi_texts.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR performed on ROI at ({x}, {y}, {w}, {h}).\")\n",
    "    return roi_texts\n",
    "\n",
    "def annotate_ocr_results(image, roi_texts, debug_path=\"/dbfs/mnt/mini-proj-dd/final_ocr_results/debug_annotated.png\"):\n",
    "    \"\"\"\n",
    "    Annotate the original image with bounding boxes for each ROI and save the debug image.\n",
    "    \"\"\"\n",
    "    annotated = image.copy()\n",
    "    for (x, y, w, h, _) in roi_texts:\n",
    "        cv2.rectangle(annotated, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    cv2.imwrite(debug_path, annotated)\n",
    "    logger.info(f\"Annotated OCR results saved to: {debug_path}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Table-Specific Processing Functions\n",
    "# ---------------------------------------------------------------------\n",
    "def build_bit_info_dict_from_rois(roi_texts, debug=False):\n",
    "    \"\"\"\n",
    "    Custom parsing for a multi-row header table.\n",
    "    Expects:\n",
    "      - Row 0: Table title\n",
    "      - Row 1: Super headers\n",
    "      - Row 2: Sub-headers\n",
    "      - Row 3+: Data rows\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    grouped_rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    # Group bounding boxes by similar y-coordinate\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            grouped_rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        grouped_rows.append(current_row)\n",
    "\n",
    "    # Merge each row group into a single string\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(grouped_rows):\n",
    "        row.sort(key=lambda c: c[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        line = line.replace(\"\\n\", \" \").strip()\n",
    "        row_strings.append(line)\n",
    "        if debug:\n",
    "            logger.info(f\"Row {i}: {line}\")\n",
    "\n",
    "    if len(row_strings) < 3:\n",
    "        logger.warning(\"Not enough rows found for table layout.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # Assume row 0 is the title, row 1 is super headers, row 2 is sub-headers\n",
    "    data_lines = row_strings[3:]\n",
    "    \n",
    "    # Define final columns (5 + 2 + 4 + 2 + 8 = 21 columns)\n",
    "    final_columns = [\n",
    "        \"Bit #\", \"Size\", \"Make\", \"Model\", \"Serial #\",         # 5\n",
    "        \"Nozzle-(Number x Size)\", \"Nozzle-TFA\",                # 2\n",
    "        \"Depth-In\", \"Depth-Out\", \"Depth-Feet\", \"Depth-ROP\",    # 4\n",
    "        \"Hours-Total\", \"Hours-On Btm\",                         # 2\n",
    "        \"Dull Grade-I\", \"Dull Grade-O1\", \"Dull Grade-D\", \"Dull Grade-L\", \n",
    "        \"Dull Grade-B\", \"Dull Grade-G\", \"Dull Grade-O2\", \"Dull Grade-RP\"  # 8\n",
    "    ]\n",
    "\n",
    "    structured_data = []\n",
    "    for line in data_lines:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) < 21:\n",
    "            tokens += [\"\"] * (21 - len(tokens))\n",
    "        elif len(tokens) > 21:\n",
    "            tokens = tokens[:21]\n",
    "        row_dict = {final_columns[i]: tokens[i] for i in range(21)}\n",
    "        structured_data.append(row_dict)\n",
    "        if debug:\n",
    "            logger.info(f\"Parsed row: {row_dict}\")\n",
    "\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    # Optionally save CSV/JSON for debugging purposes here if needed.\n",
    "    return structured_data, df\n",
    "\n",
    "def process_bha(image_path, debug=False):\n",
    "    # For BHA, using your extract_bha_data implementation\n",
    "    bha_data = extract_bha_data(image_path, debug=debug)\n",
    "    df = pd.json_normalize(bha_data[\"BHA\"])\n",
    "    return bha_data, df\n",
    "\n",
    "def extract_bha_data(image_path, debug=False):\n",
    "    \"\"\"\n",
    "    Extract BHA data using pytesseract. Adjust patterns as needed.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pat in patterns.items():\n",
    "        m = re.search(pat, ocr_text)\n",
    "        if m:\n",
    "            bha_data[key] = m.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for rem in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if rem in bha_data:\n",
    "                detail = re.sub(rf\"{rem}:\\s*{re.escape(bha_data[rem])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    if debug:\n",
    "        logger.info(\"Extracted BHA data:\")\n",
    "        logger.info(json.dumps(structured, indent=4))\n",
    "    return structured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6312f4c-c0fe-4dd3-8c7e-30516f91e826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4ba698-1fc2-4906-9bba-67a6ae1a085c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_mud_data(img_path, debug=False):\n",
    "    logger.info(f\"Processing MUD data from image: {img_path}\")\n",
    "\n",
    "    # Step 1: Read the image\n",
    "    img = safe_read_image(img_path)\n",
    "    if img is None:\n",
    "        logger.error(f\"Failed to read image: {img_path}\")\n",
    "        return {\"MUD\": {}}, pd.DataFrame()\n",
    "\n",
    "    # Step 2: Preprocess Image\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    if thresh is None:\n",
    "        logger.error(\"Image preprocessing failed\")\n",
    "        return {\"MUD\": {}}, pd.DataFrame()\n",
    "\n",
    "    # Step 3: Detect Text Regions (ROI)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    if not rois:\n",
    "        logger.error(\"No text regions detected in image\")\n",
    "        return {\"MUD\": {}}, pd.DataFrame()\n",
    "\n",
    "    # Step 4: OCR Extraction\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    if not roi_texts:\n",
    "        logger.error(\"OCR failed, extracted no text.\")\n",
    "        return {\"MUD\": {}}, pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Extracted {len(roi_texts)} OCR text regions.\")\n",
    "\n",
    "    expected_headers = [\n",
    "        \"Type\", \"Weight In\", \"Weight Out\", \"pH\", \"CAKE\",\n",
    "        \"GELS (10s/10m/30m)\", \"Oil/Water\", \"FV\", \"ES\", \"PV\",\n",
    "        \"YP\", \"CL\", \"Ca\", \"LGS\", \"WL\", \"HTHP Loss\", \"3 RPM\",\n",
    "        \"6 RPM\", \"Mud Pits and Hole Volume\", \"24 Hr Loss\",\n",
    "        \"Total Loss\", \"Comments\"\n",
    "    ]\n",
    "\n",
    "    # Step 5: Build MUD dictionary\n",
    "    mud_dict = build_mud_dict_from_rois(roi_texts, expected_headers)\n",
    "    if not mud_dict:\n",
    "        logger.warning(\"MUD dictionary is empty!\")\n",
    "\n",
    "    # Step 6: Convert to DataFrame\n",
    "    df = pd.DataFrame(list(mud_dict.items()), columns=[\"Key\", \"Value\"])\n",
    "    \n",
    "    logger.info(f\"Final MUD Data: {mud_dict}\")\n",
    "    return {\"MUD\": mud_dict}, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d6f917-5b2d-45f7-b582-136114dcba40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def detect_text_regions_casing(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image for CASING.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        show_image(\"CASING Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "def build_casing_dict_from_rois(roi_texts, expected_headers, debug=False):\n",
    "    \"\"\"\n",
    "    Processes the OCR output for CASING, grouping text lines and mapping tokens to the expected headers.\n",
    "    \"\"\"\n",
    "    # Group OCR results into row strings using your existing group_ocr_results utility\n",
    "    row_strings = group_ocr_results(roi_texts)\n",
    "    data_lines = []\n",
    "\n",
    "    # Process each row and split into tokens\n",
    "    for line in row_strings:\n",
    "        for sub in line.split(\"\\n\"):\n",
    "            sub = sub.strip()\n",
    "            if not sub:\n",
    "                continue\n",
    "            # Use multiple spaces to split; fallback to split() if necessary\n",
    "            tokens = re.split(r'\\s{2,}', sub)\n",
    "            if len(tokens) == 1:\n",
    "                tokens = sub.split()\n",
    "\n",
    "            lower_tokens = [t.lower() for t in tokens]\n",
    "            # Skip header lines that contain both \"type\" and \"size\"\n",
    "            if \"type\" in lower_tokens and \"size\" in lower_tokens:\n",
    "                logger.info(f\"CASING - Skipping header line: {tokens}\")\n",
    "                continue\n",
    "\n",
    "            # Ensure the token count matches the expected headers by padding or trimming\n",
    "            if len(tokens) < len(expected_headers):\n",
    "                logger.warning(f\"CASING - Line has fewer tokens than expected ({len(tokens)} vs {len(expected_headers)}). Padding.\")\n",
    "                tokens += [''] * (len(expected_headers) - len(tokens))\n",
    "            elif len(tokens) > len(expected_headers):\n",
    "                logger.warning(f\"CASING - Line has more tokens than expected ({len(tokens)} vs {len(expected_headers)}). Trimming.\")\n",
    "                tokens = tokens[:len(expected_headers)]\n",
    "\n",
    "            data_lines.append(tokens)\n",
    "\n",
    "    # Build a list of dictionaries for each data row\n",
    "    casing_list = [\n",
    "        {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        for tokens in data_lines\n",
    "    ]\n",
    "    return casing_list\n",
    "\n",
    "def process_casing_data(img_path, debug=False):\n",
    "    \"\"\"\n",
    "    Processes CASING section data:\n",
    "      - Reads and preprocesses the image.\n",
    "      - Detects text regions.\n",
    "      - Performs OCR.\n",
    "      - Extracts CASING data into structured JSON and a DataFrame.\n",
    "    \"\"\"\n",
    "    expected_headers = [\"Type\", \"Size\", \"Weight\", \"Grade\", \"Connection\", \"Top MD\", \"Bottom MD\", \"TOC\"]\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions_casing(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    casing_list = build_casing_dict_from_rois(roi_texts, expected_headers, debug=debug)\n",
    "    df = pd.DataFrame(casing_list)\n",
    "    logger.info(f\"CASING DataFrame shape: {df.shape}\")\n",
    "    return {\"CASING\": casing_list}, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8036db04-760f-4182-aa9e-5fc2b46f9f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:WELL/JOB INFORMATION processing failed: [Errno 2] No such file or directory: '/dbfs/mnt/mini-proj-dd/final_results/well/job_information_data.json'\nERROR:__main__:No data row found for header1!\nWARNING:__main__:MUD dictionary is empty!\nWARNING:__main__:No bounding box after 'Daily Cumulative'.\nWARNING:__main__:Not enough rows found for table layout.\nERROR:__main__:DRILL BITS processing failed: cannot unpack non-iterable NoneType object\nERROR:__main__:CASING processing failed: not enough values to unpack (expected 5, got 4)\nERROR:__main__:BOP processing failed: too many values to unpack (expected 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: []\nIndex: []\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Row has unexpected number of numeric tokens: PERSONNEL PERSONNEL |\nERROR:__main__:BHA processing failed: [Errno 2] No such file or directory: '/Workspace/Repos/divya.dhaipullay@zeussolutionsinc.com/automate_ddr/dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png'\nERROR:__main__:PUMPS processing failed: name 'read_pil_image' is not defined\nERROR:__main__:TIME BREAKDOWN processing failed: name 'show_image' is not defined\nERROR:__main__:CONSUMABLES processing failed: not enough values to unpack (expected 5, got 4)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Aggregated JSON Output -----\n{\n    \"DAILY DRILLING REPORT\": {\n        \"Report Date\": \"7/4/2024\",\n        \"Report Num\": \"11\",\n        \"Rig\": \"Cyclone 39\"\n    },\n    \"WELL/JOB INFORMATION\": {\n        \"Well Name\": \"Ross Fee 4371-31-7-15 MH\",\n        \"Job Name\": \"Drilling\",\n        \"Supervisor(s)\": \"CHAD MILLER / ED COOLEY\",\n        \"Field\": \"XBE\",\n        \"Sec/Twn/Rng\": \"31, 43N, 71W\",\n        \"Phone\": \"307-315-1908\",\n        \"AFE #\": \"240098\",\n        \"API #\": \"49-005-78911\",\n        \"Email\": \"cyclone39@aec-denver.com\",\n        \"Contractor\": \"\",\n        \"Elevation\": \"4913.5\",\n        \"RKB\": \"27.5\",\n        \"Spud Date\": \"6/4/2024\",\n        \"Days from Spud\": \"7.67\",\n        \"Days on Loc\": \"34\",\n        \"MD/TVD\": \"20537 FT/10719 FT\",\n        \"24 Hr Footage\": \"3068\",\n        \"Present Operations\": \"DRILLING LATERAL @ 20,537'.\",\n        \"Activity Planned\": \"DRILL LATERAL SECTION TO PLANNED TD @ ~21,226', PUMP TD SWEEPS & CHC, SOOH & L/D DRILL PIPE.\"\n    },\n    \"MUD\": {},\n    \"SURVEY DATA\": [\n        {\n            \"MD\": \"20,286\",\n            \"Inclination\": \"89.20\",\n            \"Azimuth\": \"179.98\",\n            \"DLS\": \"0.67\",\n            \"TVD\": \"10,716\"\n        },\n        {\n            \"MD\": \"20,191\",\n            \"Inclination\": \"89.23\",\n            \"Azimuth\": \"179.34\",\n            \"DLS\": \"0.51\",\n            \"TVD\": \"10,715\"\n        },\n        {\n            \"MD\": \"20,096\",\n            \"Inclination\": \"89.65\",\n            \"Azimuth\": \"179.59\",\n            \"DLS\": \"0.55\",\n            \"TVD\": \"10,714\"\n        },\n        {\n            \"MD\": \"20,001\",\n            \"Inclination\": \"89.65\",\n            \"Azimuth\": \"180.11\",\n            \"DLS\": \"0.34\",\n            \"TVD\": \"10,714\"\n        },\n        {\n            \"MD\": \"19,906\",\n            \"Inclination\": \"89.76\",\n            \"Azimuth\": \"179.81\",\n            \"DLS\": \"0.15\",\n            \"TVD\": \"10,713\"\n        }\n    ],\n    \"DIR INFO\": {},\n    \"PERSONNEL\": [\n        {\n            \"Company\": \"WORKRISE\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 2,\n            \"Daily Hours\": 24,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"Cyclone Drilling Days Crews\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 7,\n            \"Daily Hours\": 84,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"Cyclone Drilling Night Crews\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 7,\n            \"Daily Hours\": 84,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"DCT\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 2,\n            \"Daily Hours\": 24,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"\",\n            \"Contractor\": \"\",\n            \"No. Personnel\": \"Totals\",\n            \"Daily Hours\": 347,\n            \"Cumulative Hours\": \"3069.0\"\n        }\n    ],\n    \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": [\n        {\n            \"Type\": \"DAILY NUMBERS: OBSERVATION & INTERVENTION\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Number\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Stop Cards\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Isa\\u2019\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"PermittoWork SS\",\n            \"Number\": \"\"\n        }\n    ],\n    \"COST DATA\": {\n        \"Drilling AFE Amount\": null,\n        \"Daily Drilling Cost\": \"$167,006.63\",\n        \"Cumulative Drilling Cost\": \"$1,747,745\",\n        \"Cumulative Well Cost\": \"$1,914,752\",\n        \"Daily Mud Cost\": \"$54,185.80\",\n        \"Cumulative Mud Cost\": \"$299,370.66\"\n    }\n}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Main Process Runner\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    debug = False  # Set True to enable debugging output\n",
    "    # Define DBFS image paths for each section\n",
    "    image_paths = {\n",
    "        \"DAILY DRILLING REPORT\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_1.png\",\n",
    "        \"WELL/JOB INFORMATION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_2.png\",\n",
    "        \"MUD\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\",\n",
    "        \"SURVEY DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_4.png\",\n",
    "        \"DIR INFO\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_5.png\",\n",
    "        \"DRILL BITS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_6.png\",\n",
    "        \"CASING\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_7.png\",\n",
    "        \"BOP\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_8.png\",\n",
    "        \"PERSONNEL\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_9.png\",\n",
    "        \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_10.png\",\n",
    "        \"BHA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png\",\n",
    "        \"PUMPS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_12.png\",\n",
    "        \"COST DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\",\n",
    "        \"TIME BREAKDOWN\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_14.png\",\n",
    "        \"CONSUMABLES\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_2_section_2.png\"\n",
    "    }\n",
    "    \n",
    "    # Define output folder using DBFS path directly\n",
    "    output_folder = dbfs_to_local_path(\"dbfs:/mnt/mini-proj-dd/final_results\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    aggregated_json = {}\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    \n",
    "    # Define processing order for sections\n",
    "    processes = [\n",
    "        (\"DAILY DRILLING REPORT\", process_daily_drilling_report, image_paths.get(\"DAILY DRILLING REPORT\")),\n",
    "        (\"WELL/JOB INFORMATION\", process_well_job_info, image_paths.get(\"WELL/JOB INFORMATION\")),\n",
    "        (\"MUD\", process_mud_data, image_paths.get(\"MUD\")),\n",
    "        (\"SURVEY DATA\", process_survey, image_paths.get(\"SURVEY DATA\")),\n",
    "        (\"DIR INFO\", process_dir_info, image_paths.get(\"DIR INFO\")),\n",
    "        (\"DRILL BITS\", process_drill_bits, image_paths.get(\"DRILL BITS\")),\n",
    "        (\"CASING\", process_casing_data, image_paths.get(\"CASING\")),\n",
    "        (\"BOP\", process_bop, image_paths.get(\"BOP\")),\n",
    "        (\"PERSONNEL\", process_personnel, image_paths.get(\"PERSONNEL\")),\n",
    "        (\"DAILY NUMBERS: OBSERVATION & INTERVENTION\", process_obs_int, image_paths.get(\"DAILY NUMBERS: OBSERVATION & INTERVENTION\")),\n",
    "        (\"BHA\", process_bha, image_paths.get(\"BHA\")),\n",
    "        (\"PUMPS\", process_pumps, image_paths.get(\"PUMPS\")),\n",
    "        (\"COST DATA\", process_cost_data, image_paths.get(\"COST DATA\")),\n",
    "        (\"TIME BREAKDOWN\", main_time_breakdown_process, image_paths.get(\"TIME BREAKDOWN\")),\n",
    "        (\"CONSUMABLES\", process_consumables_data, image_paths.get(\"CONSUMABLES\"))\n",
    "    ]\n",
    "    \n",
    "    for section, func, img_path in processes:\n",
    "        try:\n",
    "            logger.info(f\"Processing section: {section}\")\n",
    "            if img_path:\n",
    "                data_json, df = func(img_path, debug)\n",
    "            else:\n",
    "                data_json, df = func(debug)\n",
    "            # For consistency, use the section key from the returned JSON if present.\n",
    "            aggregated_json[section] = data_json.get(section, data_json)\n",
    "            aggregated_df = pd.concat([aggregated_df, df], ignore_index=True)\n",
    "            logger.info(f\"{section} output:\\n{json.dumps(data_json, indent=4)}\")\n",
    "            save_output(section, data_json, df, output_folder)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{section} processing failed: {e}\")\n",
    "    \n",
    "    # Save aggregated results\n",
    "    agg_json_path = os.path.join(output_folder, \"aggregated_data.json\")\n",
    "    with open(agg_json_path, \"w\") as f:\n",
    "        json.dump(aggregated_json, f, indent=4)\n",
    "    agg_csv_path = os.path.join(output_folder, \"aggregated_data.csv\")\n",
    "    aggregated_df.to_csv(agg_csv_path, index=False)\n",
    "    logger.info(f\"Aggregated JSON saved to: {agg_json_path}\")\n",
    "    # logger.info(f\"Aggregated CSV saved to: {agg_csv_path}\")\n",
    "    print(\"----- Aggregated JSON Output -----\")\n",
    "    print(json.dumps(aggregated_json, indent=4))\n",
    "    # print(\"----- Aggregated DataFrame -----\")\n",
    "    # print(aggregated_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a88c5608-a04f-426f-bf61-724495cc9ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:WELL/JOB INFORMATION processing failed: [Errno 2] No such file or directory: '/dbfs/mnt/mini-proj-dd/final_results/well/job_information_data.json'\nERROR:__main__:No data row found for header1!\nWARNING:__main__:MUD dictionary is empty!\nWARNING:__main__:No bounding box after 'Daily Cumulative'.\nWARNING:__main__:Not enough rows found for table layout.\nERROR:__main__:DRILL BITS processing failed: cannot unpack non-iterable NoneType object\nERROR:__main__:CASING processing failed: not enough values to unpack (expected 5, got 4)\nERROR:__main__:BOP processing failed: too many values to unpack (expected 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\nColumns: []\nIndex: []\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:Row has unexpected number of numeric tokens: PERSONNEL PERSONNEL |\nERROR:__main__:BHA processing failed: [Errno 2] No such file or directory: '/Workspace/Repos/divya.dhaipullay@zeussolutionsinc.com/automate_ddr/dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png'\nERROR:__main__:PUMPS processing failed: name 'read_pil_image' is not defined\nERROR:__main__:TIME BREAKDOWN processing failed: name 'show_image' is not defined\nERROR:__main__:CONSUMABLES processing failed: not enough values to unpack (expected 5, got 4)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Aggregated JSON Output -----\n{\n    \"DAILY DRILLING REPORT\": {\n        \"Report Date\": \"7/4/2024\",\n        \"Report Num\": \"11\",\n        \"Rig\": \"Cyclone 39\"\n    },\n    \"WELL/JOB INFORMATION\": {\n        \"Well Name\": \"Ross Fee 4371-31-7-15 MH\",\n        \"Job Name\": \"Drilling\",\n        \"Supervisor(s)\": \"CHAD MILLER / ED COOLEY\",\n        \"Field\": \"XBE\",\n        \"Sec/Twn/Rng\": \"31, 43N, 71W\",\n        \"Phone\": \"307-315-1908\",\n        \"AFE #\": \"240098\",\n        \"API #\": \"49-005-78911\",\n        \"Email\": \"cyclone39@aec-denver.com\",\n        \"Contractor\": \"\",\n        \"Elevation\": \"4913.5\",\n        \"RKB\": \"27.5\",\n        \"Spud Date\": \"6/4/2024\",\n        \"Days from Spud\": \"7.67\",\n        \"Days on Loc\": \"34\",\n        \"MD/TVD\": \"20537 FT/10719 FT\",\n        \"24 Hr Footage\": \"3068\",\n        \"Present Operations\": \"DRILLING LATERAL @ 20,537'.\",\n        \"Activity Planned\": \"DRILL LATERAL SECTION TO PLANNED TD @ ~21,226', PUMP TD SWEEPS & CHC, SOOH & L/D DRILL PIPE.\"\n    },\n    \"MUD\": {},\n    \"SURVEY DATA\": [\n        {\n            \"MD\": \"20,286\",\n            \"Inclination\": \"89.20\",\n            \"Azimuth\": \"179.98\",\n            \"DLS\": \"0.67\",\n            \"TVD\": \"10,716\"\n        },\n        {\n            \"MD\": \"20,191\",\n            \"Inclination\": \"89.23\",\n            \"Azimuth\": \"179.34\",\n            \"DLS\": \"0.51\",\n            \"TVD\": \"10,715\"\n        },\n        {\n            \"MD\": \"20,096\",\n            \"Inclination\": \"89.65\",\n            \"Azimuth\": \"179.59\",\n            \"DLS\": \"0.55\",\n            \"TVD\": \"10,714\"\n        },\n        {\n            \"MD\": \"20,001\",\n            \"Inclination\": \"89.65\",\n            \"Azimuth\": \"180.11\",\n            \"DLS\": \"0.34\",\n            \"TVD\": \"10,714\"\n        },\n        {\n            \"MD\": \"19,906\",\n            \"Inclination\": \"89.76\",\n            \"Azimuth\": \"179.81\",\n            \"DLS\": \"0.15\",\n            \"TVD\": \"10,713\"\n        }\n    ],\n    \"DIR INFO\": {},\n    \"PERSONNEL\": [\n        {\n            \"Company\": \"WORKRISE\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 2,\n            \"Daily Hours\": 24,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"Cyclone Drilling Days Crews\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 7,\n            \"Daily Hours\": 84,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"Cyclone Drilling Night Crews\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 7,\n            \"Daily Hours\": 84,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"DCT\",\n            \"Contractor\": \"Service Company\",\n            \"No. Personnel\": 2,\n            \"Daily Hours\": 24,\n            \"Cumulative Hours\": 2777\n        },\n        {\n            \"Company\": \"\",\n            \"Contractor\": \"\",\n            \"No. Personnel\": \"Totals\",\n            \"Daily Hours\": 347,\n            \"Cumulative Hours\": \"3069.0\"\n        }\n    ],\n    \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": [\n        {\n            \"Type\": \"DAILY NUMBERS: OBSERVATION & INTERVENTION\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Number\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Stop Cards\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"Isa\\u2019\",\n            \"Number\": \"\"\n        },\n        {\n            \"Type\": \"PermittoWork SS\",\n            \"Number\": \"\"\n        }\n    ],\n    \"COST DATA\": {\n        \"Drilling AFE Amount\": null,\n        \"Daily Drilling Cost\": \"$167,006.63\",\n        \"Cumulative Drilling Cost\": \"$1,747,745\",\n        \"Cumulative Well Cost\": \"$1,914,752\",\n        \"Daily Mud Cost\": \"$54,185.80\",\n        \"Cumulative Mud Cost\": \"$299,370.66\"\n    }\n}\n"
     ]
    }
   ],
   "source": [
    "def build_casing_dict_from_rois(roi_texts, expected_headers, debug=False):\n",
    "    # Group OCR results; ensure group_ocr_results is defined elsewhere.\n",
    "    row_strings = group_ocr_results(roi_texts)\n",
    "    logger.debug(f\"Grouped OCR results: {row_strings}\")\n",
    "    \n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for sub in line.split(\"\\n\"):\n",
    "            sub = sub.strip()\n",
    "            if sub:\n",
    "                all_lines.append(sub)\n",
    "    logger.debug(f\"All non-empty lines: {all_lines}\")\n",
    "\n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        # First try splitting on two or more spaces\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        logger.debug(f\"Processing line: '{line}' -> tokens: {tokens}\")\n",
    "\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        # Skip header lines\n",
    "        if \"type\" in lower_tokens and \"size\" in lower_tokens:\n",
    "            logger.info(f\"CASING - Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        \n",
    "        # If there are fewer tokens than expected, log a warning.\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"CASING - Line has fewer tokens than expected (got {len(tokens)}; expected {len(expected_headers)}): {tokens}\")\n",
    "            # Optionally, pad the tokens with empty strings\n",
    "            tokens = tokens + [\"\"] * (len(expected_headers) - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    \n",
    "    # Create a list of dictionaries using expected_headers as keys.\n",
    "    casing_list = [\n",
    "        {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        for tokens in data_lines\n",
    "    ]\n",
    "    logger.debug(f\"Final casing list: {casing_list}\")\n",
    "    return casing_list\n",
    "\n",
    "# def detect_text_regions_casing(thresh_img, debug=False):\n",
    "#     \"\"\"\n",
    "#     Detects text regions (bounding boxes) from the thresholded image.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error finding contours: {e}\")\n",
    "#         return []\n",
    "    \n",
    "#     rois = []\n",
    "#     for cnt in contours:\n",
    "#         try:\n",
    "#             # cv2.boundingRect should return (x, y, w, h)\n",
    "#             x, y, w, h = cv2.boundingRect(cnt)\n",
    "#         except Exception as e:\n",
    "#             logger.error(f\"Error unpacking boundingRect for contour {cnt}: {e}\")\n",
    "#             continue\n",
    "#         if w > 30 and h > 15:\n",
    "#             rois.append((x, y, w, h))\n",
    "#     # Sort by y (top-to-bottom) then by x (left-to-right)\n",
    "#     rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    \n",
    "#     if debug:\n",
    "#         debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "#         for (x, y, w, h) in rois:\n",
    "#             cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#         show_image(\"3) Detected Regions\", debug_img)\n",
    "    \n",
    "#     logger.debug(f\"Detected ROIs: {rois}\")\n",
    "#     return rois\n",
    "\n",
    "def detect_text_regions_casing(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error finding contours: {e}\")\n",
    "        return []\n",
    "    \n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        rect = cv2.boundingRect(cnt)\n",
    "        logger.debug(f\"Bounding rectangle: {rect} (length: {len(rect)})\")\n",
    "        # If rect length is not 4, log error and skip\n",
    "        if len(rect) != 4:\n",
    "            logger.error(f\"Unexpected bounding rectangle format: {rect}\")\n",
    "            continue\n",
    "        try:\n",
    "            x, y, w, h = rect\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error unpacking boundingRect {rect}: {e}\")\n",
    "            continue\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    # Sort by y (top-to-bottom) then by x (left-to-right)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    \n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    \n",
    "    logger.debug(f\"Detected ROIs: {rois}\")\n",
    "    return rois\n",
    "\n",
    "def process_casing_data(img_path, debug=False):\n",
    "    # Read image safely\n",
    "    img = safe_read_image(img_path)\n",
    "    # Preprocess image for thresholding\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    # Detect text regions\n",
    "    rois = detect_text_regions_casing(thresh, debug=debug)\n",
    "    logger.info(f\"Detected {len(rois)} text regions for CASING\")\n",
    "    # Perform OCR on detected regions; ensure perform_ocr_on_rois is defined elsewhere.\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    logger.debug(f\"OCR texts from ROIs: {roi_texts}\")\n",
    "    \n",
    "    expected_headers = [\"Type\", \"Size\", \"Weight\", \"Grade\", \"Connection\", \"Top MD\", \"Bottom MD\", \"TOC\"]\n",
    "    casing_list = build_casing_dict_from_rois(roi_texts, expected_headers, debug=debug)\n",
    "    \n",
    "    # Create a DataFrame from the casing list\n",
    "    df = pd.DataFrame(casing_list)\n",
    "    logger.info(f\"CASING DataFrame shape: {df.shape}\")\n",
    "    \n",
    "    return {\"CASING\": casing_list}, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Main Process Runner\n",
    "# ---------------------------------------------------------------------\n",
    "def main():\n",
    "    debug = False  # Set True to enable debugging output\n",
    "    \n",
    "    # Define DBFS image paths for each section\n",
    "    image_paths = {\n",
    "        \"DAILY DRILLING REPORT\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_1.png\",\n",
    "        \"WELL/JOB INFORMATION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_2.png\",\n",
    "        \"MUD\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\",\n",
    "        \"SURVEY DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_4.png\",\n",
    "        \"DIR INFO\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_5.png\",\n",
    "        \"DRILL BITS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_6.png\",\n",
    "        \"CASING\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_7.png\",\n",
    "        \"BOP\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_8.png\",\n",
    "        \"PERSONNEL\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_9.png\",\n",
    "        \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_10.png\",\n",
    "        \"BHA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png\",\n",
    "        \"PUMPS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_12.png\",\n",
    "        \"COST DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\",\n",
    "        \"TIME BREAKDOWN\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_14.png\",\n",
    "        \"CONSUMABLES\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_2_section_2.png\"\n",
    "    }\n",
    "    \n",
    "    # Define output folder using DBFS path directly\n",
    "    output_folder = dbfs_to_local_path(\"dbfs:/mnt/mini-proj-dd/final_results\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    aggregated_json = {}\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    \n",
    "    # Define processing order for sections\n",
    "    processes = [\n",
    "        (\"DAILY DRILLING REPORT\", process_daily_drilling_report, image_paths.get(\"DAILY DRILLING REPORT\")),\n",
    "        (\"WELL/JOB INFORMATION\", process_well_job_info, image_paths.get(\"WELL/JOB INFORMATION\")),\n",
    "        (\"MUD\", process_mud_data, image_paths.get(\"MUD\")),\n",
    "        (\"SURVEY DATA\", process_survey, image_paths.get(\"SURVEY DATA\")),\n",
    "        (\"DIR INFO\", process_dir_info, image_paths.get(\"DIR INFO\")),\n",
    "        (\"DRILL BITS\", process_drill_bits, image_paths.get(\"DRILL BITS\")),\n",
    "        (\"CASING\", process_casing_data, image_paths.get(\"CASING\")),\n",
    "        (\"BOP\", process_bop, image_paths.get(\"BOP\")),\n",
    "        (\"PERSONNEL\", process_personnel, image_paths.get(\"PERSONNEL\")),\n",
    "        (\"DAILY NUMBERS: OBSERVATION & INTERVENTION\", process_obs_int, image_paths.get(\"DAILY NUMBERS: OBSERVATION & INTERVENTION\")),\n",
    "        (\"BHA\", process_bha, image_paths.get(\"BHA\")),\n",
    "        (\"PUMPS\", process_pumps, image_paths.get(\"PUMPS\")),\n",
    "        (\"COST DATA\", process_cost_data, image_paths.get(\"COST DATA\")),\n",
    "        (\"TIME BREAKDOWN\", main_time_breakdown_process, image_paths.get(\"TIME BREAKDOWN\")),\n",
    "        (\"CONSUMABLES\", process_consumables_data, image_paths.get(\"CONSUMABLES\"))\n",
    "    ]\n",
    "    \n",
    "    for section, func, img_path in processes:\n",
    "        try:\n",
    "            logger.info(f\"Processing section: {section}\")\n",
    "            if img_path:\n",
    "                data_json, df = func(img_path, debug)\n",
    "            else:\n",
    "                data_json, df = func(debug)\n",
    "            \n",
    "            # For consistency, use the section key from the returned JSON if present.\n",
    "            aggregated_json[section] = data_json.get(section, data_json)\n",
    "            aggregated_df = pd.concat([aggregated_df, df], ignore_index=True)\n",
    "            logger.info(f\"{section} output:\\n{json.dumps(data_json, indent=4)}\")\n",
    "            save_output(section, data_json, df, output_folder)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{section} processing failed: {e}\")\n",
    "    \n",
    "    # Save aggregated results\n",
    "    agg_json_path = os.path.join(output_folder, \"aggregated_data.json\")\n",
    "    with open(agg_json_path, \"w\") as f:\n",
    "        json.dump(aggregated_json, f, indent=4)\n",
    "    agg_csv_path = os.path.join(output_folder, \"aggregated_data.csv\")\n",
    "    aggregated_df.to_csv(agg_csv_path, index=False)\n",
    "    logger.info(f\"Aggregated JSON saved to: {agg_json_path}\")\n",
    "    print(\"----- Aggregated JSON Output -----\")\n",
    "    print(json.dumps(aggregated_json, indent=4))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "125e5d89-79f7-471b-8486-7f73b88d7bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7760541951788028,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_final",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
