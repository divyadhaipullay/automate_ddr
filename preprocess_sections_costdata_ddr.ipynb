{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23ae4442-d27e-42fa-a3a9-54f383b31c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def copy_dbfs_to_local(dbfs_path, local_path):\n",
    "    \"\"\"\n",
    "    Copies a file from DBFS to a local path using Databricks utilities.\n",
    "    Only needed if your file is in dbfs:/; otherwise you can read directly from /dbfs/ path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dbutils.fs.cp(dbfs_path, f\"file:{local_path}\")\n",
    "        if not os.path.exists(local_path):\n",
    "            raise FileNotFoundError(f\"File was not copied properly to {local_path}\")\n",
    "        return local_path\n",
    "    except Exception as e:\n",
    "        raise FileNotFoundError(f\"Failed to copy from {dbfs_path} to {local_path}. Error: {e}\")\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "    Reads an image from the local file system path.\n",
    "    In Databricks, you can also do: image_path = '/dbfs/mnt/...'\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found at {image_path}\")\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Failed to read image file at {image_path}\")\n",
    "    return img\n",
    "\n",
    "def draw_bounding_box_and_crop(image, top_right_coords, debug_path=\"/dbfs/mnt/mini-proj-dd/final_ocr_results/debug_top_right.png\"):\n",
    "    \"\"\"\n",
    "    Draws the bounding box for the top-right region on the original image\n",
    "    and saves a debug image. Then returns the cropped region.\n",
    "    top_right_coords = (x, y, w, h).\n",
    "    \"\"\"\n",
    "    x, y, w, h = top_right_coords\n",
    "\n",
    "    # Draw a rectangle on a copy for debugging\n",
    "    debug_img = image.copy()\n",
    "    cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save debug image so you can see the bounding box\n",
    "    cv2.imwrite(debug_path, debug_img)\n",
    "    logger.info(f\"Debug image with bounding box saved to: {debug_path}\")\n",
    "\n",
    "    # Crop the top-right region\n",
    "    cropped = image[y:y+h, x:x+w]\n",
    "    return cropped\n",
    "\n",
    "def preprocess_image_for_ocr(image):\n",
    "    \"\"\"\n",
    "    Preprocesses the image for better OCR:\n",
    "    1) Grayscale\n",
    "    2) Histogram equalization\n",
    "    3) Gaussian blur\n",
    "    4) Adaptive threshold\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
    "    processed = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    return processed\n",
    "\n",
    "def perform_ocr(image):\n",
    "    \"\"\"\n",
    "    Performs OCR on the provided image with a recommended config.\n",
    "    \"\"\"\n",
    "    config = \"--oem 3 --psm 6\"  # OEM 3: LSTM, PSM 6: Assume a single uniform block\n",
    "    text = pytesseract.image_to_string(image, config=config)\n",
    "    return text\n",
    "\n",
    "def extract_key_value_from_text(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Extracts key-value pairs from the OCR text using expected keys.\n",
    "    If a key's value is empty, it assigns None.\n",
    "    \"\"\"\n",
    "    # Normalize text: remove extra spaces and combine lines\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    \n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value if value else None\n",
    "        else:\n",
    "            result[key] = None\n",
    "    return result\n",
    "\n",
    "def clean_report_num(report_num_str):\n",
    "    \"\"\"\n",
    "    Removes trailing punctuation from the extracted 'Report Num' if present.\n",
    "    Example: '11.' -> '11'\n",
    "    \"\"\"\n",
    "    if not report_num_str:\n",
    "        return report_num_str\n",
    "    # Use regex to capture digits, ignoring trailing punctuation\n",
    "    match = re.search(r'^(\\d+)\\.?$', report_num_str)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return report_num_str\n",
    "\n",
    "def main_pipeline():\n",
    "    # Path in DBFS. If you prefer direct read, set image_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_1.png\"\n",
    "    dbfs_image_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_1.png\"\n",
    "    local_image_path = \"/tmp/page_1_section_1.png\"\n",
    "\n",
    "    try:\n",
    "        # If your environment requires copying from DBFS to local:\n",
    "        copy_dbfs_to_local(dbfs_image_path, local_image_path)\n",
    "        img = read_image(local_image_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Adjust bounding box to isolate only the top-right area with 'Report Date', 'Report Num', 'Rig'\n",
    "    # Example coordinates: (1600, 0, 950, 185)  -> tune as needed\n",
    "    top_right_coords = (1600, 0, 950, 185)\n",
    "\n",
    "    # Draw bounding box, save debug image, then crop\n",
    "    cropped_section = draw_bounding_box_and_crop(\n",
    "        img,\n",
    "        top_right_coords,\n",
    "        debug_path=\"/dbfs/mnt/mini-proj-dd/final_ocr_results/debug_top_right.png\"\n",
    "    )\n",
    "\n",
    "    # Preprocess for OCR\n",
    "    processed_image = preprocess_image_for_ocr(cropped_section)\n",
    "    logger.info(\"Top-right image preprocessed for OCR.\")\n",
    "\n",
    "    # Perform OCR\n",
    "    ocr_text = perform_ocr(processed_image)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    # Extract expected keys\n",
    "    expected_keys = [\"Report Date\", \"Report Num\", \"Rig\"]\n",
    "    extracted = extract_key_value_from_text(ocr_text, expected_keys)\n",
    "\n",
    "    # Clean trailing punctuation from Report Num\n",
    "    if extracted[\"Report Num\"] is not None:\n",
    "        extracted[\"Report Num\"] = clean_report_num(extracted[\"Report Num\"])\n",
    "\n",
    "    # Construct final dictionary\n",
    "    final_dict = {\"DAILY DRILLING REPORT\": extracted}\n",
    "    logger.info(json.dumps(final_dict, indent=4))\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    # Save to CSV\n",
    "    df_final = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, \"page_1_section_ddr_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "176c6f41-f0ef-43f9-a197-eb715fb03f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"WellJobInfoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) OCR Extraction (Minimal Processing)\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Use psm 6: assume a uniform block of text\n",
    "    text = pytesseract.image_to_string(gray, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Expected Keys Extraction from Combined OCR Text\n",
    "# --------------------------------------------------------\n",
    "def extract_key_value_from_text(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Combines all OCR text lines into a single string and, using the expected keys\n",
    "    (in order), extracts each value as the text between the current key and the next key.\n",
    "    If a key is not found, an empty string is returned.\n",
    "    \"\"\"\n",
    "    # Combine all non-empty lines into one string.\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    # Normalize whitespace.\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*?)\\s*(?=' + re.escape(next_key) + r'\\s*:)'\n",
    "        else:\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*)$'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value\n",
    "        else:\n",
    "            result[key] = \"\"\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_2.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    # Define the exact expected keys (in the desired order)\n",
    "    expected_keys = [\n",
    "        \"Well Name\",\n",
    "        \"Job Name\",\n",
    "        \"Supervisor(s)\",\n",
    "        \"Field\",\n",
    "        \"Sec/Twn/Rng\",\n",
    "        \"Phone\",\n",
    "        \"AFE #\",\n",
    "        \"API #\",\n",
    "        \"Email\",\n",
    "        \"Contractor\",\n",
    "        \"Elevation\",\n",
    "        \"RKB\",\n",
    "        \"Spud Date\",\n",
    "        \"Days from Spud\",\n",
    "        \"Days on Loc\",\n",
    "        \"MD/TVD\",\n",
    "        \"24 Hr Footage\",\n",
    "        \"Present Operations\",\n",
    "        \"Activity Planned\"\n",
    "    ]\n",
    "\n",
    "    extracted = extract_key_value_from_text(ocr_text, expected_keys)\n",
    "    final_dict = {\"WELL/JOB INFORMATION\": extracted}\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    local_output_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(local_output_folder, \"page_1_section_2_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc82f3c-f8c7-466c-93f0-94da55029e39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"WellJobInfoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) OCR Extraction (Minimal Processing)\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Extract BOP Information\n",
    "# --------------------------------------------------------\n",
    "def extract_bop_info(text):\n",
    "    pattern = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in pattern.items():\n",
    "        match = re.search(regex, text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_8.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    extracted_bop = extract_bop_info(ocr_text)\n",
    "    final_dict = {\"BOP\": extracted_bop}\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted_bop.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    local_output_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(local_output_folder, \"page_1_section_8_bop_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9abff60d-7207-42ec-bd8b-d4ab78c6716c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"WellJobInfoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) OCR Extraction (Minimal Processing)\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "    \n",
    "def extract_key_value_from_text(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Extracts key-value pairs from the text, ensuring that keys with empty values\n",
    "    are correctly detected instead of capturing the next key as their value.\n",
    "    \"\"\"\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)  # Normalize whitespace\n",
    "\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value if value else None  # Assign None for empty values\n",
    "        else:\n",
    "            result[key] = None  # Explicitly mark missing values\n",
    "\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline for Cost Data Extraction\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\"\n",
    "    \n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    expected_keys = [\n",
    "        \"Drilling AFE Amount\",\n",
    "        \"Daily Drilling Cost\",\n",
    "        \"Cumulative Drilling Cost\",\n",
    "        \"Cumulative Well Cost\",\n",
    "        \"Daily Mud Cost\",\n",
    "        \"Cumulative Mud Cost\"\n",
    "    ]\n",
    "\n",
    "    extracted = extract_key_value_from_text(ocr_text, expected_keys)\n",
    "    final_dict = {\"COST DATA\": extracted}\n",
    "    logger.info(json.dumps(final_dict, indent=4))\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, \"page_1_section_cost_data_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f87388ba-649b-40c0-a661-0ffb130c4dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2198194816545784,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_costdata_ddr",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
