{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ac49f2-9328-493b-bfd3-04f8de7a6ab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"dir_infoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a local or DBFS path.\n",
    "    \"\"\"\n",
    "    local_path = img_path.replace(\"dbfs:\", \"/dbfs\") if img_path.startswith(\"dbfs:\") else img_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    Only regions larger than 30x15 pixels are kept.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))  # top->bottom, then left->right\n",
    "\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box {i}: {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_dir_info_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_dir_info_dict_from_rois(roi_texts):\n",
    "    \"\"\"\n",
    "    Because of the known layout:\n",
    "      - \"Daily Cumulative\" is a bounding box\n",
    "      - The next bounding box has multiple lines for categories\n",
    "      - Then each subsequent bounding box has the daily/cumulative values in order\n",
    "      - The last bounding box merges \"Rotating Footage\" with its daily/cumulative\n",
    "\n",
    "    We'll parse them in a fixed sequence:\n",
    "      1) Find the bounding box that has \"Daily Cumulative\".\n",
    "      2) The next bounding box has 5 lines (the categories).\n",
    "      3) Then read 8 bounding boxes for the first 4 categories (2 each: daily/cumulative).\n",
    "      4) Finally parse the last bounding box that merges the 5th category with daily/cumulative.\n",
    "\n",
    "    This is tailored to your example layout.\n",
    "    \"\"\"\n",
    "    # Convert (x,y,w,h,text) into a list of just text for convenience\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "\n",
    "    # 1) Find index of \"Daily Cumulative\"\n",
    "    daily_cum_idx = None\n",
    "    for i, txt in enumerate(all_texts):\n",
    "        # Lowercase match\n",
    "        if \"daily\" in txt.lower() and \"cumulative\" in txt.lower():\n",
    "            daily_cum_idx = i\n",
    "            break\n",
    "\n",
    "    if daily_cum_idx is None:\n",
    "        logger.warning(\"Could not find 'Daily Cumulative' bounding box. Returning empty data.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # 2) The next bounding box (daily_cum_idx + 1) should have the 5 category lines\n",
    "    cat_idx = daily_cum_idx + 1\n",
    "    if cat_idx >= len(all_texts):\n",
    "        logger.warning(\"No bounding box found after 'Daily Cumulative'. Returning empty data.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # Split that bounding box by newline\n",
    "    categories_box = all_texts[cat_idx]\n",
    "    lines = [ln.strip() for ln in categories_box.split(\"\\n\") if ln.strip()]\n",
    "\n",
    "    # We expect 5 lines in that bounding box\n",
    "    #  e.g. [\"Circ/Cond Hours\", \"Sliding Hours\", \"Sliding Footage\", \"Rotating Hours\", \"Rotating Footage\"]\n",
    "    if len(lines) < 5:\n",
    "        logger.warning(f\"Expected 5 category lines, got {len(lines)}: {lines}\")\n",
    "\n",
    "    # 3) Next bounding boxes for the first 4 categories\n",
    "    # We have:\n",
    "    #   (cat_idx + 1) -> [BLANK]\n",
    "    #   (cat_idx + 2) -> 6.8\n",
    "    #   (cat_idx + 3) -> 5.8\n",
    "    #   (cat_idx + 4) -> 28.4\n",
    "    #   (cat_idx + 5) -> 247\n",
    "    #   (cat_idx + 6) -> 1488\n",
    "    #   (cat_idx + 7) -> 17.8\n",
    "    #   (cat_idx + 8) -> 75.9\n",
    "    #   (cat_idx + 9) -> Rotating Footage 2821 18941\n",
    "\n",
    "    # We want:\n",
    "    #   1) Circ/Cond Hours -> daily=\"\", cumulative=\"6.8\"\n",
    "    #   2) Sliding Hours   -> daily=\"5.8\", cumulative=\"28.4\"\n",
    "    #   3) Sliding Footage -> daily=\"247\", cumulative=\"1488\"\n",
    "    #   4) Rotating Hours  -> daily=\"17.8\", cumulative=\"75.9\"\n",
    "    #   5) Rotating Footage -> daily=\"2821\", cumulative=\"18941\"\n",
    "\n",
    "    # Let's define the known offset\n",
    "    # first 4 categories get 2 bounding boxes each\n",
    "    # The 5th category is in the last bounding box\n",
    "    # We'll store them in a structured list\n",
    "    structured_data = []\n",
    "\n",
    "    # Because lines might be fewer or more, let's do a safe approach:\n",
    "    # We'll gather them in the order we see them:\n",
    "    # lines[0] = \"Circ/Cond Hours\"\n",
    "    # lines[1] = \"Sliding Hours\"\n",
    "    # lines[2] = \"Sliding Footage\"\n",
    "    # lines[3] = \"Rotating Hours\"\n",
    "    # lines[4] = \"Rotating Footage\"\n",
    "\n",
    "    # We'll map them carefully to the bounding boxes:\n",
    "    # cat_idx+1 -> daily for circ/cond hours\n",
    "    # cat_idx+2 -> cumulative for circ/cond hours\n",
    "    # cat_idx+3 -> daily for sliding hours\n",
    "    # cat_idx+4 -> cumulative for sliding hours\n",
    "    # cat_idx+5 -> daily for sliding footage\n",
    "    # cat_idx+6 -> cumulative for sliding footage\n",
    "    # cat_idx+7 -> daily for rotating hours\n",
    "    # cat_idx+8 -> cumulative for rotating hours\n",
    "    # cat_idx+9 -> \"Rotating Footage 2821 18941\" => parse daily/cumulative\n",
    "\n",
    "    # We'll define a small helper to fetch text safely\n",
    "    def safe_get_text(idx):\n",
    "        if 0 <= idx < len(all_texts):\n",
    "            return all_texts[idx]\n",
    "        return \"\"\n",
    "\n",
    "    # 4) Parse the first 4 categories\n",
    "    # We expect exactly 8 bounding boxes for them\n",
    "    # Indices: cat_idx+1 to cat_idx+8\n",
    "    # We'll do them in pairs\n",
    "    for i in range(4):\n",
    "        cat_name = lines[i] if i < len(lines) else f\"Unknown Category {i+1}\"\n",
    "        daily_box = safe_get_text(cat_idx + 1 + (i * 2))   # e.g. cat_idx+1, +3, +5, +7\n",
    "        cum_box   = safe_get_text(cat_idx + 2 + (i * 2))   # e.g. cat_idx+2, +4, +6, +8\n",
    "\n",
    "        # For the very first category, we want daily=\"\", cumulative=\"6.8\"\n",
    "        # But the bounding box #6 is \"6.8\", and bounding box #5 is \"[BLANK]\"\n",
    "        # So daily_box = \"[BLANK]\", cum_box = \"6.8\"\n",
    "        # Perfect.\n",
    "\n",
    "        structured_data.append({\n",
    "            \"Category\": cat_name,\n",
    "            \"Daily\": daily_box if daily_box != \"[BLANK]\" else \"\",\n",
    "            \"Cumulative\": cum_box if cum_box != \"[BLANK]\" else \"\"\n",
    "        })\n",
    "\n",
    "    # 5) Parse the last category from bounding box cat_idx+9\n",
    "    # bounding box #14 => \"Rotating Footage 2821 18941\"\n",
    "    # We parse the line to get daily/cumulative\n",
    "    last_box = safe_get_text(cat_idx + 9)\n",
    "    # This might contain something like: \"Rotating Footage 2821 18941\"\n",
    "    # We'll remove \"Rotating Footage\" from it, then parse the two numbers\n",
    "    # But let's check lines[4] if it exists\n",
    "    if len(lines) >= 5:\n",
    "        last_cat_name = lines[4]\n",
    "    else:\n",
    "        last_cat_name = \"Rotating Footage\"\n",
    "\n",
    "    # Example: last_box = \"Rotating Footage 2821 18941\"\n",
    "    # remove the category from the front:\n",
    "    remainder = last_box.replace(last_cat_name, \"\").strip()\n",
    "    # remainder = \"2821 18941\"\n",
    "    tokens = remainder.split()\n",
    "    if len(tokens) >= 2:\n",
    "        daily_val = tokens[0]\n",
    "        cum_val   = tokens[1]\n",
    "    else:\n",
    "        # fallback if the box didn't parse\n",
    "        daily_val = \"\"\n",
    "        cum_val   = \"\"\n",
    "\n",
    "    structured_data.append({\n",
    "        \"Category\": last_cat_name,\n",
    "        \"Daily\": daily_val if daily_val != \"[BLANK]\" else \"\",\n",
    "        \"Cumulative\": cum_val if cum_val != \"[BLANK]\" else \"\"\n",
    "    })\n",
    "\n",
    "    logger.info(f\"Structured Data: {structured_data}\")\n",
    "\n",
    "    # Convert to DataFrame and JSON\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    df.to_csv(\"dir_info_data.csv\", index=False)\n",
    "    logger.info(\"Data saved successfully as CSV.\")\n",
    "\n",
    "    structured_data_json = df.to_dict(orient='records')\n",
    "    with open(\"dir_info_data.json\", \"w\") as json_file:\n",
    "        json.dump(structured_data_json, json_file, indent=4)\n",
    "    logger.info(\"Data saved successfully in JSON format.\")\n",
    "\n",
    "    return structured_data_json, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_dir_info_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_dir_info_pipeline():\n",
    "    # Path to your image\n",
    "    dir_info_img_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_5.png\"\n",
    "\n",
    "    try:\n",
    "        img = safe_read_image(dir_info_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # 1) Preprocess\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    # 2) Detect bounding boxes\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    # 3) OCR\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    # 4) Build structured data\n",
    "    dir_info_list, df = build_dir_info_dict_from_rois(roi_texts)\n",
    "\n",
    "    # 5) Final Output\n",
    "    final_output = {\"DIR INFO\": dir_info_list}\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    print(df)\n",
    "\n",
    "    # 6) Save results\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_dir_info_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    with open(os.path.join(output_folder, \"dir_info_data.json\"), \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    df.to_csv(os.path.join(output_folder, \"dir_info_data.csv\"), index=False)\n",
    "    logger.info(\"Data saved successfully in output folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_dir_info_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db7be4fc-793c-4e2f-9db8-cc4859fe06a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"daily_numbersExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a local or DBFS path.\n",
    "    \"\"\"\n",
    "    local_path = img_path.replace(\"dbfs:\", \"/dbfs\") if img_path.startswith(\"dbfs:\") else img_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    Only regions larger than 30x15 pixels are kept.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))  # top->bottom, then left->right\n",
    "\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box {i}: {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_obs_int_data_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_obs_int_data_from_rois(roi_texts):\n",
    "    \"\"\"\n",
    "    Builds structured data for the \"DAILY NUMBERS: OBSERVATION & INTERVENTION\" section.\n",
    "    \n",
    "    Expected layout:\n",
    "      - One bounding box contains the header \"DAILY NUMBERS: OBSERVATION & INTERVENTION\"\n",
    "      - The next bounding box contains the observation/intervention types (one per line):\n",
    "            Stop Cards\n",
    "            Hazard ID's\n",
    "            JSA's\n",
    "            Permit to Work\n",
    "            Totals\n",
    "      - The following bounding box contains the corresponding numbers (one per line), e.g.:\n",
    "            14\n",
    "            2\n",
    "            5\n",
    "            (blank)\n",
    "            21\n",
    "\n",
    "    Returns a tuple: (structured_data_json, df)\n",
    "    \"\"\"\n",
    "    # Convert (x,y,w,h,text) into a list of just text for convenience\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "\n",
    "    header_idx = None\n",
    "    # Look for the header box that contains the unique section title.\n",
    "    for i, txt in enumerate(all_texts):\n",
    "        if \"daily numbers\" in txt.lower() and \"observation\" in txt.lower() and \"intervention\" in txt.lower():\n",
    "            header_idx = i\n",
    "            break\n",
    "\n",
    "    if header_idx is None:\n",
    "        logger.warning(\"Could not find the header 'DAILY NUMBERS: OBSERVATION & INTERVENTION'. Returning empty data.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # Expect that the next two bounding boxes contain the types and numbers respectively.\n",
    "    types_idx = header_idx + 1\n",
    "    nums_idx  = header_idx + 2\n",
    "\n",
    "    if types_idx >= len(all_texts) or nums_idx >= len(all_texts):\n",
    "        logger.warning(\"Not enough bounding boxes after header for types and numbers. Returning empty data.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # Process types: each line is a type.\n",
    "    types_text = all_texts[types_idx]\n",
    "    types = [line.strip() for line in types_text.split(\"\\n\") if line.strip()]\n",
    "    # Process numbers: each line is the corresponding number.\n",
    "    nums_text = all_texts[nums_idx]\n",
    "    nums = [line.strip() for line in nums_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # Ensure we have the same number of types and numbers.\n",
    "    if len(types) != len(nums):\n",
    "        logger.warning(f\"Mismatch between number of types ({len(types)}) and numbers ({len(nums)}).\")\n",
    "    \n",
    "    # Zip together the types and numbers. If there is a mismatch, pair what you can.\n",
    "    structured_data = []\n",
    "    for typ, num in zip(types, nums):\n",
    "        structured_data.append({\n",
    "            \"Type\": typ,\n",
    "            \"Number\": num if num != \"[BLANK]\" else \"\"\n",
    "        })\n",
    "\n",
    "    logger.info(f\"Structured Data: {structured_data}\")\n",
    "\n",
    "    # Convert to DataFrame and JSON\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    df.to_csv(\"obs_int_data.csv\", index=False)\n",
    "    logger.info(\"Data saved successfully as CSV.\")\n",
    "\n",
    "    structured_data_json = df.to_dict(orient='records')\n",
    "    with open(\"obs_int_data.json\", \"w\") as json_file:\n",
    "        json.dump(structured_data_json, json_file, indent=4)\n",
    "    logger.info(\"Data saved successfully in JSON format.\")\n",
    "\n",
    "    return structured_data_json, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_obs_int_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_obs_int_pipeline():\n",
    "    # Path to your image for the \"OBSERVATION & INTERVENTION\" section.\n",
    "    obs_int_img_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_10.png\"\n",
    "\n",
    "    try:\n",
    "        img = safe_read_image(obs_int_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # 1) Preprocess the image\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    # 2) Detect bounding boxes\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    # 3) Perform OCR on each region\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    # 4) Build structured data for Observation & Intervention\n",
    "    obs_int_list, df = build_obs_int_data_from_rois(roi_texts)\n",
    "\n",
    "    # 5) Final Output\n",
    "    final_output = {\"DAILY NUMBERS: OBSERVATION & INTERVENTION\": obs_int_list}\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    print(df)\n",
    "\n",
    "    # 6) Save results\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_obs_int_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    with open(os.path.join(output_folder, \"obs_int_data.json\"), \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    df.to_csv(os.path.join(output_folder, \"obs_int_data.csv\"), index=False)\n",
    "    logger.info(\"Data saved successfully in output folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_obs_int_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139ac06c-fe5a-4b01-bfc1-33fbc6f05a0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"daily_numbersExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a local or DBFS path.\n",
    "    \"\"\"\n",
    "    local_path = img_path.replace(\"dbfs:\", \"/dbfs\") if img_path.startswith(\"dbfs:\") else img_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    Only regions larger than 30x15 pixels are kept.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))  # top->bottom, then left->right\n",
    "\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns a list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box {i}: {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_obs_int_data_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_obs_int_data_from_rois(roi_texts):\n",
    "    \"\"\"\n",
    "    Builds structured data for the \"DAILY NUMBERS: OBSERVATION & INTERVENTION\" section.\n",
    "    \n",
    "    Expected final format:\n",
    "    \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": [\n",
    "        { \"Type\": \"Stop Cards\",      \"Number\": \"14\" },\n",
    "        { \"Type\": \"Hazard ID's\",       \"Number\": \"2\" },\n",
    "        { \"Type\": \"JSA's\",             \"Number\": \"5\" },\n",
    "        { \"Type\": \"Permit to Work\",    \"Number\": \"\" },\n",
    "        { \"Type\": \"Totals\",            \"Number\": \"21\" }\n",
    "    ]\n",
    "    \n",
    "    This version filters out duplicate headers and \"[BLANK]\" texts,\n",
    "    splits multi-line OCR boxes for types, and pads the numbers list if needed.\n",
    "    \"\"\"\n",
    "    header_str = \"daily numbers: observation & intervention\"\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "\n",
    "    types_list = []\n",
    "    numbers_list = []\n",
    "\n",
    "    # Process each OCR box in order\n",
    "    for txt in all_texts:\n",
    "        clean_txt = txt.strip()\n",
    "        # Skip header duplicates and the \"Number\" column label and \"[BLANK]\"\n",
    "        if clean_txt.lower() == header_str or clean_txt.lower() == \"number\" or clean_txt.lower() == \"[blank]\":\n",
    "            continue\n",
    "\n",
    "        # If the text can be parsed as a number, then treat it as a number entry.\n",
    "        try:\n",
    "            float(clean_txt)\n",
    "            numbers_list.append(\"\" if clean_txt.lower() == \"[blank]\" else clean_txt)\n",
    "            continue\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # Otherwise, if the text contains a newline, assume it contains multiple types.\n",
    "        if \"\\n\" in clean_txt:\n",
    "            for line in clean_txt.splitlines():\n",
    "                line = line.strip()\n",
    "                if line and line.lower() != \"[blank]\":\n",
    "                    types_list.append(line)\n",
    "        else:\n",
    "            types_list.append(clean_txt)\n",
    "\n",
    "    logger.info(f\"Extracted Types: {types_list}\")\n",
    "    logger.info(f\"Extracted Numbers: {numbers_list}\")\n",
    "\n",
    "    # Ensure we have the expected number of rows. For this layout, we expect 5 entries.\n",
    "    expected_count = 5\n",
    "    if len(types_list) < expected_count:\n",
    "        logger.warning(f\"Expected {expected_count} types, got {len(types_list)}: {types_list}\")\n",
    "    if len(numbers_list) < expected_count:\n",
    "        logger.warning(f\"Expected {expected_count} numbers, got {len(numbers_list)}: {numbers_list}\")\n",
    "        # Pad numbers_list with empty strings\n",
    "        while len(numbers_list) < expected_count:\n",
    "            numbers_list.append(\"\")\n",
    "\n",
    "    # If there are extra numbers, trim the list.\n",
    "    types_list = types_list[:expected_count]\n",
    "    numbers_list = numbers_list[:expected_count]\n",
    "\n",
    "    # Zip together the lists to form the structured data\n",
    "    structured_data = []\n",
    "    for i in range(expected_count):\n",
    "        structured_data.append({\n",
    "            \"Type\": types_list[i],\n",
    "            \"Number\": numbers_list[i]\n",
    "        })\n",
    "\n",
    "    logger.info(f\"Structured Data: {structured_data}\")\n",
    "\n",
    "    # Save data as CSV and JSON\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    csv_filename = \"obs_int_data.csv\"\n",
    "    json_filename = \"obs_int_data.json\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    logger.info(f\"Data saved successfully as CSV: {csv_filename}\")\n",
    "\n",
    "    structured_data_json = df.to_dict(orient='records')\n",
    "    with open(json_filename, \"w\") as json_file:\n",
    "        json.dump(structured_data_json, json_file, indent=4)\n",
    "    logger.info(f\"Data saved successfully in JSON format: {json_filename}\")\n",
    "\n",
    "    return structured_data_json, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_obs_int_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_obs_int_pipeline():\n",
    "    # Path to your image for the \"OBSERVATION & INTERVENTION\" section.\n",
    "    obs_int_img_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_10.png\"\n",
    "\n",
    "    try:\n",
    "        img = safe_read_image(obs_int_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # 1) Preprocess the image\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    # 2) Detect bounding boxes\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    # 3) Perform OCR on each region\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    # 4) Build structured data for Observation & Intervention\n",
    "    obs_int_list, df = build_obs_int_data_from_rois(roi_texts)\n",
    "\n",
    "    # 5) Final Output\n",
    "    final_output = {\"DAILY NUMBERS: OBSERVATION & INTERVENTION\": obs_int_list}\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    print(df)\n",
    "\n",
    "    # 6) Save results to an output folder\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_obs_int_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    with open(os.path.join(output_folder, \"obs_int_data.json\"), \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    df.to_csv(os.path.join(output_folder, \"obs_int_data.csv\"), index=False)\n",
    "    logger.info(\"Data saved successfully in output folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_obs_int_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba01f467-739b-4e88-aae8-507f1c914f40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4160977587552902,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_dirinfo_dailynumbers",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
