{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65676a6f-9382-4181-8063-7aeae1364548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_pumps_table(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses the pumps table from OCR text using a regex.\n",
    "    Expected format: Number BOMCO TRIPLEX [HHP] Efficiency Stroke(in) Liner(in) P-Rating P-Limit SPM_Rating SPM_Limit\n",
    "    \"\"\"\n",
    "    pump_pattern = re.compile(\n",
    "        r\"^(\\d+)?\\s*\"               # Number (optional)\n",
    "        r\"(BOMCO)\\s+(TRIPLEX)\\s+\"    # Model, Type\n",
    "        r\"(\\d+)?\\s*\"                # HHP (optional)\n",
    "        r\"(\\d+)\\s+\"                 # Efficiency\n",
    "        r\"([\\d.]+)\\s+\"              # Stroke\\(in\\)\n",
    "        r\"([\\d.]+)\\s+\"              # Liner\\(in\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Rating\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # P-Limit\\(psi\\)\n",
    "        r\"(\\d+)\\s+\"                 # SPM Rating\n",
    "        r\"(\\d+)\\s*$\",               # SPM Limit\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    pumps = []\n",
    "    lines = ocr_text.splitlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        match = pump_pattern.match(line)\n",
    "        if match:\n",
    "            number, model, pump_type, hhp, efficiency, stroke, liner, p_rating, p_limit, spm_rating, spm_limit = match.groups()\n",
    "            pumps.append({\n",
    "                \"Number\": number if number else \"\",\n",
    "                \"Model\": model,\n",
    "                \"Type\": pump_type,\n",
    "                \"HHP\": hhp if hhp else \"\",\n",
    "                \"Efficiency\": efficiency,\n",
    "                \"Stroke(in)\": stroke,\n",
    "                \"Liner(in)\": liner,\n",
    "                \"P-Rating(psi)\": p_rating,\n",
    "                \"P-Limit(psi)\": p_limit,\n",
    "                \"SPM Rating\": spm_rating,\n",
    "                \"SPM Limit\": spm_limit\n",
    "            })\n",
    "    return pumps\n",
    "    \n",
    "def parse_drilling_circ_rates(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses drilling/circ rates from OCR text.\n",
    "    This version splits the text into segments starting with \"Drilling/Circ Rate <n>\"\n",
    "    then combines the lines in each segment and applies a regex with DOTALL.\n",
    "    \"\"\"\n",
    "    circ_rates = []\n",
    "    \n",
    "    # Split the OCR text into segments where each segment begins with \"Drilling/Circ Rate\" followed by a digit\n",
    "    segments = re.split(r\"(?=Drilling/Circ Rate \\d+)\", ocr_text)\n",
    "    \n",
    "    # Regex pattern to capture the numbers:\n",
    "    # Group 1: Rate ID (the number after \"Drilling/Circ Rate\")\n",
    "    # Group 2: Pressure (number preceding \"PS!\" or \"PSI\")\n",
    "    # Group 3: SPM value (number after \"@\")\n",
    "    # Group 4: Gal/Stoke value\n",
    "    # Group 5: GPM value\n",
    "    # Group 6: BPM value\n",
    "    # Group 7: DC value\n",
    "    # Group 8: DP value\n",
    "    pattern = re.compile(\n",
    "        r\"Drilling/Circ Rate\\s+(\\d+).*?\"       # Rate ID\n",
    "        r\"(\\d+)\\s+PS[!I].*?\"                   # Pressure\n",
    "        r\"@\\s*(\\d+).*?\"                        # SPM value\n",
    "        r\"([\\d.]+)\\s+Gal/Stoke.*?\"              # Gal/Stoke\n",
    "        r\"([\\d.]+)\\s+GPM.*?\"                    # GPM\n",
    "        r\"([\\d.]+)\\s+BPM.*?\"                    # BPM\n",
    "        r\"([\\d.]+)\\s+DC.*?\"                     # DC\n",
    "        r\"([\\d.]+)\\s+DP\",                      # DP\n",
    "        re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    \n",
    "    # Process each segment individually\n",
    "    for seg in segments:\n",
    "        seg = seg.strip()\n",
    "        if not seg.startswith(\"Drilling/Circ Rate\"):\n",
    "            continue  # Skip any header or unrelated segments\n",
    "        # Replace newline characters with spaces to form a continuous string\n",
    "        seg_clean = \" \".join(seg.splitlines())\n",
    "        match = pattern.search(seg_clean)\n",
    "        if match:\n",
    "            rate_id, pressure, spm, gal_stroke, gpm, bpm, dc, dp = match.groups()\n",
    "            circ_rates.append({\n",
    "                \"RateID\": rate_id,\n",
    "                \"Pressure(PSI)\": pressure,\n",
    "                \"SPM\": spm,\n",
    "                \"Gal/Stoke\": gal_stroke,\n",
    "                \"GPM\": gpm,\n",
    "                \"BPM\": bpm,\n",
    "                \"DC\": dc,\n",
    "                \"DP\": dp\n",
    "            })\n",
    "        else:\n",
    "            # Optional: log a warning if no match is found for a segment\n",
    "            print(f\"Warning: No match found in segment:\\n{seg_clean}\")\n",
    "            \n",
    "    return circ_rates\n",
    "\n",
    "def process_pumps(pumps_img_path, debug=True):\n",
    "    \"\"\"\n",
    "    Processes the pumps section:\n",
    "      - Reads image using PIL,\n",
    "      - Performs OCR,\n",
    "      - Parses pumps table and drilling/circ rates,\n",
    "      - Returns combined results as JSON and a DataFrame.\n",
    "    \"\"\"\n",
    "    pil_img = safe_read_image(pumps_img_path)\n",
    "    ocr_text = perform_ocr(pil_img)\n",
    "    if debug:\n",
    "        logger.info(\"Pumps OCR Text:\\n\" + ocr_text)\n",
    "    pumps = parse_pumps_table(ocr_text)\n",
    "    circ_rates = parse_drilling_circ_rates(ocr_text)\n",
    "    final_data = {\"Pumps\": pumps, \"DrillingCircRates\": circ_rates}\n",
    "    df_pumps = pd.DataFrame(pumps)\n",
    "    df_circ = pd.DataFrame(circ_rates)\n",
    "    if not df_pumps.empty and not df_circ.empty:\n",
    "        df = pd.concat([df_pumps, df_circ], axis=0, ignore_index=False)\n",
    "    elif not df_pumps.empty:\n",
    "        df = df_pumps\n",
    "    else:\n",
    "        df = df_circ\n",
    "    return final_data, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a5c5c6-3755-4a10-a457-55ce12475e05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c9b6ee-8ed4-4907-bb03-d36bdf36e4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# 5) Personnel Extraction process\n",
    "# --------------------------------------------------------\n",
    "def detect_text_regions_personnel(thresh_img, debug=True):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    logger.debug(f\"Detected {len(rois)} text regions for personnel.\")\n",
    "    # if debug:\n",
    "    #     show_image(\"Detected Personnel Text Regions\", debug_img, size=(12, 12))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois_personnel(img, rois, debug=True):\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        logger.debug(f\"ROI bbox=({x}, {y}, {w}, {h}), text: '{text}'\")\n",
    "    return results\n",
    "\n",
    "def group_rois_by_row(roi_results, threshold=20):\n",
    "    roi_with_center = [(x, y, w, h, text, y + h/2) for (x, y, w, h, text) in roi_results]\n",
    "    roi_with_center.sort(key=lambda r: r[5])\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    current_center = None\n",
    "    for roi in roi_with_center:\n",
    "        x, y, w, h, text, y_center = roi\n",
    "        if current_center is None:\n",
    "            current_center = y_center\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        elif abs(y_center - current_center) < threshold:\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [(x, y, w, h, text)]\n",
    "            current_center = y_center\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    logger.debug(f\"Grouped ROIs into {len(groups)} rows.\")\n",
    "    return groups\n",
    "\n",
    "def preprocess_personnel_data_from_rows(groups):\n",
    "    personnel_data = []\n",
    "    header_lines = {\n",
    "        \"personnel\", \n",
    "        \"company contractor no. personnel daily hours cumulative hours\",\n",
    "        \"ssn\"\n",
    "    }\n",
    "    for group in groups:\n",
    "        group.sort(key=lambda r: r[0])\n",
    "        row_text = \" \".join([r[4] for r in group]).strip()\n",
    "        logger.debug(f\"Processing row: '{row_text}'\")\n",
    "        if row_text.lower() in header_lines:\n",
    "            logger.debug(\"Skipping header row.\")\n",
    "            continue\n",
    "        tokens = row_text.split()\n",
    "        numeric_tokens = re.findall(r'\\d+(?:\\.\\d+)?', row_text)\n",
    "        logger.debug(f\"Row tokens: {tokens}\")\n",
    "        logger.debug(f\"Numeric tokens found: {numeric_tokens}\")\n",
    "        if tokens[0].lower().startswith(\"totals\"):\n",
    "            if len(numeric_tokens) >= 2:\n",
    "                try:\n",
    "                    daily_hours = int(float(numeric_tokens[0]))\n",
    "                    cumulative_hours = numeric_tokens[1]\n",
    "                except ValueError as e:\n",
    "                    logger.error(f\"Error parsing Totals row: {row_text} => {e}\")\n",
    "                    continue\n",
    "                row_dict = {\n",
    "                    \"Company\": \"\",\n",
    "                    \"Contractor\": \"\",\n",
    "                    \"No. Personnel\": \"Totals\",\n",
    "                    \"Daily Hours\": daily_hours,\n",
    "                    \"Cumulative Hours\": cumulative_hours\n",
    "                }\n",
    "                logger.info(f\"Totals row parsed: {row_dict}\")\n",
    "                personnel_data.append(row_dict)\n",
    "            else:\n",
    "                logger.warning(f\"Totals row without sufficient numbers: {row_text}\")\n",
    "            continue\n",
    "        if len(numeric_tokens) >= 3:\n",
    "            try:\n",
    "                no_personnel = int(float(numeric_tokens[-3]))\n",
    "                daily_hours = int(float(numeric_tokens[-2]))\n",
    "                cumulative_hours = int(float(numeric_tokens[-1]))\n",
    "                logger.debug(f\"Extracted: no_personnel={no_personnel}, daily_hours={daily_hours}, cumulative_hours={cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting numbers in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            pattern = (r'\\s*' + re.escape(numeric_tokens[-3]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-2]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-1]) + r'\\s*$')\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        elif len(numeric_tokens) == 1:\n",
    "            try:\n",
    "                cumulative_hours = int(float(numeric_tokens[0]))\n",
    "                logger.debug(f\"Single numeric token, cumulative_hours: {cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting single number in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            no_personnel = None\n",
    "            daily_hours = None\n",
    "            pattern = r'\\s*' + re.escape(numeric_tokens[0]) + r'\\s*$'\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        else:\n",
    "            logger.warning(f\"Row has unexpected number of numeric tokens: {row_text}\")\n",
    "            continue\n",
    "\n",
    "        if \"service company\" in text_only.lower():\n",
    "            parts = re.split(r'(?i)service company', text_only, maxsplit=1)\n",
    "            company = parts[0].strip()\n",
    "            contractor = \"Service Company\"\n",
    "        else:\n",
    "            company = text_only\n",
    "            contractor = \"Service Company\"\n",
    "        \n",
    "        row_dict = {\n",
    "            \"Company\": company,\n",
    "            \"Contractor\": contractor,\n",
    "            \"No. Personnel\": no_personnel,\n",
    "            \"Daily Hours\": daily_hours,\n",
    "            \"Cumulative Hours\": cumulative_hours\n",
    "        }\n",
    "        logger.info(f\"Parsed row: {row_dict}\")\n",
    "        personnel_data.append(row_dict)\n",
    "    return {\"PERSONNEL\": personnel_data}\n",
    "\n",
    "def process_personnel(personnel_img_path, debug=True):\n",
    "    \"\"\"Processes the personnel section: read image, detect ROIs, OCR, group and parse rows.\"\"\"\n",
    "    img = read_cropped_section_image(personnel_img_path)\n",
    "    # if debug:\n",
    "        # show_image(\"Original Personnel Image\", img, size=(10,10))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "    # if debug:\n",
    "        # show_image(\"Thresholded Personnel Image\", cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR), size=(8,8))\n",
    "    rois = detect_text_regions_personnel(thresh_img, debug=debug)\n",
    "    roi_results = perform_ocr_on_rois_personnel(img, rois, debug=debug)\n",
    "    grouped_rows = group_rois_by_row(roi_results, threshold=20)\n",
    "    data_dict = preprocess_personnel_data_from_rows(grouped_rows)\n",
    "    df = pd.DataFrame(data_dict[\"PERSONNEL\"]) if data_dict[\"PERSONNEL\"] else pd.DataFrame(\n",
    "        columns=[\"Company\", \"Contractor\", \"No. Personnel\", \"Daily Hours\", \"Cumulative Hours\"])\n",
    "    return data_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e026211d-23eb-436f-8ea0-94cdc0bf1124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_casing_dict_from_rois(roi_texts, expected_headers, debug=False):\n",
    "    \"\"\"\n",
    "    Groups OCR results for CASING into rows and returns a list of dictionaries.\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row).strip()\n",
    "        row_strings.append(line)\n",
    "        if debug:\n",
    "            logger.info(f\"Grouped Row {i}: {line}\")\n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for sub in line.split(\"\\n\"):\n",
    "            sub = sub.strip()\n",
    "            if sub:\n",
    "                all_lines.append(sub)\n",
    "    if debug:\n",
    "        logger.info(f\"All extracted lines: {all_lines}\")\n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        if debug:\n",
    "            logger.info(f\"Processing line: '{line}' -> tokens: {tokens}\")\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        if \"type\" in lower_tokens and \"size\" in lower_tokens:\n",
    "            logger.info(f\"Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"Line has fewer tokens than expected: {tokens}\")\n",
    "            tokens = tokens + [\"\"] * (len(expected_headers) - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    casing_list = [{expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "                   for tokens in data_lines]\n",
    "    if debug:\n",
    "        logger.info(f\"Final casing list: {casing_list}\")\n",
    "    return casing_list\n",
    "\n",
    "def process_casing(img_path, debug=False):\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    logger.info(f\"Detected {len(rois)} text regions for CASING\")\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    expected_headers = [\"Type\", \"Size\", \"Weight\", \"Grade\", \"Connection\", \"Top MD\", \"Bottom MD\", \"TOC\"]\n",
    "    casing_list = build_casing_dict_from_rois(roi_texts, expected_headers, debug=debug)\n",
    "    df = pd.DataFrame(casing_list)\n",
    "    logger.info(f\"CASING DataFrame shape: {df.shape}\")\n",
    "    return {\"CASING\": casing_list}, df\n",
    "\n",
    "# --- BOP Pipeline ---\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config=\"--psm 6\")\n",
    "    return text.strip()\n",
    "\n",
    "def extract_bop_info(ocr_text):\n",
    "    patterns = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in patterns.items():\n",
    "        match = re.search(regex, ocr_text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    return result\n",
    "\n",
    "def process_bop(img_path, debug=False):\n",
    "    img = safe_read_image(img_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"BOP OCR extraction complete.\")\n",
    "    bop_info = extract_bop_info(ocr_text)\n",
    "    df = pd.DataFrame(list(bop_info.items()), columns=[\"Key\", \"Value\"])\n",
    "    logger.info(f\"BOP DataFrame shape: {df.shape}\")\n",
    "    return {\"BOP\": bop_info}, df\n",
    "\n",
    "# --- CONSUMABLES Pipeline ---\n",
    "def build_consumables_dict_from_rois(roi_texts, debug=False):\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    grouped_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row).strip()\n",
    "        grouped_rows.append(line)\n",
    "        if debug:\n",
    "            logger.info(f\"Grouped Row {i}: {line}\")\n",
    "    data_rows = []\n",
    "    for line in grouped_rows:\n",
    "        lower_line = line.lower()\n",
    "        if (\"consumable\" in lower_line and \"received\" in lower_line) or \"nun\" in lower_line:\n",
    "            continue\n",
    "        if len(line.split()) < 5:\n",
    "            continue\n",
    "        data_rows.append(line)\n",
    "    if debug:\n",
    "        logger.info(f\"Data rows to parse: {data_rows}\")\n",
    "    consumables_list = []\n",
    "    for line in data_rows:\n",
    "        tokens = re.split(r'\\s+', line)\n",
    "        if len(tokens) > 5:\n",
    "            first = \" \".join(tokens[:-4])\n",
    "            tokens = [first] + tokens[-4:]\n",
    "        if len(tokens) != 5:\n",
    "            logger.warning(f\"Skipping row (unexpected token count): {tokens}\")\n",
    "            continue\n",
    "        row_dict = {\n",
    "            \"Consumable\": tokens[0],\n",
    "            \"Daily Received (gal)\": tokens[1],\n",
    "            \"Daily Used (gal)\": tokens[2],\n",
    "            \"Cumulative Used (gal)\": tokens[3],\n",
    "            \"Daily on Hand (gal)\": tokens[4]\n",
    "        }\n",
    "        consumables_list.append(row_dict)\n",
    "    return consumables_list\n",
    "\n",
    "def process_consumables(img_path, debug=False):\n",
    "    img = safe_read_image(img_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    logger.info(f\"Detected {len(rois)} text regions for CONSUMABLES\")\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    consumables_list = build_consumables_dict_from_rois(roi_texts, debug=debug)\n",
    "    df = pd.DataFrame(consumables_list)\n",
    "    logger.info(f\"CONSUMABLES DataFrame shape: {df.shape}\")\n",
    "    return {\"CONSUMABLES\": consumables_list}, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c6594bf-0f9f-4acb-a9a8-e7e7eb1946a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_bit_info_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_bit_info_dict_from_rois(roi_texts, debug=True):\n",
    "    \"\"\"\n",
    "    Custom parsing for the multi-row header layout:\n",
    "      Row 0 => Table Title (e.g. \"DRILL BITS ...\")\n",
    "      Row 1 => Super Headers: \"Bit Data  Nozzles  Depth  Hours  Dull Grade\"\n",
    "      Row 2 => Sub-headers:   \"Bit # Size Make Model Serial #  Number x Size TFA  In Out Feet ROP  Total On Btm  I oO D L B G oO RP\"\n",
    "      Row 3 => Data row #1\n",
    "      Row 4 => Data row #2\n",
    "      ...\n",
    "    We'll parse row 1 and row 2 to define column groups. Then parse each subsequent row in chunks.\n",
    "    \"\"\"\n",
    "    # Step 1) Group bounding boxes by y-coordinate\n",
    "    row_tolerance = 10\n",
    "    grouped_rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            grouped_rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        grouped_rows.append(current_row)\n",
    "\n",
    "    # Step 2) Convert each row group into a single string\n",
    "    row_strings = []\n",
    "    for i, row_cells in enumerate(grouped_rows):\n",
    "        row_cells.sort(key=lambda c: c[0])  # left->right\n",
    "        line = \" \".join(cell[4] for cell in row_cells)\n",
    "        line = line.replace(\"\\n\", \" \").strip()  # flatten\n",
    "        row_strings.append(line)\n",
    "        if debug:\n",
    "            logger.info(f\"Row {i} => {line}\")\n",
    "\n",
    "    # We expect something like:\n",
    "    # Row 0 => \"DRILL BITS DRILL BITS [BLANK]\"\n",
    "    # Row 1 => \"Bit Data Nozzles Depth Hours Dull Grade\"\n",
    "    # Row 2 => \"Bit # Size Make Model Serial # Number x Size TFA In Out Feet ROP Total On Btm I oO D L B G oO RP\"\n",
    "    # Row 3 => \"4 6.750 BAKER DD40+TWS 5355166 6X12 0.66 ...\"\n",
    "    # Row 4 => \"3 9.875 REED TKS6-H1 A308739 7X12 0.77 ...\"\n",
    "\n",
    "    # Step 3) Identify the row indices for:\n",
    "    #  - Title (row 0)\n",
    "    #  - Super headers (row 1)\n",
    "    #  - Sub-headers (row 2)\n",
    "    #  - Data rows (row 3, 4, ...)\n",
    "    if len(row_strings) < 3:\n",
    "        logger.warning(\"Not enough rows found for this layout.\")\n",
    "        return [], pd.DataFrame()\n",
    "\n",
    "    # We'll skip row 0 (table title).\n",
    "    super_header_line = row_strings[1] if len(row_strings) > 1 else \"\"\n",
    "    sub_header_line   = row_strings[2] if len(row_strings) > 2 else \"\"\n",
    "    data_lines        = row_strings[3:]  # everything after row 2\n",
    "\n",
    "    if debug:\n",
    "        logger.info(f\"Super Headers => {super_header_line}\")\n",
    "        logger.info(f\"Sub Headers => {sub_header_line}\")\n",
    "        logger.info(f\"Data Lines => {data_lines}\")\n",
    "\n",
    "    # Step 4) Define the \"super header\" groups and sub-headers\n",
    "    # We'll do a simpler approach: we know how many tokens each group has:\n",
    "    #  Bit Data => 5, Nozzles => 2, Depth => 4, Hours => 2, Dull Grade => 8 (Total = 21)\n",
    "    final_columns = [\n",
    "        \"Bit #\", \"Size\", \"Make\", \"Model\", \"Serial #\",         # 5\n",
    "        \"Nozzle-(Number x Size)\", \"Nozzle-TFA\",               # 2\n",
    "        \"Depth-In\", \"Depth-Out\", \"Depth-Feet\", \"Depth-ROP\",   # 4\n",
    "        \"Hours-Total\", \"Hours-On Btm\",                        # 2\n",
    "        \"Dull Grade-I\", \"Dull Grade-O1\", \"Dull Grade-D\", \"Dull Grade-L\", \n",
    "        \"Dull Grade-B\", \"Dull Grade-G\", \"Dull Grade-O2\", \"Dull Grade-RP\"  # 8\n",
    "    ]\n",
    "\n",
    "    # Step 5) Parse each data row in chunks of 21 tokens\n",
    "    structured_data = []\n",
    "    for line in data_lines:\n",
    "        tokens = line.split()\n",
    "        # We expect 21 tokens per data row; pad or truncate if necessary\n",
    "        if len(tokens) < 21:\n",
    "            tokens += [\"\"] * (21 - len(tokens))\n",
    "        elif len(tokens) > 21:\n",
    "            tokens = tokens[:21]\n",
    "\n",
    "        row_dict = {}\n",
    "        for col_idx, col_name in enumerate(final_columns):\n",
    "            row_dict[col_name] = tokens[col_idx] if col_idx < len(tokens) else \"\"\n",
    "\n",
    "        structured_data.append(row_dict)\n",
    "        if debug:\n",
    "            logger.info(f\"Parsed row => {row_dict}\")\n",
    "\n",
    "    # Step 6) Convert to DataFrame and JSON\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    if debug:\n",
    "        logger.info(\"DataFrame Preview:\")\n",
    "        logger.info(df.head())\n",
    "\n",
    "    df.to_csv(\"bit_info_data.csv\", index=False)\n",
    "    logger.info(\"Data saved successfully as CSV.\")\n",
    "\n",
    "    structured_data_json = df.to_dict(orient='records')\n",
    "    with open(\"bit_info_data.json\", \"w\") as json_file:\n",
    "        json.dump(structured_data_json, json_file, indent=4)\n",
    "    logger.info(\"Data saved successfully in JSON format.\")\n",
    "\n",
    "    return structured_data_json, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_bit_info_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def process_drill_bits(img_path, debug=True):\n",
    "    \"\"\"\n",
    "    Main pipeline for extracting the BIT DETAILS table from your layout.\n",
    "    \"\"\"\n",
    "    # Replace with your actual path\n",
    "    #bit_info_img_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_6.png\"\n",
    "\n",
    "    try:\n",
    "        img = safe_read_image(img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # 1) Preprocess\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "\n",
    "    # 2) Detect bounding boxes\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "\n",
    "    # 3) Perform OCR\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # --- New Step: Annotate and show OCR results on the image ---\n",
    "    # annotate_ocr_results(img, roi_texts)\n",
    "\n",
    "    # 4) Build structured data (tailored to your table layout)\n",
    "    bit_info_list, df = build_bit_info_dict_from_rois(roi_texts, debug=True)\n",
    "\n",
    "    # 5) Show final JSON in logs\n",
    "    final_output = {\"BIT DETAILS\": bit_info_list}\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    print(df)\n",
    "\n",
    "    # 6) Save final results\n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_bit_info_results\"\n",
    "    os.makedirs(output_folder, exist_ok=False)\n",
    "    with open(os.path.join(output_folder, \"bit_info_data.json\"), \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    df.to_csv(os.path.join(output_folder, \"bit_info_data.csv\"), index=False)\n",
    "    logger.info(\"Data saved successfully in output folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d076f68b-6d16-4437-83ff-7a449dd1504f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_dir_info_dict_from_rois(roi_texts, debug=True):\n",
    "    all_texts = [t[4] for t in roi_texts]\n",
    "    daily_cum_idx = next((i for i, txt in enumerate(all_texts)\n",
    "                           if \"daily\" in txt.lower() and \"cumulative\" in txt.lower()), None)\n",
    "    if daily_cum_idx is None:\n",
    "        logger.warning(\"Could not find 'Daily Cumulative' bounding box.\")\n",
    "        return {}, pd.DataFrame()\n",
    "    cat_idx = daily_cum_idx + 1\n",
    "    if cat_idx >= len(all_texts):\n",
    "        logger.warning(\"No bounding box after 'Daily Cumulative'.\")\n",
    "        return {}, pd.DataFrame()\n",
    "    categories_box = all_texts[cat_idx]\n",
    "    lines = [ln.strip() for ln in categories_box.split(\"\\n\") if ln.strip()]\n",
    "    if len(lines) < 5:\n",
    "        logger.warning(f\"Expected 5 category lines, got {len(lines)}: {lines}\")\n",
    "    def safe_get(idx):\n",
    "        return all_texts[idx] if 0 <= idx < len(all_texts) else \"\"\n",
    "    structured = []\n",
    "    for i in range(4):\n",
    "        cat_name = lines[i] if i < len(lines) else f\"Unknown Category {i+1}\"\n",
    "        daily_box = safe_get(cat_idx + 1 + (i * 2))\n",
    "        cum_box = safe_get(cat_idx + 2 + (i * 2))\n",
    "        structured.append({\n",
    "            \"Category\": cat_name,\n",
    "            \"Daily\": \"\" if daily_box == \"[BLANK]\" else daily_box,\n",
    "            \"Cumulative\": \"\" if cum_box == \"[BLANK]\" else cum_box\n",
    "        })\n",
    "    last_box = safe_get(cat_idx + 9)\n",
    "    last_cat = lines[4] if len(lines) >= 5 else \"Rotating Footage\"\n",
    "    remainder = last_box.replace(last_cat, \"\").strip()\n",
    "    tokens = remainder.split()\n",
    "    daily_val = tokens[0] if len(tokens) >= 2 else \"\"\n",
    "    cum_val = tokens[1] if len(tokens) >= 2 else \"\"\n",
    "    structured.append({\n",
    "        \"Category\": last_cat,\n",
    "        \"Daily\": \"\" if daily_val == \"[BLANK]\" else daily_val,\n",
    "        \"Cumulative\": \"\" if cum_val == \"[BLANK]\" else cum_val\n",
    "    })\n",
    "    df = pd.DataFrame(structured)\n",
    "    logger.info(f\"DIR INFO DataFrame shape: {df.shape}\")\n",
    "    return {\"DIR INFO\": structured}, df\n",
    "\n",
    "def process_dir_info(section_path, debug=True):\n",
    "    img = safe_read_image(section_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    return build_dir_info_dict_from_rois(roi_texts, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d247133-9a9d-4d59-bc4b-aefc236b9965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6103765517986980>, line 733\u001B[0m\n",
       "\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mprint\u001B[39m(json\u001B[38;5;241m.\u001B[39mdumps(aggregated_json, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m))\n",
       "\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[0;32m--> 733\u001B[0m     main()\n",
       "\n",
       "File \u001B[0;32m<command-6103765517986980>, line 701\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m    685\u001B[0m aggregated_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n",
       "\u001B[1;32m    687\u001B[0m \u001B[38;5;66;03m# Define processing order as tuples: (Section Name, processing function, image path)\u001B[39;00m\n",
       "\u001B[1;32m    688\u001B[0m processes \u001B[38;5;241m=\u001B[39m [\n",
       "\u001B[1;32m    689\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY DRILLING REPORT\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_daily_drilling_report, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY DRILLING REPORT\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    690\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWELL/JOB INFORMATION\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_well_job_info, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWELL/JOB INFORMATION\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    691\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUD\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_mud, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUD\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    692\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSURVEY DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_survey, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSURVEY DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    693\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDIR INFO\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_dir_info, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDIR INFO\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    694\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDRILL BITS\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_drill_bits, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDRILL BITS\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    695\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCASING\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_casing, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCASING\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    696\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBOP\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_bop, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBOP\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    697\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPERSONNEL\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_personnel, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPERSONNEL\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    698\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY NUMBERS: OBSERVATION & INTERVENTION\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_obs_int, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY NUMBERS: OBSERVATION & INTERVENTION\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    699\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBHA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_bha, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBHA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    700\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPUMPS\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_pumps, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPUMPS\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[0;32m--> 701\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOST DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_cost_data, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOST DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    702\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTIME BREAKDOWN\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_time_breakdown, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTIME BREAKDOWN\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n",
       "\u001B[1;32m    703\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCONSUMABLES\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_consumables, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCONSUMABLES\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
       "\u001B[1;32m    704\u001B[0m ]\n",
       "\u001B[1;32m    706\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m section, func, img_path \u001B[38;5;129;01min\u001B[39;00m processes:\n",
       "\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'process_cost_data' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'process_cost_data' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'process_cost_data' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-6103765517986980>, line 733\u001B[0m\n\u001B[1;32m    730\u001B[0m     \u001B[38;5;28mprint\u001B[39m(json\u001B[38;5;241m.\u001B[39mdumps(aggregated_json, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 733\u001B[0m     main()\n",
        "File \u001B[0;32m<command-6103765517986980>, line 701\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    685\u001B[0m aggregated_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[1;32m    687\u001B[0m \u001B[38;5;66;03m# Define processing order as tuples: (Section Name, processing function, image path)\u001B[39;00m\n\u001B[1;32m    688\u001B[0m processes \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    689\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY DRILLING REPORT\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_daily_drilling_report, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY DRILLING REPORT\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    690\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWELL/JOB INFORMATION\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_well_job_info, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWELL/JOB INFORMATION\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    691\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUD\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_mud, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMUD\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    692\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSURVEY DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_survey, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSURVEY DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    693\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDIR INFO\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_dir_info, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDIR INFO\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    694\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDRILL BITS\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_drill_bits, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDRILL BITS\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    695\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCASING\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_casing, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCASING\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    696\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBOP\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_bop, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBOP\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    697\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPERSONNEL\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_personnel, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPERSONNEL\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    698\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY NUMBERS: OBSERVATION & INTERVENTION\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_obs_int, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDAILY NUMBERS: OBSERVATION & INTERVENTION\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    699\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBHA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_bha, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBHA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    700\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPUMPS\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_pumps, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPUMPS\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[0;32m--> 701\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOST DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_cost_data, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOST DATA\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    702\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTIME BREAKDOWN\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_time_breakdown, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTIME BREAKDOWN\u001B[39m\u001B[38;5;124m\"\u001B[39m)),\n\u001B[1;32m    703\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCONSUMABLES\u001B[39m\u001B[38;5;124m\"\u001B[39m, process_consumables, image_paths\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCONSUMABLES\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    704\u001B[0m ]\n\u001B[1;32m    706\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m section, func, img_path \u001B[38;5;129;01min\u001B[39;00m processes:\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
        "\u001B[0;31mNameError\u001B[0m: name 'process_cost_data' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import math\n",
    "#from matplotlib import pyplot as plt  # Commented out since we do not show images\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------\n",
    "# Logger Setup\n",
    "# -------------------------------\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(\"SectionExtractor\")\n",
    "\n",
    "# -------------------------------\n",
    "# Utility Functions\n",
    "# -------------------------------\n",
    "def dbfs_to_local_path(dbfs_path):\n",
    "    \"\"\"Convert a DBFS URI (e.g. \"dbfs:/mnt/xxx\") to a local path (\"/dbfs/mnt/xxx\").\"\"\"\n",
    "    if dbfs_path.startswith(\"dbfs:/\"):\n",
    "        return \"/dbfs/\" + dbfs_path[len(\"dbfs:/\"):]\n",
    "    return dbfs_path\n",
    "\n",
    "def sanitize_section_name(section):\n",
    "    \"\"\"Convert section name to safe file name.\"\"\"\n",
    "    return section.lower().replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"\")\n",
    "\n",
    "def safe_read_image_cv2(image_path):\n",
    "    local_path = dbfs_to_local_path(image_path)\n",
    "    logger.info(f\"Reading image from: {local_path}\")\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"Image file not found at {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"OpenCV failed to read image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "def safe_read_image_pil(image_path):\n",
    "    local_path = dbfs_to_local_path(image_path)\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"Image file not found at {local_path}\")\n",
    "    return Image.open(local_path)\n",
    "\n",
    "# (Note: show_image function omitted since we do not display images.)\n",
    "\n",
    "# -------------------------------\n",
    "# Preprocessing Functions\n",
    "# -------------------------------\n",
    "def preprocess_image(image, debug=False):\n",
    "    \"\"\"Convert image to grayscale and apply adaptive thresholding.\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        gray = image\n",
    "    elif len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of channels in input image.\")\n",
    "    # (Image display omitted.)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 9)\n",
    "    return thresh\n",
    "\n",
    "# -------------------------------\n",
    "# Generic OCR Functions\n",
    "# -------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"Detect text regions from thresholded image.\"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"Perform OCR on each region; returns list of (x,y,w,h,text).\"\"\"\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        logger.debug(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# DDR Pipeline\n",
    "# -------------------------------\n",
    "def process_daily_drilling_report(image_path, debug=True):\n",
    "    logger.info(f\"Processing DDR image from: {image_path}\")\n",
    "    img = safe_read_image_cv2(image_path)\n",
    "    # Coordinates for the top-right DDR region; adjust as needed.\n",
    "    coords = (1600, 0, 950, 185)\n",
    "    debug_path = os.path.join(dbfs_to_local_path(\"dbfs:/mnt/mini-proj-dd/final_results\"), \"debug_top_right.png\")\n",
    "    # Draw bounding box and crop (no image display)\n",
    "    x, y, w, h = coords\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    # Preprocess using DDR-specific method\n",
    "    if len(cropped.shape) == 2:\n",
    "        gray = cropped\n",
    "    else:\n",
    "        gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    blurred = cv2.GaussianBlur(equalized, (5,5), 0)\n",
    "    processed = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "    ocr_text = pytesseract.image_to_string(processed, config=\"--psm 6\").strip()\n",
    "    logger.info(\"DDR OCR extraction complete.\")\n",
    "    logger.debug(f\"OCR Text: {ocr_text}\")\n",
    "    expected_keys = [\"Report Date\", \"Report Num\", \"Rig\"]\n",
    "    # Extract key-value pairs from text.\n",
    "    combined = \" \".join(line.strip() for line in ocr_text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    extracted = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        extracted[key] = match.group(1).strip() if match and match.group(1).strip() else None\n",
    "    if extracted.get(\"Report Num\"):\n",
    "        m = re.search(r'^(\\d+)\\.?$', extracted[\"Report Num\"])\n",
    "        extracted[\"Report Num\"] = m.group(1) if m else extracted[\"Report Num\"]\n",
    "    df = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    return {\"DAILY DRILLING REPORT\": extracted}, df\n",
    "\n",
    "# -------------------------------\n",
    "# WELL/JOB INFORMATION Pipeline\n",
    "# -------------------------------\n",
    "def process_well_job_info(section_path, debug=True):\n",
    "    img = safe_read_image(section_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"Well/Job OCR extraction complete.\")\n",
    "    expected_keys = [\n",
    "        \"Well Name\", \"Job Name\", \"Supervisor(s)\", \"Field\", \"Sec/Twn/Rng\", \"Phone\",\n",
    "        \"AFE #\", \"API #\", \"Email\", \"Contractor\", \"Elevation\", \"RKB\",\n",
    "        \"Spud Date\", \"Days from Spud\", \"Days on Loc\", \"MD/TVD\", \"24 Hr Footage\",\n",
    "        \"Present Operations\", \"Activity Planned\"\n",
    "    ]\n",
    "    combined = \" \".join(line.strip() for line in ocr_text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*?)(?=\\s*' + re.escape(next_key) + r'\\s*:|$)'\n",
    "        else:\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*)'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        result[key] = match.group(1).strip() if match else \"\"\n",
    "    df = pd.DataFrame(list(result.items()), columns=[\"Key\", \"Value\"])\n",
    "    logger.info(f\"WELL/JOB DataFrame shape: {df.shape}\")\n",
    "    return {\"WELL/JOB INFORMATION\": result}, df\n",
    "    \n",
    "# -------------------------------\n",
    "# MUD Pipeline\n",
    "# -------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = dbfs_to_local_path(section_path)\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "def preprocess_image_mud(img, debug=True):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 9)\n",
    "    return thresh\n",
    "\n",
    "def detect_text_regions_mud(thresh_img, debug=True):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois_mud(img, rois, debug=True):\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "    return results\n",
    "\n",
    "def parse_value_row_tokens(expected_headers, tokens):\n",
    "    expected_token_count = (len(expected_headers) - 1) + 3\n",
    "    if len(tokens) < expected_token_count:\n",
    "        tokens += [\"[BLANK]\"] * (expected_token_count - len(tokens))\n",
    "    elif len(tokens) > expected_token_count:\n",
    "        tokens = tokens[:expected_token_count]\n",
    "    result = {}\n",
    "    idx = 0\n",
    "    for header in expected_headers:\n",
    "        if header == \"GELS (10s/10m/30m)\":\n",
    "            gels_tokens = tokens[idx:idx+3]\n",
    "            result[header] = {\"10s\": gels_tokens[0], \"10m\": gels_tokens[1], \"30m\": gels_tokens[2]}\n",
    "            idx += 3\n",
    "        else:\n",
    "            result[header] = tokens[idx]\n",
    "            idx += 1\n",
    "    return result\n",
    "\n",
    "def build_mud_dict_from_rois(roi_texts, expected_headers):\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line)\n",
    "    # Identify header and data rows (this logic may need adjustment)\n",
    "    header1_line = None\n",
    "    value1_line = None\n",
    "    header2_line = None\n",
    "    value2_line = None\n",
    "    for i, r_text in enumerate(row_strings):\n",
    "        if \"type\" in r_text.lower() and not header1_line:\n",
    "            header1_line = r_text\n",
    "            if i+1 < len(row_strings):\n",
    "                value1_line = row_strings[i+1]\n",
    "        elif header1_line and not header2_line and any(kw in r_text.lower() for kw in [\"rpm\", \"mud\", \"loss\", \"comments\"]):\n",
    "            header2_line = r_text\n",
    "            if i+1 < len(row_strings):\n",
    "                value2_line = row_strings[i+1]\n",
    "            break\n",
    "    if value1_line is None:\n",
    "        logger.error(\"No data row found for Mud section!\")\n",
    "        return {}\n",
    "    tokens1 = value1_line.split()\n",
    "    tokens2 = value2_line.split() if value2_line else []\n",
    "    combined_tokens = tokens1 + tokens2\n",
    "    return parse_value_row_tokens(expected_headers, combined_tokens)\n",
    "\n",
    "def process_mud(image_path, debug=True):\n",
    "    img = read_cropped_section_image(image_path)\n",
    "    thresh_img = preprocess_image_mud(img, debug=debug)\n",
    "    rois = detect_text_regions_mud(thresh_img, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois_mud(img, rois, debug=debug)\n",
    "    expected_headers = [\n",
    "        \"Type\", \"Weight In\", \"Weight Out\", \"pH\", \"CAKE\",\n",
    "        \"GELS (10s/10m/30m)\", \"Oil/Water\", \"FV\", \"ES\", \"PV\",\n",
    "        \"YP\", \"CL\", \"Ca\", \"LGS\", \"WL\", \"HTHP Loss\", \"3 RPM\",\n",
    "        \"6 RPM\", \"Mud Pits and Hole Volume\", \"24 Hr Loss\",\n",
    "        \"Total Loss\", \"Comments\"\n",
    "    ]\n",
    "    mud_dict = build_mud_dict_from_rois(roi_texts, expected_headers)\n",
    "    # If mud_dict is a dict, convert to DataFrame of key-value pairs; else assume list.\n",
    "    if isinstance(mud_dict, dict):\n",
    "        df = pd.DataFrame(list(mud_dict.items()), columns=[\"Key\", \"Value\"])\n",
    "    else:\n",
    "        df = pd.DataFrame(mud_dict)\n",
    "    return {\"MUD\": mud_dict}, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3) Survey Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def build_survey_dict_from_rois(roi_texts, expected_headers):\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "    \n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line)\n",
    "        logger.info(f\"Grouped Row {i}: {line}\")\n",
    "    \n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for subline in line.split(\"\\n\"):\n",
    "            subline = subline.strip()\n",
    "            if subline:\n",
    "                all_lines.append(subline)\n",
    "    logger.info(f\"All extracted lines: {all_lines}\")\n",
    "    \n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        if \"md\" in lower_tokens and \"inclination\" in lower_tokens:\n",
    "            logger.info(f\"Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"Line has fewer tokens than expected: {tokens}\")\n",
    "            continue\n",
    "        tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    \n",
    "    survey_list = []\n",
    "    for tokens in data_lines:\n",
    "        row_dict = {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        survey_list.append(row_dict)\n",
    "    return survey_list\n",
    "\n",
    "def sort_survey_data(survey_list):\n",
    "    def md_value(row):\n",
    "        try:\n",
    "            return float(row[\"MD\"].replace(\",\", \"\"))\n",
    "        except Exception:\n",
    "            return 0\n",
    "    sorted_list = sorted(survey_list, key=md_value, reverse=False)\n",
    "    filtered_list = [row for row in sorted_list if not row[\"MD\"].upper().startswith(\"SURVEY\")]\n",
    "    return filtered_list\n",
    "\n",
    "def process_survey(survey_img_path, debug=True):\n",
    "    expected_headers = [\"MD\", \"Inclination\", \"Azimuth\", \"DLS\", \"TVD\"]\n",
    "    img = safe_read_image(survey_img_path)\n",
    "    # if debug:\n",
    "        # show_image(\"Original Survey Image\", img, size=(12,12))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    # if debug:\n",
    "        # show_image(\"Adaptive Threshold\", thresh, cmap=\"gray\")\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    roi_texts = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        roi_texts.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    survey_list = build_survey_dict_from_rois(roi_texts, expected_headers)\n",
    "    survey_list = sort_survey_data(survey_list)\n",
    "    final_output = {\"SURVEY DATA\": survey_list}\n",
    "    df = pd.DataFrame(survey_list)\n",
    "    return final_output, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4) BOP Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def process_bop(ocr_text, debug= True):\n",
    "    pattern = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in pattern.items():\n",
    "        match = re.search(regex, ocr_text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    return result\n",
    "\n",
    "def process_bop(section_path, debug=False):\n",
    "    img = safe_read_image(section_path)\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"BOP OCR extraction complete.\")\n",
    "    patterns = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in patterns.items():\n",
    "        match = re.search(regex, ocr_text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    df = pd.DataFrame(list(result.items()), columns=[\"Key\", \"Value\"])\n",
    "    logger.info(f\"BOP DataFrame shape: {df.shape}\")\n",
    "    return {\"BOP\": result}, df\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 6) BHA Extraction process\n",
    "# ---------------------------------------------------------------------\n",
    "def extract_bha_data(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, ocr_text)\n",
    "        if match:\n",
    "            bha_data[key] = match.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for remove_key in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if remove_key in bha_data:\n",
    "                detail = re.sub(rf\"{remove_key}:\\s*{re.escape(bha_data[remove_key])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured_data = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    return structured_data\n",
    "\n",
    "def process_bha(bha_img_path, debug=True):\n",
    "    bha_json = extract_bha_data(bha_img_path)\n",
    "    df = pd.json_normalize(bha_json[\"BHA\"])\n",
    "    return {\"BHA\": bha_json[\"BHA\"]}, df\n",
    "\n",
    "# -------------------------------\n",
    "# BHA Pipeline\n",
    "# -------------------------------\n",
    "def process_bha(image_path, debug=True):\n",
    "    bha_data = extract_bha_data(image_path)\n",
    "    df = pd.DataFrame([bha_data.get(\"BHA\", {})])\n",
    "    return {\"BHA\": bha_data.get(\"BHA\", {})}, df\n",
    "\n",
    "def extract_bha_data(image_path):\n",
    "    image = safe_read_image_pil(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",\n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    bha_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, ocr_text)\n",
    "        if match:\n",
    "            bha_data[key] = match.group(1).strip()\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for remove_key in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if remove_key in bha_data:\n",
    "                detail = re.sub(rf\"{remove_key}:\\s*{re.escape(bha_data[remove_key])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail\n",
    "    structured_data = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")\n",
    "        }\n",
    "    }\n",
    "    return structured_data\n",
    "\n",
    "# -------------------------------\n",
    "# Bit Info Pipeline\n",
    "# -------------------------------\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def adaptive_threshold(image):\n",
    "    return cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 9)\n",
    "\n",
    "def detect_text_regions_bit(image, debug=False):\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    return rois\n",
    "\n",
    "def perform_ocr_on_rois_bit(img, rois, debug=False):\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip() or \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        logger.debug(f\"Bit Info OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n",
    "\n",
    "def build_bit_info_dict_from_rois(roi_texts, debug=False):\n",
    "    row_tolerance = 10\n",
    "    grouped_rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            grouped_rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        grouped_rows.append(current_row)\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(grouped_rows):\n",
    "        row.sort(key=lambda cell: cell[0])\n",
    "        line = \" \".join(cell[4] for cell in row).replace(\"\\n\", \" \").strip()\n",
    "        row_strings.append(line)\n",
    "        logger.info(f\"Bit Info Row {i}: {line}\")\n",
    "    if len(row_strings) < 3:\n",
    "        logger.warning(\"Not enough rows found for Bit Info layout.\")\n",
    "        return [], pd.DataFrame()\n",
    "    data_lines = row_strings[3:]\n",
    "    final_columns = [\n",
    "        \"Bit #\", \"Size\", \"Make\", \"Model\", \"Serial #\",\n",
    "        \"Nozzle-(Number x Size)\", \"Nozzle-TFA\",\n",
    "        \"Depth-In\", \"Depth-Out\", \"Depth-Feet\", \"Depth-ROP\",\n",
    "        \"Hours-Total\", \"Hours-On Btm\",\n",
    "        \"Dull Grade-I\", \"Dull Grade-O1\", \"Dull Grade-D\", \"Dull Grade-L\", \n",
    "        \"Dull Grade-B\", \"Dull Grade-G\", \"Dull Grade-O2\", \"Dull Grade-RP\"\n",
    "    ]\n",
    "    structured_data = []\n",
    "    for line in data_lines:\n",
    "        tokens = line.split()\n",
    "        if len(tokens) < 21:\n",
    "            tokens += [\"\"] * (21 - len(tokens))\n",
    "        elif len(tokens) > 21:\n",
    "            tokens = tokens[:21]\n",
    "        row_dict = {final_columns[i]: tokens[i] for i in range(21)}\n",
    "        structured_data.append(row_dict)\n",
    "        logger.info(f\"Bit Info Parsed row: {row_dict}\")\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    return structured_data, df\n",
    "\n",
    "def process_bit_info(image_path, debug=False):\n",
    "    img = safe_read_image_cv2(image_path)\n",
    "    gray = get_grayscale(img)\n",
    "    thresh = adaptive_threshold(gray)\n",
    "    rois = detect_text_regions_bit(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois_bit(img, rois, debug=debug)\n",
    "    bit_info_data, df = build_bit_info_dict_from_rois(roi_texts, debug=debug)\n",
    "    return {\"BIT INFO\": bit_info_data}, df\n",
    "\n",
    "# -------------------------------\n",
    "# DAILY NUMBERS: OBSERVATION & INTERVENTION Pipeline\n",
    "# -------------------------------\n",
    "def process_obs_int(image_path, debug=False):\n",
    "    img = safe_read_image_cv2(image_path)\n",
    "    thresh = preprocess_image(img, debug=debug)\n",
    "    rois = detect_text_regions(thresh, debug=debug)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=debug)\n",
    "    # Collect texts; filter out header words.\n",
    "    types_list = []\n",
    "    numbers_list = []\n",
    "    for (_, _, _, _, text) in roi_texts:\n",
    "        clean = text.strip()\n",
    "        if clean.lower() in [\"daily numbers: observation & intervention\", \"number\", \"[blank]\"]:\n",
    "            continue\n",
    "        # If text can be converted to a number, assume it is a number.\n",
    "        try:\n",
    "            float(clean)\n",
    "            numbers_list.append(clean)\n",
    "        except ValueError:\n",
    "            types_list.append(clean)\n",
    "    # Use the maximum count from either list.\n",
    "    count = max(len(types_list), len(numbers_list))\n",
    "    # Pad lists if necessary.\n",
    "    while len(types_list) < count:\n",
    "        types_list.append(\"\")\n",
    "    while len(numbers_list) < count:\n",
    "        numbers_list.append(\"\")\n",
    "    structured = [{\"Type\": types_list[i], \"Number\": numbers_list[i]} for i in range(count)]\n",
    "    df = pd.DataFrame(structured)\n",
    "    return {\"DAILY NUMBERS: OBSERVATION & INTERVENTION\": structured}, df\n",
    "\n",
    "# -------------------------------\n",
    "# Aggregator Main Process\n",
    "# -------------------------------\n",
    "def main():\n",
    "    debug = True  # Set True for verbose logging.\n",
    "    \n",
    "    # Define image paths for all sections.\n",
    "    image_paths = {\n",
    "        \"DAILY DRILLING REPORT\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_1.png\",\n",
    "        \"WELL/JOB INFORMATION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_2.png\",\n",
    "        \"MUD\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\",\n",
    "        \"SURVEY DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_4.png\",\n",
    "        \"DIR INFO\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_5.png\",\n",
    "        \"DRILL BITS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_6.png\",\n",
    "        \"CASING\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_7.png\",\n",
    "        \"BOP\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_8.png\",\n",
    "        \"PERSONNEL\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_9.png\",\n",
    "        \"DAILY NUMBERS: OBSERVATION & INTERVENTION\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_10.png\",\n",
    "        \"BHA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png\",\n",
    "        \"PUMPS\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_12.png\",\n",
    "        \"COST DATA\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\",\n",
    "        \"TIME BREAKDOWN\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_14.png\",\n",
    "        \"CONSUMABLES\": \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_2_section_2.png\"\n",
    "    }\n",
    "    \n",
    "    # Define output folder.\n",
    "    output_folder = dbfs_to_local_path(\"dbfs:/mnt/mini-proj-dd/final_results\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    aggregated_json = {}\n",
    "    aggregated_df = pd.DataFrame()\n",
    "    \n",
    "    # Define processing order as tuples: (Section Name, processing function, image path)\n",
    "    processes = [\n",
    "        (\"DAILY DRILLING REPORT\", process_daily_drilling_report, image_paths.get(\"DAILY DRILLING REPORT\")),\n",
    "        (\"WELL/JOB INFORMATION\", process_well_job_info, image_paths.get(\"WELL/JOB INFORMATION\")),\n",
    "        (\"MUD\", process_mud, image_paths.get(\"MUD\")),\n",
    "        (\"SURVEY DATA\", process_survey, image_paths.get(\"SURVEY DATA\")),\n",
    "        (\"DIR INFO\", process_dir_info, image_paths.get(\"DIR INFO\")),\n",
    "        (\"DRILL BITS\", process_drill_bits, image_paths.get(\"DRILL BITS\")),\n",
    "        (\"CASING\", process_casing, image_paths.get(\"CASING\")),\n",
    "        (\"BOP\", process_bop, image_paths.get(\"BOP\")),\n",
    "        (\"PERSONNEL\", process_personnel, image_paths.get(\"PERSONNEL\")),\n",
    "        (\"DAILY NUMBERS: OBSERVATION & INTERVENTION\", process_obs_int, image_paths.get(\"DAILY NUMBERS: OBSERVATION & INTERVENTION\")),\n",
    "        (\"BHA\", process_bha, image_paths.get(\"BHA\")),\n",
    "        (\"PUMPS\", process_pumps, image_paths.get(\"PUMPS\")),\n",
    "        (\"COST DATA\", process_cost_data, image_paths.get(\"COST DATA\")),\n",
    "        (\"TIME BREAKDOWN\", process_time_breakdown, image_paths.get(\"TIME BREAKDOWN\")),\n",
    "        (\"CONSUMABLES\", process_consumables, image_paths.get(\"CONSUMABLES\"))\n",
    "    ]\n",
    "    \n",
    "    for section, func, img_path in processes:\n",
    "        try:\n",
    "            logger.info(f\"Processing section: {section}\")\n",
    "            data_json, df = func(img_path, debug)\n",
    "            safe_section = sanitize_section_name(section)\n",
    "            aggregated_json[section] = data_json.get(section, data_json)\n",
    "            aggregated_df = pd.concat([aggregated_df, df], ignore_index=True)\n",
    "            logger.info(f\"{section} output:\\n{json.dumps(data_json, indent=4)}\")\n",
    "            section_json_file = os.path.join(output_folder, f\"{safe_section}.json\")\n",
    "            with open(section_json_file, \"w\") as f:\n",
    "                json.dump(data_json, f, indent=4)\n",
    "            section_csv_file = os.path.join(output_folder, f\"{safe_section}.csv\")\n",
    "            df.to_csv(section_csv_file, index=False)\n",
    "            logger.info(f\"Saved {section} outputs to JSON and CSV.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{section} processing failed: {e}\")\n",
    "    \n",
    "    agg_json_path = os.path.join(output_folder, \"aggregated_data.json\")\n",
    "    with open(agg_json_path, \"w\") as f:\n",
    "        json.dump(aggregated_json, f, indent=4)\n",
    "    agg_csv_path = os.path.join(output_folder, \"aggregated_data.csv\")\n",
    "    aggregated_df.to_csv(agg_csv_path, index=False)\n",
    "    logger.info(f\"Aggregated outputs saved to {agg_json_path} and {agg_csv_path}.\")\n",
    "    print(\"----- Aggregated JSON Output -----\")\n",
    "    print(json.dumps(aggregated_json, indent=4))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d885b8-56fc-4cf0-9f04-6889262ffb2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1bb4e1-c885-4fb7-ab6c-11c0a0290b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "try_modularize",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
