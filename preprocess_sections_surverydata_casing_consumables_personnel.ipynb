{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebb6b9e-a0f0-405a-ba65-44db293f3df9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"SurveyExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a DBFS or local path.\n",
    "    \"\"\"\n",
    "    if img_path.startswith(\"dbfs:\"):\n",
    "        local_path = img_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "    else:\n",
    "        local_path = img_path\n",
    "    logger.info(f\"Trying to read image from: {local_path}\")\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to read the image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns a list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_survey_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_survey_dict_from_rois(roi_texts, expected_headers):\n",
    "    \"\"\"\n",
    "    Groups OCR results (list of (x,y,w,h,text)) into rows by y coordinate,\n",
    "    joins text for each row, splits them by newline and multiple spaces,\n",
    "    then parses each candidate row into tokens.\n",
    "    Only rows with at least len(expected_headers) tokens are kept.\n",
    "    Returns a list of dictionaries (one per valid row).\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    # Group by similar y coordinate.\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    # Join texts in each row (sorted by x) and log.\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda c: c[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line)\n",
    "        logger.info(f\"Grouped Row {i}: {line}\")\n",
    "    \n",
    "    # Split joined rows by newline if present.\n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        split_lines = line.split(\"\\n\")\n",
    "        for subline in split_lines:\n",
    "            subline = subline.strip()\n",
    "            if subline:\n",
    "                all_lines.append(subline)\n",
    "    logger.info(f\"All extracted lines: {all_lines}\")\n",
    "    \n",
    "    # Filter out header lines (if they contain known column names) and parse rows.\n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        # Split using multiple spaces.\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        if \"md\" in lower_tokens and \"inclination\" in lower_tokens:\n",
    "            logger.info(f\"Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"Line has fewer tokens than expected: {tokens}\")\n",
    "            continue\n",
    "        # If extra tokens exist, take only the first expected_headers number.\n",
    "        tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    \n",
    "    logger.info(f\"Data lines to parse: {data_lines}\")\n",
    "    \n",
    "    # Build list of dictionaries.\n",
    "    survey_list = []\n",
    "    for tokens in data_lines:\n",
    "        row_dict = {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        survey_list.append(row_dict)\n",
    "    return survey_list\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# sort_survey_data\n",
    "# ---------------------------------------------------------------------\n",
    "def sort_survey_data(survey_list):\n",
    "    \"\"\"\n",
    "    Sorts the survey list in descending order based on the MD value.\n",
    "    MD values are expected as strings with commas (e.g., \"20,286\").\n",
    "    \"\"\"\n",
    "    def md_value(row):\n",
    "        try:\n",
    "            return float(row[\"MD\"].replace(\",\", \"\"))\n",
    "        except Exception:\n",
    "            return 0\n",
    "    sorted_list = sorted(survey_list, key=md_value, reverse=True)\n",
    "    return sorted_list\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_survey_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_survey_pipeline():\n",
    "    # Expected columns for the survey table.\n",
    "    expected_headers = [\"MD\", \"Inclination\", \"Azimuth\", \"DLS\", \"TVD\"]\n",
    "    \n",
    "    # Set the path to your survey image.\n",
    "    survey_img_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_4.png\"\n",
    "    \n",
    "    try:\n",
    "        img = safe_read_image(survey_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Display the original image.\n",
    "    show_image(\"Original Survey Image\", img, size=(12,12))\n",
    "    \n",
    "    # Preprocess the image.\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    \n",
    "    # Detect text regions.\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    \n",
    "    # Perform OCR on each detected region.\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # Log the raw OCR outputs.\n",
    "    for i, (x, y, w, h, text) in enumerate(roi_texts):\n",
    "        logger.info(f\"OCR Box {i}: {text}\")\n",
    "    \n",
    "    # Build the survey data rows from OCR results.\n",
    "    survey_list = build_survey_dict_from_rois(roi_texts, expected_headers)\n",
    "    \n",
    "    # Sort survey data by MD (descending) to match desired order.\n",
    "    survey_list = sort_survey_data(survey_list)\n",
    "    \n",
    "    final_output = {\"SURVEY DATA\": survey_list}\n",
    "    logger.info(\"===== FINAL SURVEY DATA =====\")\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    \n",
    "    # Create and print a DataFrame.\n",
    "    df = pd.DataFrame(survey_list)\n",
    "    print(\"----- Extracted DataFrame -----\")\n",
    "    print(df)\n",
    "    \n",
    "    # Save outputs as JSON and CSV.\n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_survey_results\"\n",
    "    local_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_folder, exist_ok=True)\n",
    "    \n",
    "    out_json = os.path.join(local_folder, \"survey_data.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    logger.info(f\"JSON saved to {out_json}\")\n",
    "    \n",
    "    out_csv = os.path.join(local_folder, \"survey_data.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    logger.info(f\"CSV saved to {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_survey_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f5c7bac-cd1d-4e27-a0be-1ef8ce3102d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"CasingExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a DBFS or local path.\n",
    "    \"\"\"\n",
    "    if img_path.startswith(\"dbfs:\"):\n",
    "        local_path = img_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "    else:\n",
    "        local_path = img_path\n",
    "    logger.info(f\"Trying to read image from: {local_path}\")\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to read the image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    # Sort by y (top-to-bottom) then by x (left-to-right)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns a list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_casing_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_casing_dict_from_rois(roi_texts, expected_headers):\n",
    "    \"\"\"\n",
    "    Groups OCR results (list of (x, y, w, h, text)) into rows by y coordinate,\n",
    "    joins text for each row (sorted by x), then parses each row into tokens.\n",
    "    Rows containing header keywords (e.g., column names) are skipped.\n",
    "    Returns a list of dictionaries (one per valid row).\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    # Group by similar y-coordinate.\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    # Join texts in each row (sorted by x)\n",
    "    row_strings = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda c: c[0])\n",
    "        line = \" \".join(cell[4] for cell in row)\n",
    "        row_strings.append(line.strip())\n",
    "        logger.info(f\"Grouped Row {i}: {line}\")\n",
    "\n",
    "    # Split joined rows by newline if present.\n",
    "    all_lines = []\n",
    "    for line in row_strings:\n",
    "        for subline in line.split(\"\\n\"):\n",
    "            subline = subline.strip()\n",
    "            if subline:\n",
    "                all_lines.append(subline)\n",
    "    logger.info(f\"All extracted lines: {all_lines}\")\n",
    "\n",
    "    # Filter out header-like lines and build the data rows.\n",
    "    data_lines = []\n",
    "    for line in all_lines:\n",
    "        tokens = re.split(r'\\s{2,}', line)\n",
    "        if len(tokens) == 1:\n",
    "            tokens = line.split()\n",
    "        lower_tokens = [t.lower() for t in tokens]\n",
    "        # Skip rows that contain header keywords.\n",
    "        if \"type\" in lower_tokens and \"size\" in lower_tokens:\n",
    "            logger.info(f\"Skipping header line: {tokens}\")\n",
    "            continue\n",
    "        if len(tokens) < len(expected_headers):\n",
    "            logger.warning(f\"Line has fewer tokens than expected: {tokens}\")\n",
    "            continue\n",
    "        tokens = tokens[:len(expected_headers)]\n",
    "        data_lines.append(tokens)\n",
    "    \n",
    "    logger.info(f\"Data lines to parse: {data_lines}\")\n",
    "\n",
    "    # Build list of dictionaries.\n",
    "    casing_list = []\n",
    "    for tokens in data_lines:\n",
    "        row_dict = {expected_headers[i]: tokens[i] for i in range(len(expected_headers))}\n",
    "        casing_list.append(row_dict)\n",
    "    return casing_list\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_casing_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_casing_pipeline():\n",
    "    # Expected columns for the casing table.\n",
    "    expected_headers = [\"Type\", \"Size\", \"Weight\", \"Grade\", \"Connection\", \"Top MD\", \"Bottom MD\", \"TOC\"]\n",
    "    \n",
    "    # Set the path to your casing image.\n",
    "    casing_img_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_7.png\"\n",
    "    \n",
    "    try:\n",
    "        img = safe_read_image(casing_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Display the original image.\n",
    "    show_image(\"Original Casing Image\", img, size=(12,12))\n",
    "    \n",
    "    # Preprocess the image.\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    \n",
    "    # Detect text regions.\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    \n",
    "    # Perform OCR on each detected region.\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # Log the raw OCR outputs.\n",
    "    for i, (x, y, w, h, text) in enumerate(roi_texts):\n",
    "        logger.info(f\"OCR Box {i}: {text}\")\n",
    "    \n",
    "    # Build the casing data rows from OCR results.\n",
    "    casing_list = build_casing_dict_from_rois(roi_texts, expected_headers)\n",
    "    \n",
    "    # Create final output dictionary.\n",
    "    final_output = {\"CASING\": casing_list}\n",
    "    logger.info(\"===== FINAL CASING DATA =====\")\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    \n",
    "    # Create and print a DataFrame.\n",
    "    df = pd.DataFrame(casing_list)\n",
    "    print(\"----- Extracted DataFrame -----\")\n",
    "    print(df)\n",
    "    \n",
    "    # Save outputs as JSON and CSV.\n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_casing_results\"\n",
    "    local_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_folder, exist_ok=True)\n",
    "    \n",
    "    out_json = os.path.join(local_folder, \"casing_data.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    logger.info(f\"JSON saved to {out_json}\")\n",
    "    \n",
    "    out_csv = os.path.join(local_folder, \"casing_data.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    logger.info(f\"CSV saved to {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_casing_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3d6b6c-2c59-4a6b-ac3f-980d537aa9c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"consumablesExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility: show_image\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10,10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# safe_read_image\n",
    "# ---------------------------------------------------------------------\n",
    "def safe_read_image(img_path):\n",
    "    \"\"\"\n",
    "    Reads an image from a DBFS or local path.\n",
    "    \"\"\"\n",
    "    if img_path.startswith(\"dbfs:\"):\n",
    "        local_path = img_path.replace(\"dbfs:\", \"/dbfs\")\n",
    "    else:\n",
    "        local_path = img_path\n",
    "    logger.info(f\"Trying to read image from: {local_path}\")\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to read the image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=False):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale and applies adaptive thresholding.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap=\"gray\")\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 15, 9\n",
    "    )\n",
    "    if debug:\n",
    "        show_image(\"2) Thresholded\", thresh, cmap=\"gray\")\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=False):\n",
    "    \"\"\"\n",
    "    Detects text regions (bounding boxes) from the thresholded image.\n",
    "    \"\"\"\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # A basic size filter to skip very small or very thin boxes\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "    # Sort by y then x\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "        for (x, y, w, h) in rois:\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "        show_image(\"3) Detected Regions\", debug_img)\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=False):\n",
    "    \"\"\"\n",
    "    Performs OCR on each detected text region.\n",
    "    Returns a list of tuples: (x, y, w, h, text).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for (x, y, w, h) in rois:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config=\"--psm 6\").strip()\n",
    "        # Replace empty OCR results with a placeholder.\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug:\n",
    "            logger.info(f\"OCR Box ({x},{y},{w},{h}): {text}\")\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_consumables_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_consumables_dict_from_rois(roi_texts):\n",
    "    \"\"\"\n",
    "    Groups OCR results into rows based on similar y-coordinate.\n",
    "    Skips header rows and selects only data rows.\n",
    "    Then, for each data row, it parses tokens to produce exactly five columns:\n",
    "      \"Consumable\", \"Daily Received (gal)\", \"Daily Used (gal)\",\n",
    "      \"Cumulative Used (gal)\", \"Daily on Hand (gal)\"\n",
    "    We keep \"[BLANK]\" tokens so each row has exactly 5 columns, even if\n",
    "    some columns are blank.\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    # Join texts in each row (sorted by x)\n",
    "    grouped_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        row.sort(key=lambda cell: cell[0])  # sort by x-coordinate\n",
    "        line = \" \".join(cell[4] for cell in row).strip()\n",
    "        grouped_rows.append(line)\n",
    "        logger.info(f\"Grouped Row {i}: {line}\")\n",
    "\n",
    "    # Filter out header or unwanted rows by checking for keywords\n",
    "    data_rows = []\n",
    "    for line in grouped_rows:\n",
    "        lower_line = line.lower()\n",
    "        # Skip lines that look like headers\n",
    "        if (\"consumable\" in lower_line and \"received\" in lower_line) or \"nun\" in lower_line:\n",
    "            continue\n",
    "        # If too few tokens, skip\n",
    "        if len(line.split()) < 5:\n",
    "            continue\n",
    "        data_rows.append(line)\n",
    "\n",
    "    logger.info(f\"Data rows to parse: {data_rows}\")\n",
    "\n",
    "    consumables_list = []\n",
    "    for line in data_rows:\n",
    "        # First split on single or multiple spaces\n",
    "        tokens = re.split(r'\\s+', line)\n",
    "        # ---------------------------------------------------------------------\n",
    "        # IMPORTANT CHANGE: Do NOT remove \"[BLANK]\" tokens here.\n",
    "        # ---------------------------------------------------------------------\n",
    "        # If there are more than 5 tokens, merge extras into the first field\n",
    "        # so we end up with exactly 5 tokens total.\n",
    "        if len(tokens) > 5:\n",
    "            # everything except the last 4 tokens becomes \"Consumable\"\n",
    "            first = \" \".join(tokens[:-4])\n",
    "            last4 = tokens[-4:]\n",
    "            tokens = [first] + last4\n",
    "\n",
    "        # Now we must have exactly 5 tokens to parse\n",
    "        if len(tokens) != 5:\n",
    "            logger.warning(f\"Skipping row (unexpected token count): {tokens}\")\n",
    "            continue\n",
    "\n",
    "        row_dict = {\n",
    "            \"Consumable\":             tokens[0],\n",
    "            \"Daily Received (gal)\":   tokens[1],\n",
    "            \"Daily Used (gal)\":       tokens[2],\n",
    "            \"Cumulative Used (gal)\":  tokens[3],\n",
    "            \"Daily on Hand (gal)\":    tokens[4]\n",
    "        }\n",
    "        consumables_list.append(row_dict)\n",
    "\n",
    "    return consumables_list\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_consumables_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_consumables_pipeline():\n",
    "    # Set the path to your consumables image.\n",
    "    consumables_img_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_2_section_2.png\"\n",
    "    \n",
    "    try:\n",
    "        img = safe_read_image(consumables_img_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Display the original image (optional).\n",
    "    show_image(\"Original consumables Image\", img, size=(12,12))\n",
    "    \n",
    "    # Preprocess the image.\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    \n",
    "    # Detect text regions.\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    \n",
    "    # Perform OCR on each detected region.\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # Log the raw OCR outputs.\n",
    "    for i, (x, y, w, h, text) in enumerate(roi_texts):\n",
    "        logger.info(f\"OCR Box {i}: {text}\")\n",
    "    \n",
    "    # Build the consumables data rows from OCR results.\n",
    "    consumables_list = build_consumables_dict_from_rois(roi_texts)\n",
    "    \n",
    "    # Create final output dictionary.\n",
    "    final_output = {\"CONSUMABLES\": consumables_list}\n",
    "    logger.info(\"===== FINAL CONSUMABLES DATA =====\")\n",
    "    logger.info(json.dumps(final_output, indent=4))\n",
    "    \n",
    "    # Create and print a DataFrame.\n",
    "    df = pd.DataFrame(consumables_list)\n",
    "    print(\"----- Extracted DataFrame -----\")\n",
    "    print(df)\n",
    "    \n",
    "    # Save outputs as JSON and CSV.\n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_consumables_results\"\n",
    "    local_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_folder, exist_ok=True)\n",
    "    \n",
    "    out_json = os.path.join(local_folder, \"consumables_data.json\")\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump(final_output, f, indent=4)\n",
    "    logger.info(f\"JSON saved to {out_json}\")\n",
    "    \n",
    "    out_csv = os.path.join(local_folder, \"consumables_data.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    logger.info(f\"CSV saved to {out_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_consumables_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a526fca-c9ff-4777-810d-0f5a28de5a78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"PersonnelExtractor\")\n",
    "logger.setLevel(logging.DEBUG)  # Debug mode on for detailed logging.\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    logger.info(f\"Image loaded from {local_path} with shape {img.shape}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) Show Image Utility (for debugging)\n",
    "# --------------------------------------------------------\n",
    "def show_image(title, img, size=(10, 10)):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Detect Text Regions in Thresholded Image\n",
    "# --------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=True):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        # Use a size filter to ignore very small regions.\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    logger.debug(f\"Detected {len(rois)} text regions.\")\n",
    "    if debug:\n",
    "        show_image(\"Detected Text Regions\", debug_img, size=(12, 12))\n",
    "    return rois\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Perform OCR on Detected ROIs\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=True):\n",
    "    results = []\n",
    "    n = len(rois)\n",
    "    if debug and n > 0:\n",
    "        cols = 5\n",
    "        rows = math.ceil(n / cols)\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "        if rows == 1:\n",
    "            axes = [axes] if n == 1 else axes.flatten()\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        logger.debug(f\"ROI {i+1}: bbox=({x}, {y}, {w}, {h}), extracted text: '{text}'\")\n",
    "        if debug and i < len(axes):\n",
    "            roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(roi_rgb)\n",
    "            axes[i].set_title(f\"ROI {i+1}\\n{text[:30]}...\")\n",
    "            axes[i].axis(\"off\")\n",
    "    if debug and n > 0:\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return results\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 6) Group ROIs into Rows Based on Vertical Center\n",
    "# --------------------------------------------------------\n",
    "def group_rois_by_row(roi_results, threshold=20):\n",
    "    # Compute the y-center for each ROI and sort by that value.\n",
    "    roi_with_center = [(x, y, w, h, text, y + h/2) for (x, y, w, h, text) in roi_results]\n",
    "    roi_with_center.sort(key=lambda r: r[5])\n",
    "    groups = []\n",
    "    current_group = []\n",
    "    current_center = None\n",
    "    for roi in roi_with_center:\n",
    "        x, y, w, h, text, y_center = roi\n",
    "        if current_center is None:\n",
    "            current_center = y_center\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        elif abs(y_center - current_center) < threshold:\n",
    "            current_group.append((x, y, w, h, text))\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [(x, y, w, h, text)]\n",
    "            current_center = y_center\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "    logger.debug(f\"Grouped ROIs into {len(groups)} rows.\")\n",
    "    return groups\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 7) Parse Grouped Rows into Structured Data\n",
    "# --------------------------------------------------------\n",
    "def preprocess_personnel_data_from_rows(groups):\n",
    "    \"\"\"\n",
    "    For each grouped row, sort the regions by x-coordinate and join texts.\n",
    "    Expected columns:\n",
    "      Company, Contractor, No. Personnel, Daily Hours, Cumulative Hours.\n",
    "    - If row starts with \"Totals\" (case-insensitive), treat it as Totals.\n",
    "    - If 3 or more numeric tokens are present, take the last 3 as numbers.\n",
    "    - If only 1 numeric token is present, log the values and leave missing values as None.\n",
    "    \"\"\"\n",
    "    personnel_data = []\n",
    "    \n",
    "    # Define a set of header lines to skip (exact matches or lower-case versions)\n",
    "    header_lines = {\n",
    "        \"personnel\", \n",
    "        \"company contractor no. personnel daily hours cumulative hours\",\n",
    "        \"ssn\"\n",
    "    }\n",
    "    \n",
    "    for group in groups:\n",
    "        # Sort each group by x coordinate.\n",
    "        group.sort(key=lambda r: r[0])\n",
    "        row_text = \" \".join([r[4] for r in group]).strip()\n",
    "        logger.debug(f\"Processing row: '{row_text}'\")\n",
    "        \n",
    "        # Skip if the row exactly matches a known header (case-insensitive)\n",
    "        if row_text.lower() in header_lines:\n",
    "            logger.debug(\"Skipping header row.\")\n",
    "            continue\n",
    "\n",
    "        tokens = row_text.split()\n",
    "        numeric_tokens = re.findall(r'\\d+(?:\\.\\d+)?', row_text)\n",
    "        logger.debug(f\"Row tokens: {tokens}\")\n",
    "        logger.debug(f\"Numeric tokens found: {numeric_tokens}\")\n",
    "\n",
    "        # Handle Totals row\n",
    "        if tokens[0].lower().startswith(\"totals\"):\n",
    "            if len(numeric_tokens) >= 2:\n",
    "                try:\n",
    "                    daily_hours = int(float(numeric_tokens[0]))\n",
    "                    cumulative_hours = numeric_tokens[1]  # Keeping as string per expected output\n",
    "                except ValueError as e:\n",
    "                    logger.error(f\"Error parsing Totals row: {row_text} => {e}\")\n",
    "                    continue\n",
    "                row_dict = {\n",
    "                    \"Company\": \"\",\n",
    "                    \"Contractor\": \"\",\n",
    "                    \"No. Personnel\": \"Totals\",\n",
    "                    \"Daily Hours\": daily_hours,\n",
    "                    \"Cumulative Hours\": cumulative_hours\n",
    "                }\n",
    "                logger.info(f\"Totals row parsed: {row_dict}\")\n",
    "                personnel_data.append(row_dict)\n",
    "            else:\n",
    "                logger.warning(f\"Totals row without sufficient numbers: {row_text}\")\n",
    "            continue\n",
    "\n",
    "        if len(numeric_tokens) >= 3:\n",
    "            try:\n",
    "                no_personnel = int(float(numeric_tokens[-3]))\n",
    "                daily_hours = int(float(numeric_tokens[-2]))\n",
    "                cumulative_hours = int(float(numeric_tokens[-1]))\n",
    "                logger.debug(f\"Extracted values: no_personnel={no_personnel}, daily_hours={daily_hours}, cumulative_hours={cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting numbers in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            # Remove the numeric tokens from the end.\n",
    "            pattern = (r'\\s*' + re.escape(numeric_tokens[-3]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-2]) +\n",
    "                       r'\\s+' + re.escape(numeric_tokens[-1]) + r'\\s*$')\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        elif len(numeric_tokens) == 1:\n",
    "            try:\n",
    "                cumulative_hours = int(float(numeric_tokens[0]))\n",
    "                logger.debug(f\"Single numeric token found. Extracted cumulative_hours: {cumulative_hours}\")\n",
    "            except ValueError as e:\n",
    "                logger.error(f\"Error converting single number in row: {row_text} => {e}\")\n",
    "                continue\n",
    "            # Instead of defaulting to 7 and 84, we now set missing values to None\n",
    "            no_personnel = None\n",
    "            daily_hours = None\n",
    "            pattern = r'\\s*' + re.escape(numeric_tokens[0]) + r'\\s*$'\n",
    "            text_only = re.sub(pattern, '', row_text).strip()\n",
    "        else:\n",
    "            logger.warning(f\"Row has an unexpected number of numeric tokens: {row_text}\")\n",
    "            continue\n",
    "\n",
    "        # Split text_only into Company and Contractor if possible.\n",
    "        if \"service company\" in text_only.lower():\n",
    "            parts = re.split(r'(?i)service company', text_only, maxsplit=1)\n",
    "            company = parts[0].strip()\n",
    "            contractor = \"Service Company\"\n",
    "        else:\n",
    "            company = text_only\n",
    "            contractor = \"Service Company\"\n",
    "        \n",
    "        row_dict = {\n",
    "            \"Company\": company,\n",
    "            \"Contractor\": contractor,\n",
    "            \"No. Personnel\": no_personnel,\n",
    "            \"Daily Hours\": daily_hours,\n",
    "            \"Cumulative Hours\": cumulative_hours\n",
    "        }\n",
    "        logger.info(f\"Parsed row: {row_dict}\")\n",
    "        personnel_data.append(row_dict)\n",
    "    return {\"PERSONNEL\": personnel_data}\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 8) Main Pipeline\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_9.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    # Preprocess image: grayscale and adaptive threshold.\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "    show_image(\"Thresholded Image\", cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR), size=(8, 8))\n",
    "    \n",
    "    # Detect text regions.\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    # Perform OCR on each ROI.\n",
    "    roi_results = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    # Group ROIs into rows using vertical center.\n",
    "    grouped_rows = group_rois_by_row(roi_results, threshold=20)\n",
    "    logger.debug(f\"Grouped rows: {grouped_rows}\")\n",
    "    \n",
    "    # Parse grouped rows into structured personnel data.\n",
    "    data_dict = preprocess_personnel_data_from_rows(grouped_rows)\n",
    "    \n",
    "    # Print extracted JSON data.\n",
    "    print(\"=== Extracted Data ===\")\n",
    "    print(json.dumps(data_dict, indent=4))\n",
    "    print(\"======================\\n\")\n",
    "    \n",
    "    # Create a DataFrame; if empty, use expected columns.\n",
    "    if data_dict[\"PERSONNEL\"]:\n",
    "        df_personnel = pd.DataFrame(data_dict[\"PERSONNEL\"])\n",
    "    else:\n",
    "        df_personnel = pd.DataFrame(columns=[\"Company\", \"Contractor\", \"No. Personnel\", \"Daily Hours\", \"Cumulative Hours\"])\n",
    "    \n",
    "    try:\n",
    "        display(df_personnel)\n",
    "    except NameError:\n",
    "        print(df_personnel)\n",
    "    \n",
    "    # Save outputs to CSV and JSON.\n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    local_output_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_output_folder, exist_ok=True)\n",
    "    \n",
    "    output_file_csv = os.path.join(local_output_folder, \"page_1_section_9_personnel_ocr.csv\")\n",
    "    output_file_json = os.path.join(local_output_folder, \"page_1_section_9_personnel_ocr.json\")\n",
    "    \n",
    "    df_personnel.to_csv(output_file_csv, index=False)\n",
    "    with open(output_file_json, \"w\") as json_file:\n",
    "        json.dump(data_dict, json_file, indent=4)\n",
    "    \n",
    "    logger.info(f\"Final DataFrame saved to {output_file_csv}\")\n",
    "    logger.info(f\"Final JSON saved to {output_file_json}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2740647171451187,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_surverydata_casing_consumables_personnel",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
