{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "230534a4-4011-47cb-a71d-55baffad3080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper Function: Convert DBFS URI to Local Path\n",
    "# ---------------------------------------------------------------------\n",
    "def dbfs_to_local_path(dbfs_path):\n",
    "    \"\"\"\n",
    "    Converts a DBFS URI (e.g. \"dbfs:/mnt/xxx\") to its local path (\"/dbfs/mnt/xxx\")\n",
    "    \"\"\"\n",
    "    if dbfs_path.startswith(\"dbfs:/\"):\n",
    "        return \"/dbfs/\" + dbfs_path[len(\"dbfs:/\"):]\n",
    "    return dbfs_path\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Helper Function: Check if a file exists on DBFS\n",
    "# ---------------------------------------------------------------------\n",
    "def file_exists(dbfs_path):\n",
    "    \"\"\"\n",
    "    Checks if a file exists on DBFS using dbutils.fs.ls.\n",
    "    If the path does not exist, an exception is thrown.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dbutils.fs.ls(dbfs_path)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Logger Setup\n",
    "# ---------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"MudSectionExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# show_image utility\n",
    "# ---------------------------------------------------------------------\n",
    "def show_image(title, img, cmap=None, size=(10, 10)):\n",
    "    plt.figure(figsize=size)\n",
    "    if cmap:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# read_cropped_section_image\n",
    "# ---------------------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    # Check file existence using DBFS API\n",
    "    if not file_exists(section_path):\n",
    "        raise FileNotFoundError(f\"File not found: {section_path}\")\n",
    "    # Convert DBFS URI to local path for OpenCV\n",
    "    local_path = dbfs_to_local_path(section_path)\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# preprocess_image\n",
    "# ---------------------------------------------------------------------\n",
    "def preprocess_image(img, debug=True):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if debug:\n",
    "        show_image(\"1) Grayscale\", gray, cmap='gray', size=(10,10))\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 9)\n",
    "    if debug:\n",
    "        show_image(\"2) Adaptive Threshold\", thresh, cmap='gray', size=(10,10))\n",
    "    return thresh\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# detect_text_regions\n",
    "# ---------------------------------------------------------------------\n",
    "def detect_text_regions(thresh_img, debug=True):\n",
    "    contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rois = []\n",
    "    debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 30 and h > 15:\n",
    "            rois.append((x, y, w, h))\n",
    "            cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "    rois.sort(key=lambda b: (b[1], b[0]))\n",
    "    if debug:\n",
    "        show_image(\"3) Detected Text Regions\", debug_img, size=(12,12))\n",
    "    return rois\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# perform_ocr_on_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def perform_ocr_on_rois(img, rois, debug=True):\n",
    "    results = []\n",
    "    n = len(rois)\n",
    "    if debug and n > 0:\n",
    "        cols = 5\n",
    "        rows = math.ceil(n / cols)\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "        axes = axes.flatten() if rows > 1 else [axes]\n",
    "    for i, (x, y, w, h) in enumerate(rois):\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "        if not text:\n",
    "            text = \"[BLANK]\"\n",
    "        results.append((x, y, w, h, text))\n",
    "        if debug and i < len(axes):\n",
    "            roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            axes[i].imshow(roi_rgb)\n",
    "            axes[i].set_title(f\"ROI {i+1}\\n{text[:30]}...\")\n",
    "            axes[i].axis(\"off\")\n",
    "    if debug and n > 0:\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# parse_value_row_tokens\n",
    "# ---------------------------------------------------------------------\n",
    "def parse_value_row_tokens(expected_headers, tokens):\n",
    "    \"\"\"\n",
    "    Map a flat list of tokens to the expected headers.\n",
    "    For \"GELS (10s/10m/30m)\", consume 3 tokens and create a sub-dictionary.\n",
    "    Expected token count = (number of headers - 1) + 3.\n",
    "    \"\"\"\n",
    "    expected_token_count = (len(expected_headers) - 1) + 3\n",
    "    logger.info(f\"Expected token count: {expected_token_count}, tokens extracted: {tokens}\")\n",
    "    \n",
    "    # Pad or trim tokens as needed.\n",
    "    if len(tokens) < expected_token_count:\n",
    "        tokens += [\"[BLANK]\"] * (expected_token_count - len(tokens))\n",
    "        logger.warning(\"Not enough tokens. Padding with [BLANK].\")\n",
    "    elif len(tokens) > expected_token_count:\n",
    "        tokens = tokens[:expected_token_count]\n",
    "        logger.warning(\"Too many tokens. Trimming the extra tokens.\")\n",
    "    \n",
    "    result = {}\n",
    "    idx = 0\n",
    "    for header in expected_headers:\n",
    "        if header == \"GELS (10s/10m/30m)\":\n",
    "            gels_tokens = tokens[idx:idx+3]\n",
    "            result[header] = {\n",
    "                \"10s\": gels_tokens[0],\n",
    "                \"10m\": gels_tokens[1],\n",
    "                \"30m\": gels_tokens[2]\n",
    "            }\n",
    "            idx += 3\n",
    "        else:\n",
    "            result[header] = tokens[idx]\n",
    "            idx += 1\n",
    "    logger.info(f\"Mapped dictionary: {result}\")\n",
    "    return result\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# build_mud_dict_from_rois\n",
    "# ---------------------------------------------------------------------\n",
    "def build_mud_dict_from_rois(roi_texts, expected_headers):\n",
    "    \"\"\"\n",
    "    Group OCR results into rows based on the y coordinate.\n",
    "    Identify header rows and corresponding data rows.\n",
    "    \n",
    "    In our case, we expect:\n",
    "      - A header row (with labels) followed by a data row,\n",
    "      - Then a second header row (for the remaining fields) followed by a second data row.\n",
    "    \n",
    "    We then combine the two data rows' tokens and map them to expected_headers.\n",
    "    \"\"\"\n",
    "    row_tolerance = 10\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    prev_y = None\n",
    "\n",
    "    # Group by row based on y coordinate.\n",
    "    for (x, y, w, h, text) in roi_texts:\n",
    "        if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "            current_row.append((x, y, w, h, text))\n",
    "        else:\n",
    "            rows.append(current_row)\n",
    "            current_row = [(x, y, w, h, text)]\n",
    "        prev_y = y\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "    # Sort each row by x coordinate and log its text.\n",
    "    row_strings = []\n",
    "    for i, row_cells in enumerate(rows):\n",
    "        row_cells.sort(key=lambda c: c[0])\n",
    "        line_text = \" \".join(cell[4] for cell in row_cells)\n",
    "        row_strings.append(line_text)\n",
    "        logger.info(f\"Row {i} text: {line_text}\")\n",
    "\n",
    "    # Based on OCR output expectations:\n",
    "    # Row 1: header row 1 (first set of labels)\n",
    "    # Row 2: data row 1 (first set of values)\n",
    "    # Row 3: header row 2 (remaining labels)\n",
    "    # Row 4: data row 2 (remaining values)\n",
    "    header1_line = None\n",
    "    value1_line = None\n",
    "    header2_line = None\n",
    "    value2_line = None\n",
    "\n",
    "    for i, r_text in enumerate(row_strings):\n",
    "        if \"Type\" in r_text and not header1_line:\n",
    "            header1_line = r_text\n",
    "            if i + 1 < len(row_strings):\n",
    "                value1_line = row_strings[i+1]\n",
    "        elif header1_line and not header2_line and any(kw in r_text for kw in [\"RPM\", \"Mud\", \"Loss\", \"Comments\"]):\n",
    "            header2_line = r_text\n",
    "            if i + 1 < len(row_strings):\n",
    "                value2_line = row_strings[i+1]\n",
    "            break\n",
    "\n",
    "    logger.info(f\"Header1: {header1_line}\")\n",
    "    logger.info(f\"Value1: {value1_line}\")\n",
    "    logger.info(f\"Header2: {header2_line}\")\n",
    "    logger.info(f\"Value2: {value2_line}\")\n",
    "\n",
    "    if value1_line is None:\n",
    "        logger.error(\"No data row found for header1!\")\n",
    "        return {}\n",
    "\n",
    "    # Split the data rows into tokens.\n",
    "    tokens1 = value1_line.split()\n",
    "    tokens2 = value2_line.split() if value2_line else []\n",
    "    logger.info(f\"Tokens from data row 1: {tokens1}\")\n",
    "    logger.info(f\"Tokens from data row 2: {tokens2}\")\n",
    "\n",
    "    # Combine tokens from both data rows.\n",
    "    combined_tokens = tokens1 + tokens2\n",
    "    logger.info(f\"Combined tokens: {combined_tokens}\")\n",
    "\n",
    "    # Map the tokens to the expected headers.\n",
    "    return parse_value_row_tokens(expected_headers, combined_tokens)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# main_pipeline\n",
    "# ---------------------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    expected_headers = [\n",
    "        \"Type\", \"Weight In\", \"Weight Out\", \"pH\", \"CAKE\",\n",
    "        \"GELS (10s/10m/30m)\", \"Oil/Water\", \"FV\", \"ES\", \"PV\",\n",
    "        \"YP\", \"CL\", \"Ca\", \"LGS\", \"WL\", \"HTHP Loss\", \"3 RPM\",\n",
    "        \"6 RPM\", \"Mud Pits and Hole Volume\", \"24 Hr Loss\",\n",
    "        \"Total Loss\", \"Comments\"\n",
    "    ]\n",
    "    # Use a DBFS URI for the input image\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    show_image(\"Original Cropped Section\", img, size=(12,12))\n",
    "    thresh_img = preprocess_image(img, debug=True)\n",
    "    rois = detect_text_regions(thresh_img, debug=True)\n",
    "    roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "    # Build the mud dictionary using the combined data rows.\n",
    "    mud_dict = build_mud_dict_from_rois(roi_texts, expected_headers)\n",
    "    final_dict = {\"MUD\": mud_dict}\n",
    "    logger.info(\"===== FINAL EXTRACTED MUD DICTIONARY =====\")\n",
    "    logger.info(json.dumps(final_dict, indent=4))\n",
    "    \n",
    "    df_final = pd.DataFrame(list(mud_dict.items()), columns=[\"Key\", \"Value\"])\n",
    "    print(\"----- Extracted DataFrame -----\")\n",
    "    print(df_final)\n",
    "    \n",
    "    # Define the output folder using a DBFS URI and create it with dbutils.fs.mkdirs\n",
    "    output_folder_dbfs = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    dbutils.fs.mkdirs(output_folder_dbfs)\n",
    "    # Instead of writing using OS-level functions, convert the DataFrame to CSV text\n",
    "    # and write it directly to DBFS.\n",
    "    out_file = output_folder_dbfs + \"/page_1_section_3_ocr.csv\"\n",
    "    csv_data = df_final.to_csv(index=False)\n",
    "    dbutils.fs.put(out_file, csv_data, overwrite=True)\n",
    "    logger.info(f\"Final DataFrame saved to {out_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eecdad8-3a6d-4cc5-9e00-a1ac43ef1b88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import cv2\n",
    "# import pytesseract\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # Logger Setup\n",
    "# # ---------------------------------------------------------------------\n",
    "# logger = logging.getLogger(\"MudSectionExtractor\")\n",
    "# logger.setLevel(logging.INFO)\n",
    "# if not logger.handlers:\n",
    "#     handler = logging.StreamHandler()\n",
    "#     handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "#     logger.addHandler(handler)\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # show_image utility\n",
    "# # ---------------------------------------------------------------------\n",
    "# def show_image(title, img, cmap=None, size=(10, 10)):\n",
    "#     plt.figure(figsize=size)\n",
    "#     if cmap:\n",
    "#         plt.imshow(img, cmap=cmap)\n",
    "#     else:\n",
    "#         if len(img.shape) == 3:\n",
    "#             plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         else:\n",
    "#             plt.imshow(img, cmap='gray')\n",
    "#     plt.title(title)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # read_cropped_section_image\n",
    "# # ---------------------------------------------------------------------\n",
    "# def read_cropped_section_image(section_path):\n",
    "#     local_path = section_path.replace(\"dbfs:\", \"/dbfs\") if section_path.startswith(\"dbfs:\") else section_path\n",
    "#     if not os.path.exists(local_path):\n",
    "#         raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "#     img = cv2.imread(local_path)\n",
    "#     if img is None:\n",
    "#         raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "#     return img\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # preprocess_image\n",
    "# # ---------------------------------------------------------------------\n",
    "# def preprocess_image(img, debug=True):\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     if debug:\n",
    "#         show_image(\"1) Grayscale\", gray, cmap='gray', size=(10,10))\n",
    "#     thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#                                    cv2.THRESH_BINARY, 15, 9)\n",
    "#     if debug:\n",
    "#         show_image(\"2) Adaptive Threshold\", thresh, cmap='gray', size=(10,10))\n",
    "#     return thresh\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # detect_text_regions\n",
    "# # ---------------------------------------------------------------------\n",
    "# def detect_text_regions(thresh_img, debug=True):\n",
    "#     contours, _ = cv2.findContours(thresh_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     rois = []\n",
    "#     debug_img = cv2.cvtColor(thresh_img, cv2.COLOR_GRAY2BGR)\n",
    "#     for cnt in contours:\n",
    "#         x, y, w, h = cv2.boundingRect(cnt)\n",
    "#         if w > 30 and h > 15:\n",
    "#             rois.append((x, y, w, h))\n",
    "#             cv2.rectangle(debug_img, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "#     rois.sort(key=lambda b: (b[1], b[0]))\n",
    "#     if debug:\n",
    "#         show_image(\"3) Detected Text Regions\", debug_img, size=(12,12))\n",
    "#     return rois\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # perform_ocr_on_rois\n",
    "# # ---------------------------------------------------------------------\n",
    "# def perform_ocr_on_rois(img, rois, debug=True):\n",
    "#     results = []\n",
    "#     n = len(rois)\n",
    "#     if debug and n > 0:\n",
    "#         cols = 5\n",
    "#         rows = math.ceil(n / cols)\n",
    "#         fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "#         axes = axes.flatten() if rows > 1 else [axes]\n",
    "#     for i, (x, y, w, h) in enumerate(rois):\n",
    "#         roi = img[y:y+h, x:x+w]\n",
    "#         text = pytesseract.image_to_string(roi, config='--psm 6').strip()\n",
    "#         if not text:\n",
    "#             text = \"[BLANK]\"\n",
    "#         results.append((x, y, w, h, text))\n",
    "#         if debug and i < len(axes):\n",
    "#             roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "#             axes[i].imshow(roi_rgb)\n",
    "#             axes[i].set_title(f\"ROI {i+1}\\n{text[:30]}...\")\n",
    "#             axes[i].axis(\"off\")\n",
    "#     if debug and n > 0:\n",
    "#         for j in range(i + 1, len(axes)):\n",
    "#             axes[j].axis(\"off\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "#     return results\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # parse_value_row_tokens\n",
    "# # ---------------------------------------------------------------------\n",
    "# def parse_value_row_tokens(expected_headers, tokens):\n",
    "#     \"\"\"\n",
    "#     Map a flat list of tokens to the expected headers.\n",
    "#     For \"GELS (10s/10m/30m)\", consume 3 tokens and create a sub-dictionary.\n",
    "#     Expected token count = (number of headers - 1) + 3.\n",
    "#     \"\"\"\n",
    "#     expected_token_count = (len(expected_headers) - 1) + 3\n",
    "#     logger.info(f\"Expected token count: {expected_token_count}, tokens extracted: {tokens}\")\n",
    "    \n",
    "#     # Pad or trim tokens as needed.\n",
    "#     if len(tokens) < expected_token_count:\n",
    "#         tokens += [\"[BLANK]\"] * (expected_token_count - len(tokens))\n",
    "#         logger.warning(\"Not enough tokens. Padding with [BLANK].\")\n",
    "#     elif len(tokens) > expected_token_count:\n",
    "#         tokens = tokens[:expected_token_count]\n",
    "#         logger.warning(\"Too many tokens. Trimming the extra tokens.\")\n",
    "    \n",
    "#     result = {}\n",
    "#     idx = 0\n",
    "#     for header in expected_headers:\n",
    "#         if header == \"GELS (10s/10m/30m)\":\n",
    "#             gels_tokens = tokens[idx:idx+3]\n",
    "#             result[header] = {\n",
    "#                 \"10s\": gels_tokens[0],\n",
    "#                 \"10m\": gels_tokens[1],\n",
    "#                 \"30m\": gels_tokens[2]\n",
    "#             }\n",
    "#             idx += 3\n",
    "#         else:\n",
    "#             result[header] = tokens[idx]\n",
    "#             idx += 1\n",
    "#     logger.info(f\"Mapped dictionary: {result}\")\n",
    "#     return result\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # build_mud_dict_from_rois\n",
    "# # ---------------------------------------------------------------------\n",
    "# def build_mud_dict_from_rois(roi_texts, expected_headers):\n",
    "#     \"\"\"\n",
    "#     Group OCR results into rows based on the y coordinate.\n",
    "#     Identify header rows and corresponding data rows.\n",
    "    \n",
    "#     In our case, we expect:\n",
    "#       - A header row (with labels) followed by a data row,\n",
    "#       - Then a second header row (for the remaining fields) followed by a second data row.\n",
    "    \n",
    "#     We then combine the two data rows' tokens and map them to expected_headers.\n",
    "#     \"\"\"\n",
    "#     row_tolerance = 10\n",
    "#     rows = []\n",
    "#     current_row = []\n",
    "#     prev_y = None\n",
    "\n",
    "#     # Group by row based on y coordinate.\n",
    "#     for (x, y, w, h, text) in roi_texts:\n",
    "#         if prev_y is None or abs(y - prev_y) <= row_tolerance:\n",
    "#             current_row.append((x, y, w, h, text))\n",
    "#         else:\n",
    "#             rows.append(current_row)\n",
    "#             current_row = [(x, y, w, h, text)]\n",
    "#         prev_y = y\n",
    "#     if current_row:\n",
    "#         rows.append(current_row)\n",
    "\n",
    "#     # Sort each row by x coordinate and log its text.\n",
    "#     row_strings = []\n",
    "#     for i, row_cells in enumerate(rows):\n",
    "#         row_cells.sort(key=lambda c: c[0])\n",
    "#         line_text = \" \".join(cell[4] for cell in row_cells)\n",
    "#         row_strings.append(line_text)\n",
    "#         logger.info(f\"Row {i} text: {line_text}\")\n",
    "\n",
    "#     # Based on your OCR output, we expect:\n",
    "#     # Row 1: header row 1 (first set of labels)\n",
    "#     # Row 2: data row 1 (first set of values)\n",
    "#     # Row 3: header row 2 (remaining labels)\n",
    "#     # Row 4: data row 2 (remaining values)\n",
    "#     header1_line = None\n",
    "#     value1_line = None\n",
    "#     header2_line = None\n",
    "#     value2_line = None\n",
    "\n",
    "#     for i, r_text in enumerate(row_strings):\n",
    "#         if \"Type\" in r_text and not header1_line:\n",
    "#             header1_line = r_text\n",
    "#             if i + 1 < len(row_strings):\n",
    "#                 value1_line = row_strings[i+1]\n",
    "#         elif header1_line and not header2_line and any(kw in r_text for kw in [\"RPM\", \"Mud\", \"Loss\", \"Comments\"]):\n",
    "#             header2_line = r_text\n",
    "#             if i + 1 < len(row_strings):\n",
    "#                 value2_line = row_strings[i+1]\n",
    "#             break\n",
    "\n",
    "#     logger.info(f\"Header1: {header1_line}\")\n",
    "#     logger.info(f\"Value1: {value1_line}\")\n",
    "#     logger.info(f\"Header2: {header2_line}\")\n",
    "#     logger.info(f\"Value2: {value2_line}\")\n",
    "\n",
    "#     if value1_line is None:\n",
    "#         logger.error(\"No data row found for header1!\")\n",
    "#         return {}\n",
    "\n",
    "#     # Split the data rows into tokens.\n",
    "#     tokens1 = value1_line.split()\n",
    "#     tokens2 = value2_line.split() if value2_line else []\n",
    "#     logger.info(f\"Tokens from data row 1: {tokens1}\")\n",
    "#     logger.info(f\"Tokens from data row 2: {tokens2}\")\n",
    "\n",
    "#     # Combine tokens from both data rows.\n",
    "#     combined_tokens = tokens1 + tokens2\n",
    "#     logger.info(f\"Combined tokens: {combined_tokens}\")\n",
    "\n",
    "#     # Map the tokens to the expected headers.\n",
    "#     return parse_value_row_tokens(expected_headers, combined_tokens)\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # main_pipeline\n",
    "# # ---------------------------------------------------------------------\n",
    "# def main_pipeline():\n",
    "#     expected_headers = [\n",
    "#         \"Type\", \"Weight In\", \"Weight Out\", \"pH\", \"CAKE\",\n",
    "#         \"GELS (10s/10m/30m)\", \"Oil/Water\", \"FV\", \"ES\", \"PV\",\n",
    "#         \"YP\", \"CL\", \"Ca\", \"LGS\", \"WL\", \"HTHP Loss\", \"3 RPM\",\n",
    "#         \"6 RPM\", \"Mud Pits and Hole Volume\", \"24 Hr Loss\",\n",
    "#         \"Total Loss\", \"Comments\"\n",
    "#     ]\n",
    "#     section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_3.png\"\n",
    "#     try:\n",
    "#         img = read_cropped_section_image(section_path)\n",
    "#         logger.info(\"Image loaded successfully.\")\n",
    "#     except Exception as e:\n",
    "#         logger.error(e)\n",
    "#         return\n",
    "\n",
    "#     show_image(\"Original Cropped Section\", img, size=(12,12))\n",
    "#     thresh_img = preprocess_image(img, debug=True)\n",
    "#     rois = detect_text_regions(thresh_img, debug=True)\n",
    "#     roi_texts = perform_ocr_on_rois(img, rois, debug=True)\n",
    "    \n",
    "#     # Build the mud dictionary using the combined data rows.\n",
    "#     mud_dict = build_mud_dict_from_rois(roi_texts, expected_headers)\n",
    "#     final_dict = {\"MUD\": mud_dict}\n",
    "#     logger.info(\"===== FINAL EXTRACTED MUD DICTIONARY =====\")\n",
    "#     logger.info(json.dumps(final_dict, indent=4))\n",
    "    \n",
    "#     df_final = pd.DataFrame(list(mud_dict.items()), columns=[\"Key\", \"Value\"])\n",
    "#     print(\"----- Extracted DataFrame -----\")\n",
    "#     print(df_final)\n",
    "    \n",
    "#     output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "#     local_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "#     os.makedirs(local_folder, exist_ok=True)\n",
    "#     out_file = os.path.join(local_folder, \"page_1_section_3_ocr.csv\")\n",
    "#     df_final.to_csv(out_file, index=False)\n",
    "#     logger.info(f\"Final DataFrame saved to {out_file}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 267239741802602,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_mud",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
