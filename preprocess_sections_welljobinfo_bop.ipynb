{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "536ed951-ecc4-49e0-b451-aed51dfcc426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"WellJobInfoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) OCR Extraction (Minimal Processing)\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Use psm 6: assume a uniform block of text\n",
    "    text = pytesseract.image_to_string(gray, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Expected Keys Extraction from Combined OCR Text\n",
    "# --------------------------------------------------------\n",
    "def extract_key_value_from_text(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Combines all OCR text lines into a single string and, using the expected keys\n",
    "    (in order), extracts each value as the text between the current key and the next key.\n",
    "    If a key is not found, an empty string is returned.\n",
    "    \"\"\"\n",
    "    # Combine all non-empty lines into one string.\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    # Normalize whitespace.\n",
    "    combined = re.sub(r'\\s+', ' ', combined)\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*?)\\s*(?=' + re.escape(next_key) + r'\\s*:)'\n",
    "        else:\n",
    "            pattern = re.escape(key) + r'\\s*:\\s*(.*)$'\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value\n",
    "        else:\n",
    "            result[key] = \"\"\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_2.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    # Define the exact expected keys (in the desired order)\n",
    "    expected_keys = [\n",
    "        \"Well Name\",\n",
    "        \"Job Name\",\n",
    "        \"Supervisor(s)\",\n",
    "        \"Field\",\n",
    "        \"Sec/Twn/Rng\",\n",
    "        \"Phone\",\n",
    "        \"AFE #\",\n",
    "        \"API #\",\n",
    "        \"Email\",\n",
    "        \"Contractor\",\n",
    "        \"Elevation\",\n",
    "        \"RKB\",\n",
    "        \"Spud Date\",\n",
    "        \"Days from Spud\",\n",
    "        \"Days on Loc\",\n",
    "        \"MD/TVD\",\n",
    "        \"24 Hr Footage\",\n",
    "        \"Present Operations\",\n",
    "        \"Activity Planned\"\n",
    "    ]\n",
    "\n",
    "    extracted = extract_key_value_from_text(ocr_text, expected_keys)\n",
    "    final_dict = {\"WELL/JOB INFORMATION\": extracted}\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    local_output_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(local_output_folder, \"page_1_section_2_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f03ae4ae-ec88-4bfa-9c1d-7042d932ba5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import logging\n",
    "import json\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# --------------------------------------------------------\n",
    "logger = logging.getLogger(\"WellJobInfoExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2) Read Image from DBFS/Local Path\n",
    "# --------------------------------------------------------\n",
    "def read_cropped_section_image(section_path):\n",
    "    local_path = section_path\n",
    "    if local_path.startswith(\"dbfs:\"):\n",
    "        local_path = local_path.replace(\"dbfs:\", \"\")\n",
    "    if local_path.startswith(\"/mnt/\"):\n",
    "        local_path = \"/dbfs\" + local_path\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "    img = cv2.imread(local_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"OpenCV failed to load image: {local_path}\")\n",
    "    return img\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3) OCR Extraction (Minimal Processing)\n",
    "# --------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray, config='--psm 6')\n",
    "    return text\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 4) Extract BOP Information\n",
    "# --------------------------------------------------------\n",
    "def extract_bop_info(text):\n",
    "    pattern = {\n",
    "        \"Last BOP Test Date\": r\"Last BOP Test Date\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Last BOP Drill\": r\"Last BOP Drill\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\",\n",
    "        \"Next BOP Test\": r\"Next BOP Test\\s*:\\s*(\\d{1,2}/\\d{1,2}/\\d{2,4})\"\n",
    "    }\n",
    "    result = {}\n",
    "    for key, regex in pattern.items():\n",
    "        match = re.search(regex, text, re.IGNORECASE)\n",
    "        result[key] = match.group(1) if match else \"\"\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_8.png\"\n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    extracted_bop = extract_bop_info(ocr_text)\n",
    "    final_dict = {\"BOP\": extracted_bop}\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted_bop.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"dbfs:/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    local_output_folder = output_folder.replace(\"dbfs:\", \"/dbfs\")\n",
    "    os.makedirs(local_output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(local_output_folder, \"page_1_section_8_bop_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9abff60d-7207-42ec-bd8b-d4ab78c6716c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_key_value_from_text(text, expected_keys):\n",
    "    \"\"\"\n",
    "    Extracts key-value pairs from the text, ensuring that keys with empty values\n",
    "    are correctly detected instead of capturing the next key as their value.\n",
    "    \"\"\"\n",
    "    combined = \" \".join(line.strip() for line in text.splitlines() if line.strip())\n",
    "    combined = re.sub(r'\\s+', ' ', combined)  # Normalize whitespace\n",
    "\n",
    "    result = {}\n",
    "    for i, key in enumerate(expected_keys):\n",
    "        if i < len(expected_keys) - 1:\n",
    "            next_key = expected_keys[i+1]\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*?)(?=\\s*{re.escape(next_key)}\\s*:|$)'\n",
    "        else:\n",
    "            pattern = rf'{re.escape(key)}\\s*:\\s*(.*)'\n",
    "\n",
    "        match = re.search(pattern, combined, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).strip()\n",
    "            result[key] = value if value else None  # Assign None for empty values\n",
    "        else:\n",
    "            result[key] = None  # Explicitly mark missing values\n",
    "\n",
    "    return result\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 5) Main Pipeline for Cost Data Extraction\n",
    "# --------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    section_path = \"dbfs:/mnt/mini-proj-dd/cropped_sections/page_1_section_13.png\"\n",
    "    \n",
    "    try:\n",
    "        img = read_cropped_section_image(section_path)\n",
    "        logger.info(\"Image loaded successfully.\")\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\")\n",
    "\n",
    "    expected_keys = [\n",
    "        \"Drilling AFE Amount\",\n",
    "        \"Daily Drilling Cost\",\n",
    "        \"Cumulative Drilling Cost\",\n",
    "        \"Cumulative Well Cost\",\n",
    "        \"Daily Mud Cost\",\n",
    "        \"Cumulative Mud Cost\"\n",
    "    ]\n",
    "\n",
    "    extracted = extract_key_value_from_text(ocr_text, expected_keys)\n",
    "    final_dict = {\"COST DATA\": extracted}\n",
    "    logger.info(json.dumps(final_dict, indent=4))\n",
    "    print(json.dumps(final_dict, indent=4))\n",
    "\n",
    "    df_final = pd.DataFrame(list(extracted.items()), columns=[\"Key\", \"Value\"])\n",
    "    try:\n",
    "        display(df_final)\n",
    "    except NameError:\n",
    "        print(df_final)\n",
    "    \n",
    "    output_folder = \"/dbfs/mnt/mini-proj-dd/final_ocr_results\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, \"page_1_section_cost_data_ocr.csv\")\n",
    "    df_final.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final DataFrame saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c35c7aac-0961-4d06-8437-fefd5d514bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 267239741802583,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_welljobinfo_bop",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
