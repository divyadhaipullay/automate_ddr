{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1930a03-bb23-4d42-8ba5-a587d4415f76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ./init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97524773-57fe-4371-89eb-626f58904f81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import re\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "def extract_bha_data(image_path):\n",
    "    # Load image and perform OCR\n",
    "    image = Image.open(image_path)\n",
    "    ocr_text = pytesseract.image_to_string(image)\n",
    "    \n",
    "    # Define regex patterns to extract key values without repetition\n",
    "    patterns = {\n",
    "        \"Drill Pipe Detail\": r\"Drill Pipe Detail:\\s*([^\\n]+)\",  # Extracts full text but **won't duplicate fields**\n",
    "        \"Size\": r\"Size:\\s*([\\d.]+)\\b\",\n",
    "        \"Wt./Ft\": r\"Wt\\./Ft:\\s*([\\d.]+)\\b\",\n",
    "        \"Connection\": r\"Connection:\\s*([\\w\\d-]+)\\b\",\n",
    "        \"ID\": r\"ID:\\s*([\\d.]+)\\b\",\n",
    "        \"Drill Bit\": r\"Drill Bit:\\s*([^\\n;]+)\",\n",
    "        \"Motor\": r\"Motor:\\s*([^\\n;]+)\",\n",
    "        \"MWD Tool\": r\"MWD Tool:\\s*([^\\n;]+)\",\n",
    "        \"Monel Collar\": r\"Monel Collar:\\s*([^\\n;]+)\",\n",
    "        \"X-Over\": r\"X-Over:\\s*([^\\n;]+)\",\n",
    "        \"Sub\": r\"Sub:\\s*([^\\n;]+)\",\n",
    "        \"HWDP\": r\"HWDP:\\s*([^\\n;]+)\",\n",
    "        \"Drill Pipe\": r\"Drill Pipe:\\s*([\\d.]+(?:\\\" DP)?)\",  \n",
    "        \"Reamer\": r\"Reamer:\\s*([^\\n;]+)\",\n",
    "        \"Shock Sub\": r\"Shock Sub:\\s*([^\\n;]+)\",\n",
    "        \"Total Length\": r\"Total Length:\\s*(\\d+)\\b\"\n",
    "    }\n",
    "    \n",
    "    # Extract data\n",
    "    bha_data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, ocr_text)\n",
    "        if match:\n",
    "            bha_data[key] = match.group(1).strip()\n",
    "    \n",
    "    # **Fix duplication issue:** Remove Size, Wt./Ft, Connection, ID from `\"Drill Pipe Detail\"`\n",
    "    if \"Drill Pipe Detail\" in bha_data:\n",
    "        detail = bha_data[\"Drill Pipe Detail\"]\n",
    "        for remove_key in [\"Size\", \"Wt./Ft\", \"Connection\", \"ID\"]:\n",
    "            if remove_key in bha_data:\n",
    "                detail = re.sub(rf\"{remove_key}:\\s*{re.escape(bha_data[remove_key])}\", \"\", detail).strip(\",; \")\n",
    "        bha_data[\"Drill Pipe Detail\"] = detail  # Store cleaned version\n",
    "\n",
    "    # **Final structured JSON without repetition**\n",
    "    structured_data = {\n",
    "        \"BHA\": {\n",
    "            \"Drill Pipe Detail\": bha_data.get(\"Drill Pipe Detail\", \"\"),\n",
    "            \"Size\": bha_data.get(\"Size\", \"\"),\n",
    "            \"Wt./Ft\": bha_data.get(\"Wt./Ft\", \"\"),\n",
    "            \"Connection\": bha_data.get(\"Connection\", \"\"),\n",
    "            \"ID\": bha_data.get(\"ID\", \"\"),\n",
    "            \"BHA #4\": {\n",
    "                \"Drill Bit\": bha_data.get(\"Drill Bit\", \"\"),\n",
    "                \"Motor\": bha_data.get(\"Motor\", \"\"),\n",
    "                \"MWD Tool\": bha_data.get(\"MWD Tool\", \"\"),\n",
    "                \"Monel Collar\": bha_data.get(\"Monel Collar\", \"\"),\n",
    "                \"X-Over\": bha_data.get(\"X-Over\", \"\"),\n",
    "                \"Sub\": bha_data.get(\"Sub\", \"\"),\n",
    "                \"HWDP\": bha_data.get(\"HWDP\", \"\"),\n",
    "                \"Drill Pipe\": bha_data.get(\"Drill Pipe\", \"\"),\n",
    "                \"Reamer\": bha_data.get(\"Reamer\", \"\"),\n",
    "                \"Shock Sub\": bha_data.get(\"Shock Sub\", \"\")\n",
    "            },\n",
    "            \"Total Length\": bha_data.get(\"Total Length\", \"\")  # ✅ Now correctly placed at the end\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return structured_data\n",
    "\n",
    "def main():\n",
    "    image_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_11.png\"  # Change this to your actual image path\n",
    "    bha_json = extract_bha_data(image_path)\n",
    "    print(json.dumps(bha_json, indent=4))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f07a0a0-a9a1-43b9-b760-e6eb80e7565c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pytesseract\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Minimal Logger Configuration\n",
    "# ------------------------------------------------------------------\n",
    "logger = logging.getLogger(\"PumpExtractor\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(logging.Formatter(\"%(levelname)s: %(message)s\"))\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Read Image\n",
    "# ------------------------------------------------------------------\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "    Reads the image from local or DBFS path and returns a PIL Image.\n",
    "    \"\"\"\n",
    "    # If the path starts with \"dbfs:/\", convert to \"/dbfs/...\" path\n",
    "    if image_path.startswith(\"dbfs:/\"):\n",
    "        # remove the \"dbfs:\" prefix => so \"dbfs:/mnt/...\" becomes \"/mnt/...\"\n",
    "        stripped = image_path.replace(\"dbfs:\", \"\")  # => \"/mnt/mini-proj-dd/...\"\n",
    "        # prepend \"/dbfs\" => \"/dbfs/mnt/mini-proj-dd/...\"\n",
    "        local_path = \"/dbfs\" + stripped\n",
    "    else:\n",
    "        # otherwise, assume it's a normal local path\n",
    "        local_path = image_path\n",
    "\n",
    "    if not os.path.exists(local_path):\n",
    "        raise FileNotFoundError(f\"File not found: {local_path}\")\n",
    "\n",
    "    from PIL import Image\n",
    "    img = Image.open(local_path)\n",
    "    logger.info(f\"Image loaded from {local_path} with size {img.size}\")\n",
    "    return img\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Perform OCR\n",
    "# ------------------------------------------------------------------\n",
    "def perform_ocr(img):\n",
    "    \"\"\"\n",
    "    Performs OCR on the given PIL image, returning raw text.\n",
    "    \"\"\"\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    logger.info(\"OCR extraction complete.\")\n",
    "    return text\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Parse Pumps Table\n",
    "# ------------------------------------------------------------------\n",
    "def parse_pumps_table(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses the pumps table from the OCR text.\n",
    "    Expected lines look like:\n",
    "      Number Model Type   HHP  Efficiency  Stroke(in)  Liner(in)  P-Rating(psi)  P-Limit(psi)  SPM Rating  SPM Limit\n",
    "      1      BOMCO TRIPLEX 1600 95       12.000       4.75       7500           7100          120         110\n",
    "      2      BOMCO TRIPLEX 1600 95       12.000       4.75       7500           7100          120         110\n",
    "      (possibly missing fields in some rows)\n",
    "    \"\"\"\n",
    "\n",
    "    # We’ll search for lines that look like:\n",
    "    #   <Number> BOMCO TRIPLEX <HHP> <Eff> <Stroke> <Liner> <P-Rating> <P-Limit> <SPM Rating> <SPM Limit>\n",
    "    #   or possibly missing the Number or HHP.\n",
    "    # We'll capture them with a regex that checks for 8-11 columns.\n",
    "    # You can refine further as needed.\n",
    "    pump_pattern = re.compile(\n",
    "        r\"^(\\d+)?\\s*\"               # Number (optional)\n",
    "        r\"(BOMCO)\\s+(TRIPLEX)\\s+\"    # Model, Type\n",
    "        r\"(\\d+)?\\s*\"                 # HHP (optional)\n",
    "        r\"(\\d+)\\s+\"                  # Efficiency\n",
    "        r\"([\\d.]+)\\s+\"               # Stroke(in)\n",
    "        r\"([\\d.]+)\\s+\"               # Liner(in)\n",
    "        r\"(\\d+)\\s+\"                  # P-Rating(psi)\n",
    "        r\"(\\d+)\\s+\"                  # P-Limit(psi)\n",
    "        r\"(\\d+)\\s+\"                  # SPM Rating\n",
    "        r\"(\\d+)\\s*$\",                # SPM Limit\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    lines = ocr_text.splitlines()\n",
    "    pumps = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        match = pump_pattern.match(line)\n",
    "        if match:\n",
    "            # Extract fields\n",
    "            number, model, pump_type, hhp, efficiency, stroke, liner, p_rating, p_limit, spm_rating, spm_limit = match.groups()\n",
    "\n",
    "            # Store as dictionary\n",
    "            pumps.append({\n",
    "                \"Number\": number if number else \"\",\n",
    "                \"Model\": model,\n",
    "                \"Type\": pump_type,\n",
    "                \"HHP\": hhp if hhp else \"\",\n",
    "                \"Efficiency\": efficiency,\n",
    "                \"Stroke(in)\": stroke,\n",
    "                \"Liner(in)\": liner,\n",
    "                \"P-Rating(psi)\": p_rating,\n",
    "                \"P-Limit(psi)\": p_limit,\n",
    "                \"SPM Rating\": spm_rating,\n",
    "                \"SPM Limit\": spm_limit\n",
    "            })\n",
    "\n",
    "    return pumps\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5) Parse Drilling/Circ Rates\n",
    "# ------------------------------------------------------------------\n",
    "def parse_drilling_circ_rates(ocr_text):\n",
    "    \"\"\"\n",
    "    Parses lines like:\n",
    "      Drilling/Circ Rate 1 4325 PSI @ 134 SPM 2.63 Gal/Stoke 351.76 GPM 8.38 BPM 468.11 DC 340.61 DP\n",
    "      Drilling/Circ Rate 2 4475 PSI @ 134 SPM 2.63 Gal/Stoke 351.76 GPM 8.38 BPM 468.11 DC 340.61 DP\n",
    "    We'll store them in a structured list of dicts.\n",
    "    \"\"\"\n",
    "\n",
    "    # We'll define a pattern capturing Rate #, Pressure, SPM, Gal/Stoke, GPM, BPM, DC, DP, etc.\n",
    "    # Example line:\n",
    "    #   Drilling/Circ Rate 1 4325 PSI @ 134 SPM 2.63 Gal/Stoke 351.76 GPM 8.38 BPM 468.11 DC 340.61 DP\n",
    "    circ_pattern = re.compile(\n",
    "        r\"Drilling/Circ\\s+Rate\\s+(\\d+)\\s+(\\d+)\\s+PSI\\s*@\\s*(\\d+)\\s*SPM\\s*([\\d.]+)\\s+Gal/Stoke\\s+([\\d.]+)\\s+GPM\\s+([\\d.]+)\\s+BPM\\s+([\\d.]+)\\s+DC\\s+([\\d.]+)\\s+DP\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    lines = ocr_text.splitlines()\n",
    "    circ_rates = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        match = circ_pattern.search(line)\n",
    "        if match:\n",
    "            rate_id, pressure, spm, gal_stroke, gpm, bpm, dc, dp = match.groups()\n",
    "            circ_rates.append({\n",
    "                \"RateID\": rate_id,\n",
    "                \"Pressure(PSI)\": pressure,\n",
    "                \"SPM\": spm,\n",
    "                \"Gal/Stoke\": gal_stroke,\n",
    "                \"GPM\": gpm,\n",
    "                \"BPM\": bpm,\n",
    "                \"DC\": dc,\n",
    "                \"DP\": dp\n",
    "            })\n",
    "\n",
    "    return circ_rates\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6) Main Pipeline\n",
    "# ------------------------------------------------------------------\n",
    "def main_pipeline():\n",
    "    # 1) Load image\n",
    "    image_path = \"/dbfs/mnt/mini-proj-dd/cropped_sections/page_1_section_12.png\"  # Adjust as needed\n",
    "    try:\n",
    "        img = read_image(image_path)\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(e)\n",
    "        return\n",
    "    \n",
    "    # 2) Perform OCR\n",
    "    ocr_text = perform_ocr(img)\n",
    "    logger.info(f\"OCR Text:\\n{ocr_text}\\n\")\n",
    "\n",
    "    # 3) Parse the two sections\n",
    "    pumps = parse_pumps_table(ocr_text)\n",
    "    circ_rates = parse_drilling_circ_rates(ocr_text)\n",
    "\n",
    "    # 4) Convert to DataFrames\n",
    "    df_pumps = pd.DataFrame(pumps)\n",
    "    df_circ = pd.DataFrame(circ_rates)\n",
    "\n",
    "    # 5) Build final JSON structure\n",
    "    final_data = {\n",
    "        \"Pumps\": pumps,\n",
    "        \"DrillingCircRates\": circ_rates\n",
    "    }\n",
    "\n",
    "    # 6) Print or display results\n",
    "    logger.info(\"=== Pumps DataFrame ===\")\n",
    "    print(df_pumps)\n",
    "    logger.info(\"=== Drilling/Circ Rates DataFrame ===\")\n",
    "    print(df_circ)\n",
    "\n",
    "    logger.info(\"=== Final JSON ===\")\n",
    "    print(json.dumps(final_data, indent=4))\n",
    "\n",
    "    # 7) Save to CSV and JSON\n",
    "    output_folder = \"/dbfs/mnt/data/final_results_pumps\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    csv_pumps_path = os.path.join(output_folder, \"pumps.csv\")\n",
    "    csv_circ_path = os.path.join(output_folder, \"drilling_circ_rates.csv\")\n",
    "    json_path = os.path.join(output_folder, \"pumps_drilling_circ.json\")\n",
    "\n",
    "    df_pumps.to_csv(csv_pumps_path, index=False)\n",
    "    df_circ.to_csv(csv_circ_path, index=False)\n",
    "\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(final_data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"Pumps CSV saved to: {csv_pumps_path}\")\n",
    "    logger.info(f\"Drilling/Circ Rates CSV saved to: {csv_circ_path}\")\n",
    "    logger.info(f\"JSON saved to: {json_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Run if called directly\n",
    "if __name__ == \"__main__\":\n",
    "    main_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89a324a1-6cd2-4fa0-83f6-b4fc0cc56c12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4230086100460830,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "preprocess_sections_bha_pumps",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
